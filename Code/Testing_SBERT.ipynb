{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "85fdaab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "import pandas as pd\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras import backend as K\n",
    "import argparse\n",
    "import os\n",
    "from sentence_embeddings import Sentence_Embedder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "142db268",
   "metadata": {},
   "source": [
    "# Ridle (with and without Language Model)\n",
    "In this notebook, the performance of \"Ridle\" is tested on different datasets. The neural network for further testing wasn't changed in any way, except giving it different inputs. Firstly the model is tested by itself to see how it performs in the normal case of just the representation from the RBM as inputs. Then we add our sentence embedding vectors to the representation vector and concatenate them to receive a new bigger vector with the size of input (50) and sentence embedding (384). Finally the whole program is also tested with only the sentence embeddings as inputs, to see how well the program can classify just by getting information from the summary embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7e75c7a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#jupyter notebook --NotebookApp.iopub_data_rate_limit=1.0e10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eae17182",
   "metadata": {},
   "outputs": [],
   "source": [
    "Datasets = [\"Books_DBpedia\", \"ChemicalCompounds_DBpedia\", \"Company_DBpedia\", \"DBp_2016-04\", \n",
    "            \"Person_DBpedia\", \"Songs_DBpedia\", \"umls\", \"Universities_DBpedia\"]\n",
    "df1 = pd.DataFrame(Datasets, index=Datasets)\n",
    "df1[\"Ridle misclassified\"] = \"\"\n",
    "df1[\"Sbert misclassified\"] = \"\"\n",
    "df1[\"Misclassified in both\"] = \"\"\n",
    "df1[\"ID list Bert\"] = \"\"\n",
    "df1[\"Prediction Bert\"] = \"\"\n",
    "df1[\"Target Bert\"] = \"\"\n",
    "df1[\"ID list Ridle\"] = \"\"\n",
    "df1[\"Prediction Ridle\"] =\"\"\n",
    "df1[\"Target Ridle\"] = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0e9aaed6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GELU Activation function\n",
    "def gelu(x):\n",
    "    return 0.5 * x * (1 + K.tanh(x * 0.7978845608 * (1 + 0.044715 * x * x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5d2ca205",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading Data...\n",
      "Processing Data...\n"
     ]
    }
   ],
   "source": [
    "parser = argparse.ArgumentParser(\n",
    "    description='Instance Type Prediction using Ridle',\n",
    ")\n",
    "parser.add_argument('--dataset', nargs='?', default='Universities_DBpedia', type=str)\n",
    "#parser.add_argument('--dataset', nargs='?', default='umls', type=str)\n",
    "parser, unknown = parser.parse_known_args()\n",
    "\n",
    "# Load Representations\n",
    "print('Reading Data...')\n",
    "df = pd.read_csv('./dataset/{}/embedding.csv'.format(parser.dataset))\n",
    "\n",
    "# Load mapping\n",
    "if 'dbp' in parser.dataset.lower():\n",
    "    mapping = pd.read_json('./dataset/dbp_type_mapping.json')\n",
    "elif 'wd' in parser.dataset.lower() or 'wikidata' in parser.dataset.lower():\n",
    "    mapping = pd.read_json('./dataset/wd_mapping_type.json')\n",
    "else:\n",
    "    mapping = pd.read_json('./dataset/{}/type_mapping.json'.format(parser.dataset))\n",
    "\n",
    "# merge them\n",
    "print('Processing Data...')\n",
    "r = pd.merge(df, mapping, on='S')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fb21e75",
   "metadata": {},
   "source": [
    "### Loading and reading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f12f4e17",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data = pd.read_pickle('./dataset/{}/input_data_unclean.pkl'.format(parser.dataset))\n",
    "#input_data = pd.read_pickle('./dataset/{}/input_data_summary_full.pkl'.format(parser.dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b663201e",
   "metadata": {},
   "outputs": [],
   "source": [
    "non_empty = input_data[input_data.Summary!='']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7f9ba411",
   "metadata": {},
   "outputs": [],
   "source": [
    "r_copy = r.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c5aaa554",
   "metadata": {},
   "outputs": [],
   "source": [
    "r_new = r_copy[r_copy.S.isin(non_empty['S'].values)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b5f23bbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_new = input_data[input_data.S.isin(non_empty['S'].values)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e5c335e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = input_new['Summary']\n",
    "sentences = [\"\" + temp + \"\" for temp in text]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8b24136c",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = r_new.drop(['S', 'Class'], axis=1).values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3c497b4",
   "metadata": {},
   "source": [
    "#### Creating sentence embeddings and concatenated vectors\n",
    "If you want to try out a different Sentece Embedding Model, you can change the model name in the cell below. For a list of all the pretrained models visit : https://www.sbert.net/docs/pretrained_models.html. The basic tests are run on the 'all-MiniLM-L6-v2' pretrained model, which is also the default model for the Sentence_Embedder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7f9bfcf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_embeddings import Sentence_Embedder\n",
    "#s = Sentence_Embedder(model_name=\"all-mpnet-base-v2\")\n",
    "s = Sentence_Embedder(model_name=\"all-MiniLM-L6-v2\")\n",
    "embeddings = s.embed(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9aca4cbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = np.array(embeddings)\n",
    "i = 0\n",
    "dict_embeddings = {}\n",
    "for entity in input_new[\"S\"]:\n",
    "    dict_embeddings[entity] = [embeddings[i]]\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3dc0a8e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = np.array(inputs)\n",
    "ridle_dict = {}\n",
    "i=0\n",
    "for entity in r_new['S']:\n",
    "    ridle_dict[entity] = [inputs[i]]\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8422be25",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "ds = [ridle_dict, dict_embeddings]\n",
    "d = {}\n",
    "for k in ridle_dict.keys():\n",
    "    d[k] = tuple(d[k] for d in ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4fc09ff9",
   "metadata": {},
   "outputs": [],
   "source": [
    "conc_input =  []\n",
    "for key in d:\n",
    "    conc_input.append(np.concatenate((d[key][0][0], d[key][1][0])))\n",
    "conc_input = np.array(conc_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "afa84241",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29897"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb_array = np.array(embeddings)\n",
    "len(emb_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6ba3ae6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "54"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(conc_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "512972f3",
   "metadata": {},
   "source": [
    "# Concatenated Vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "14507e42",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training...\n",
      "Epoch 1/100\n",
      "94/94 [==============================] - 1s 3ms/step - loss: 0.0556 - accuracy: 0.6443 - val_loss: 0.0136 - val_accuracy: 0.7910\n",
      "Epoch 2/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.0101 - accuracy: 0.6454 - val_loss: 0.0132 - val_accuracy: 0.5729\n",
      "Epoch 3/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.0098 - accuracy: 0.5415 - val_loss: 0.0134 - val_accuracy: 0.6165\n",
      "Epoch 4/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.0094 - accuracy: 0.5317 - val_loss: 0.0127 - val_accuracy: 0.5008\n",
      "Epoch 5/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.0088 - accuracy: 0.4637 - val_loss: 0.0132 - val_accuracy: 0.5293\n",
      "Epoch 6/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.0085 - accuracy: 0.5424 - val_loss: 0.0123 - val_accuracy: 0.5263\n",
      "Epoch 7/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.0081 - accuracy: 0.3995 - val_loss: 0.0120 - val_accuracy: 0.5173\n",
      "Epoch 8/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.0073 - accuracy: 0.3937 - val_loss: 0.0125 - val_accuracy: 0.4406\n",
      "Epoch 9/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.0069 - accuracy: 0.4485 - val_loss: 0.0117 - val_accuracy: 0.2286\n",
      "Epoch 10/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.0063 - accuracy: 0.2966 - val_loss: 0.0124 - val_accuracy: 0.4195\n",
      "Epoch 11/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.0056 - accuracy: 0.3186 - val_loss: 0.0132 - val_accuracy: 0.5489\n",
      "Epoch 12/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.0052 - accuracy: 0.4326 - val_loss: 0.0124 - val_accuracy: 0.2722\n",
      "Epoch 13/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.0046 - accuracy: 0.2740 - val_loss: 0.0135 - val_accuracy: 0.7263\n",
      "Epoch 14/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.0043 - accuracy: 0.5987 - val_loss: 0.0141 - val_accuracy: 0.4361\n",
      "Epoch 15/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.0039 - accuracy: 0.5666 - val_loss: 0.0141 - val_accuracy: 0.3985\n",
      "Epoch 16/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.0037 - accuracy: 0.4976 - val_loss: 0.0156 - val_accuracy: 0.5955\n",
      "Epoch 17/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.0033 - accuracy: 0.6129 - val_loss: 0.0164 - val_accuracy: 0.6917\n",
      "Epoch 18/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.0032 - accuracy: 0.6847 - val_loss: 0.0152 - val_accuracy: 0.6556\n",
      "Epoch 19/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.0027 - accuracy: 0.7798 - val_loss: 0.0167 - val_accuracy: 0.6346\n",
      "Epoch 20/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.0025 - accuracy: 0.5916 - val_loss: 0.0167 - val_accuracy: 0.7504\n",
      "Epoch 21/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.0024 - accuracy: 0.7529 - val_loss: 0.0190 - val_accuracy: 0.6962\n",
      "Epoch 22/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.0020 - accuracy: 0.6473 - val_loss: 0.0182 - val_accuracy: 0.6692\n",
      "Epoch 23/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.0020 - accuracy: 0.7357 - val_loss: 0.0196 - val_accuracy: 0.5744\n",
      "Epoch 24/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.0018 - accuracy: 0.6700 - val_loss: 0.0195 - val_accuracy: 0.8481\n",
      "Epoch 25/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.0015 - accuracy: 0.8192 - val_loss: 0.0205 - val_accuracy: 0.7805\n",
      "Epoch 26/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.0015 - accuracy: 0.7524 - val_loss: 0.0209 - val_accuracy: 0.7263\n",
      "Epoch 27/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.0013 - accuracy: 0.7885 - val_loss: 0.0211 - val_accuracy: 0.7639\n",
      "Epoch 28/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.0012 - accuracy: 0.7566 - val_loss: 0.0212 - val_accuracy: 0.6917\n",
      "Epoch 29/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 9.7473e-04 - accuracy: 0.7297 - val_loss: 0.0211 - val_accuracy: 0.6180\n",
      "Epoch 30/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.0010 - accuracy: 0.7283 - val_loss: 0.0213 - val_accuracy: 0.8211\n",
      "Epoch 31/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 8.2100e-04 - accuracy: 0.7449 - val_loss: 0.0221 - val_accuracy: 0.8301\n",
      "Epoch 32/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 7.8277e-04 - accuracy: 0.7576 - val_loss: 0.0218 - val_accuracy: 0.7248\n",
      "Epoch 33/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 6.0528e-04 - accuracy: 0.7185 - val_loss: 0.0230 - val_accuracy: 0.7684\n",
      "Epoch 34/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 6.1183e-04 - accuracy: 0.7412 - val_loss: 0.0234 - val_accuracy: 0.7880\n",
      "Epoch 35/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 6.1817e-04 - accuracy: 0.7479 - val_loss: 0.0238 - val_accuracy: 0.6301\n",
      "Epoch 36/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 4.2441e-04 - accuracy: 0.6812 - val_loss: 0.0242 - val_accuracy: 0.7353\n",
      "Epoch 37/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 3.4826e-04 - accuracy: 0.7148 - val_loss: 0.0236 - val_accuracy: 0.7564\n",
      "Epoch 38/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 3.0127e-04 - accuracy: 0.7223 - val_loss: 0.0242 - val_accuracy: 0.7744\n",
      "Epoch 39/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 2.6662e-04 - accuracy: 0.7061 - val_loss: 0.0252 - val_accuracy: 0.6842\n",
      "Epoch 40/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 2.3711e-04 - accuracy: 0.6795 - val_loss: 0.0242 - val_accuracy: 0.7368\n",
      "Epoch 41/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 2.2062e-04 - accuracy: 0.6849 - val_loss: 0.0249 - val_accuracy: 0.6647\n",
      "Epoch 42/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 1.9679e-04 - accuracy: 0.6702 - val_loss: 0.0253 - val_accuracy: 0.6947\n",
      "Epoch 43/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 2.0861e-04 - accuracy: 0.6603 - val_loss: 0.0255 - val_accuracy: 0.6992\n",
      "Epoch 44/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 1.5443e-04 - accuracy: 0.6490 - val_loss: 0.0268 - val_accuracy: 0.6797\n",
      "Epoch 45/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 1.4414e-04 - accuracy: 0.6339 - val_loss: 0.0270 - val_accuracy: 0.6722\n",
      "Epoch 46/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 1.2830e-04 - accuracy: 0.7124 - val_loss: 0.0264 - val_accuracy: 0.6647\n",
      "Epoch 47/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 1.1018e-04 - accuracy: 0.6296 - val_loss: 0.0267 - val_accuracy: 0.7143\n",
      "Epoch 48/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 9.6475e-05 - accuracy: 0.6399 - val_loss: 0.0266 - val_accuracy: 0.6662\n",
      "Epoch 49/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 8.8970e-05 - accuracy: 0.6332 - val_loss: 0.0270 - val_accuracy: 0.6872\n",
      "Epoch 50/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 8.9869e-05 - accuracy: 0.6399 - val_loss: 0.0278 - val_accuracy: 0.6481\n",
      "Epoch 51/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 7.5367e-05 - accuracy: 0.6389 - val_loss: 0.0281 - val_accuracy: 0.6271\n",
      "Epoch 52/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 6.5926e-05 - accuracy: 0.5968 - val_loss: 0.0288 - val_accuracy: 0.6406\n",
      "Epoch 53/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 6.2235e-05 - accuracy: 0.6366 - val_loss: 0.0279 - val_accuracy: 0.6737\n",
      "Epoch 54/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 5.9339e-05 - accuracy: 0.6094 - val_loss: 0.0276 - val_accuracy: 0.6391\n",
      "Epoch 55/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 5.5050e-05 - accuracy: 0.5888 - val_loss: 0.0281 - val_accuracy: 0.6271\n",
      "Epoch 56/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 5.3569e-05 - accuracy: 0.5850 - val_loss: 0.0285 - val_accuracy: 0.6496\n",
      "Epoch 57/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 4.6831e-05 - accuracy: 0.5861 - val_loss: 0.0289 - val_accuracy: 0.6120\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 4.0936e-05 - accuracy: 0.5903 - val_loss: 0.0290 - val_accuracy: 0.5955\n",
      "Epoch 59/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 4.6413e-05 - accuracy: 0.5977 - val_loss: 0.0295 - val_accuracy: 0.6090\n",
      "Epoch 60/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 3.5224e-05 - accuracy: 0.5779 - val_loss: 0.0297 - val_accuracy: 0.5835\n",
      "Epoch 61/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 3.3429e-05 - accuracy: 0.5522 - val_loss: 0.0298 - val_accuracy: 0.6331\n",
      "Epoch 62/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 3.0542e-05 - accuracy: 0.5890 - val_loss: 0.0300 - val_accuracy: 0.5895\n",
      "Epoch 63/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 2.9305e-05 - accuracy: 0.5637 - val_loss: 0.0304 - val_accuracy: 0.6241\n",
      "Epoch 64/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 2.7689e-05 - accuracy: 0.5649 - val_loss: 0.0303 - val_accuracy: 0.5910\n",
      "Epoch 65/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 2.5179e-05 - accuracy: 0.5556 - val_loss: 0.0309 - val_accuracy: 0.5955\n",
      "Epoch 66/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 2.2624e-05 - accuracy: 0.5642 - val_loss: 0.0313 - val_accuracy: 0.5880\n",
      "Epoch 67/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 2.2150e-05 - accuracy: 0.5494 - val_loss: 0.0309 - val_accuracy: 0.6120\n",
      "Epoch 68/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 2.1123e-05 - accuracy: 0.5525 - val_loss: 0.0316 - val_accuracy: 0.5925\n",
      "Epoch 69/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 2.0276e-05 - accuracy: 0.5552 - val_loss: 0.0312 - val_accuracy: 0.5970\n",
      "Epoch 70/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 1.6927e-05 - accuracy: 0.5429 - val_loss: 0.0317 - val_accuracy: 0.5293\n",
      "Epoch 71/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 1.6879e-05 - accuracy: 0.5258 - val_loss: 0.0316 - val_accuracy: 0.6150\n",
      "Epoch 72/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 1.5777e-05 - accuracy: 0.5348 - val_loss: 0.0321 - val_accuracy: 0.5549\n",
      "Epoch 73/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 1.4867e-05 - accuracy: 0.5537 - val_loss: 0.0325 - val_accuracy: 0.5910\n",
      "Epoch 74/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 1.4495e-05 - accuracy: 0.5487 - val_loss: 0.0321 - val_accuracy: 0.5368\n",
      "Epoch 75/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 1.3618e-05 - accuracy: 0.5016 - val_loss: 0.0324 - val_accuracy: 0.5744\n",
      "Epoch 76/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 1.2152e-05 - accuracy: 0.5388 - val_loss: 0.0332 - val_accuracy: 0.5624\n",
      "Epoch 77/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 1.1909e-05 - accuracy: 0.5347 - val_loss: 0.0329 - val_accuracy: 0.5474\n",
      "Epoch 78/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 1.0877e-05 - accuracy: 0.5352 - val_loss: 0.0332 - val_accuracy: 0.5429\n",
      "Epoch 79/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 9.9800e-06 - accuracy: 0.5038 - val_loss: 0.0333 - val_accuracy: 0.5774\n",
      "Epoch 80/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 9.6977e-06 - accuracy: 0.5282 - val_loss: 0.0334 - val_accuracy: 0.5338\n",
      "Epoch 81/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 9.0085e-06 - accuracy: 0.5171 - val_loss: 0.0339 - val_accuracy: 0.5368\n",
      "Epoch 82/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 8.7819e-06 - accuracy: 0.5298 - val_loss: 0.0342 - val_accuracy: 0.5368\n",
      "Epoch 83/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 8.0679e-06 - accuracy: 0.5018 - val_loss: 0.0341 - val_accuracy: 0.5368\n",
      "Epoch 84/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 7.7315e-06 - accuracy: 0.5116 - val_loss: 0.0342 - val_accuracy: 0.5068\n",
      "Epoch 85/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 7.3008e-06 - accuracy: 0.4982 - val_loss: 0.0348 - val_accuracy: 0.5549\n",
      "Epoch 86/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 6.8496e-06 - accuracy: 0.5053 - val_loss: 0.0345 - val_accuracy: 0.5444\n",
      "Epoch 87/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 6.4921e-06 - accuracy: 0.4962 - val_loss: 0.0348 - val_accuracy: 0.5233\n",
      "Epoch 88/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 6.0404e-06 - accuracy: 0.5135 - val_loss: 0.0349 - val_accuracy: 0.5308\n",
      "Epoch 89/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 5.6202e-06 - accuracy: 0.5079 - val_loss: 0.0355 - val_accuracy: 0.5203\n",
      "Epoch 90/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 5.4181e-06 - accuracy: 0.4977 - val_loss: 0.0354 - val_accuracy: 0.5143\n",
      "Epoch 91/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 5.1363e-06 - accuracy: 0.4931 - val_loss: 0.0358 - val_accuracy: 0.5128\n",
      "Epoch 92/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 4.8010e-06 - accuracy: 0.5026 - val_loss: 0.0351 - val_accuracy: 0.5143\n",
      "Epoch 93/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 4.6650e-06 - accuracy: 0.4889 - val_loss: 0.0358 - val_accuracy: 0.5068\n",
      "Epoch 94/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 4.3508e-06 - accuracy: 0.4954 - val_loss: 0.0356 - val_accuracy: 0.5188\n",
      "Epoch 95/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 4.0359e-06 - accuracy: 0.4807 - val_loss: 0.0364 - val_accuracy: 0.5158\n",
      "Epoch 96/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 3.8683e-06 - accuracy: 0.4770 - val_loss: 0.0370 - val_accuracy: 0.5038\n",
      "Epoch 97/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 3.8607e-06 - accuracy: 0.4765 - val_loss: 0.0366 - val_accuracy: 0.5128\n",
      "Epoch 98/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 3.5211e-06 - accuracy: 0.4864 - val_loss: 0.0362 - val_accuracy: 0.5143\n",
      "Epoch 99/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 3.2954e-06 - accuracy: 0.4764 - val_loss: 0.0369 - val_accuracy: 0.5038\n",
      "Epoch 100/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 3.1872e-06 - accuracy: 0.4600 - val_loss: 0.0368 - val_accuracy: 0.5128\n",
      "Score for fold 1 : loss of 0.03683343902230263 ; F1-Macro: 0.5827684324335776 F1-Micro: 0.9971788602595449\n",
      "Training...\n",
      "Epoch 1/100\n",
      "94/94 [==============================] - 1s 2ms/step - loss: 0.0624 - accuracy: 0.4459 - val_loss: 0.0061 - val_accuracy: 0.7429\n",
      "Epoch 2/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.0109 - accuracy: 0.6480 - val_loss: 0.0061 - val_accuracy: 0.5985\n",
      "Epoch 3/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.0106 - accuracy: 0.5068 - val_loss: 0.0061 - val_accuracy: 0.4917\n",
      "Epoch 4/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.0101 - accuracy: 0.4154 - val_loss: 0.0058 - val_accuracy: 0.3805\n",
      "Epoch 5/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.0098 - accuracy: 0.4496 - val_loss: 0.0062 - val_accuracy: 0.3684\n",
      "Epoch 6/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.0092 - accuracy: 0.4060 - val_loss: 0.0063 - val_accuracy: 0.4105\n",
      "Epoch 7/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.0088 - accuracy: 0.3340 - val_loss: 0.0064 - val_accuracy: 0.0226\n",
      "Epoch 8/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.0083 - accuracy: 0.2082 - val_loss: 0.0061 - val_accuracy: 0.2165\n",
      "Epoch 9/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.0077 - accuracy: 0.2904 - val_loss: 0.0072 - val_accuracy: 0.4226\n",
      "Epoch 10/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.0069 - accuracy: 0.1911 - val_loss: 0.0067 - val_accuracy: 0.1654\n",
      "Epoch 11/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.0065 - accuracy: 0.1584 - val_loss: 0.0073 - val_accuracy: 0.0812\n",
      "Epoch 12/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.0060 - accuracy: 0.1357 - val_loss: 0.0069 - val_accuracy: 0.0962\n",
      "Epoch 13/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.0051 - accuracy: 0.0989 - val_loss: 0.0077 - val_accuracy: 0.0241\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.0051 - accuracy: 0.1171 - val_loss: 0.0070 - val_accuracy: 0.1278\n",
      "Epoch 15/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.0045 - accuracy: 0.1178 - val_loss: 0.0070 - val_accuracy: 0.2105\n",
      "Epoch 16/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.0040 - accuracy: 0.1221 - val_loss: 0.0076 - val_accuracy: 0.0647\n",
      "Epoch 17/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.0038 - accuracy: 0.1056 - val_loss: 0.0080 - val_accuracy: 0.1880\n",
      "Epoch 18/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.0034 - accuracy: 0.1688 - val_loss: 0.0084 - val_accuracy: 0.0286\n",
      "Epoch 19/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.0030 - accuracy: 0.0979 - val_loss: 0.0079 - val_accuracy: 0.1549\n",
      "Epoch 20/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.0028 - accuracy: 0.0996 - val_loss: 0.0081 - val_accuracy: 0.1519\n",
      "Epoch 21/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.0023 - accuracy: 0.1158 - val_loss: 0.0092 - val_accuracy: 0.2406\n",
      "Epoch 22/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.0025 - accuracy: 0.0757 - val_loss: 0.0093 - val_accuracy: 0.0902\n",
      "Epoch 23/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.0020 - accuracy: 0.0871 - val_loss: 0.0085 - val_accuracy: 0.1158\n",
      "Epoch 24/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.0018 - accuracy: 0.1165 - val_loss: 0.0086 - val_accuracy: 0.1925\n",
      "Epoch 25/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.0016 - accuracy: 0.0944 - val_loss: 0.0095 - val_accuracy: 0.0571\n",
      "Epoch 26/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.0015 - accuracy: 0.0902 - val_loss: 0.0096 - val_accuracy: 0.2030\n",
      "Epoch 27/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.0013 - accuracy: 0.1146 - val_loss: 0.0100 - val_accuracy: 0.1308\n",
      "Epoch 28/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.0011 - accuracy: 0.1323 - val_loss: 0.0108 - val_accuracy: 0.0436\n",
      "Epoch 29/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.0011 - accuracy: 0.1225 - val_loss: 0.0095 - val_accuracy: 0.1624\n",
      "Epoch 30/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 8.6381e-04 - accuracy: 0.1709 - val_loss: 0.0105 - val_accuracy: 0.0842\n",
      "Epoch 31/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 7.8206e-04 - accuracy: 0.0907 - val_loss: 0.0112 - val_accuracy: 0.0692\n",
      "Epoch 32/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 7.0795e-04 - accuracy: 0.1315 - val_loss: 0.0105 - val_accuracy: 0.1549\n",
      "Epoch 33/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 5.2195e-04 - accuracy: 0.1051 - val_loss: 0.0110 - val_accuracy: 0.1008\n",
      "Epoch 34/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 5.5051e-04 - accuracy: 0.0807 - val_loss: 0.0112 - val_accuracy: 0.0647\n",
      "Epoch 35/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 4.3044e-04 - accuracy: 0.1340 - val_loss: 0.0117 - val_accuracy: 0.0586\n",
      "Epoch 36/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 3.7950e-04 - accuracy: 0.1233 - val_loss: 0.0117 - val_accuracy: 0.1398\n",
      "Epoch 37/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 3.4805e-04 - accuracy: 0.1412 - val_loss: 0.0120 - val_accuracy: 0.0451\n",
      "Epoch 38/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 3.3236e-04 - accuracy: 0.1220 - val_loss: 0.0125 - val_accuracy: 0.0571\n",
      "Epoch 39/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 2.3796e-04 - accuracy: 0.1472 - val_loss: 0.0119 - val_accuracy: 0.1218\n",
      "Epoch 40/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 2.0215e-04 - accuracy: 0.1363 - val_loss: 0.0126 - val_accuracy: 0.1278\n",
      "Epoch 41/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 1.9208e-04 - accuracy: 0.1607 - val_loss: 0.0131 - val_accuracy: 0.1233\n",
      "Epoch 42/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 1.8953e-04 - accuracy: 0.1714 - val_loss: 0.0127 - val_accuracy: 0.2000\n",
      "Epoch 43/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 1.4600e-04 - accuracy: 0.1746 - val_loss: 0.0130 - val_accuracy: 0.1895\n",
      "Epoch 44/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 1.3426e-04 - accuracy: 0.1928 - val_loss: 0.0134 - val_accuracy: 0.1609\n",
      "Epoch 45/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 1.2528e-04 - accuracy: 0.1993 - val_loss: 0.0133 - val_accuracy: 0.2075\n",
      "Epoch 46/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 1.1013e-04 - accuracy: 0.2244 - val_loss: 0.0137 - val_accuracy: 0.2286\n",
      "Epoch 47/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 1.0694e-04 - accuracy: 0.2368 - val_loss: 0.0132 - val_accuracy: 0.2947\n",
      "Epoch 48/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 1.0477e-04 - accuracy: 0.2396 - val_loss: 0.0141 - val_accuracy: 0.1549\n",
      "Epoch 49/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 8.6051e-05 - accuracy: 0.2456 - val_loss: 0.0139 - val_accuracy: 0.2301\n",
      "Epoch 50/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 8.0596e-05 - accuracy: 0.2299 - val_loss: 0.0141 - val_accuracy: 0.2451\n",
      "Epoch 51/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 7.1783e-05 - accuracy: 0.2665 - val_loss: 0.0142 - val_accuracy: 0.2752\n",
      "Epoch 52/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 6.4804e-05 - accuracy: 0.2752 - val_loss: 0.0145 - val_accuracy: 0.2707\n",
      "Epoch 53/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 6.1879e-05 - accuracy: 0.3008 - val_loss: 0.0144 - val_accuracy: 0.2857\n",
      "Epoch 54/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 5.7038e-05 - accuracy: 0.3021 - val_loss: 0.0145 - val_accuracy: 0.3098\n",
      "Epoch 55/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 5.1149e-05 - accuracy: 0.3158 - val_loss: 0.0146 - val_accuracy: 0.2962\n",
      "Epoch 56/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 4.7889e-05 - accuracy: 0.3278 - val_loss: 0.0148 - val_accuracy: 0.3008\n",
      "Epoch 57/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 4.5676e-05 - accuracy: 0.2946 - val_loss: 0.0145 - val_accuracy: 0.3850\n",
      "Epoch 58/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 4.2132e-05 - accuracy: 0.3422 - val_loss: 0.0156 - val_accuracy: 0.2496\n",
      "Epoch 59/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 4.2413e-05 - accuracy: 0.3268 - val_loss: 0.0156 - val_accuracy: 0.3278\n",
      "Epoch 60/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 3.6677e-05 - accuracy: 0.3527 - val_loss: 0.0154 - val_accuracy: 0.3308\n",
      "Epoch 61/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 3.3926e-05 - accuracy: 0.3520 - val_loss: 0.0155 - val_accuracy: 0.3188\n",
      "Epoch 62/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 3.4770e-05 - accuracy: 0.3515 - val_loss: 0.0158 - val_accuracy: 0.3489\n",
      "Epoch 63/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 2.9514e-05 - accuracy: 0.3721 - val_loss: 0.0160 - val_accuracy: 0.3338\n",
      "Epoch 64/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 2.7805e-05 - accuracy: 0.3718 - val_loss: 0.0157 - val_accuracy: 0.3639\n",
      "Epoch 65/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 2.5622e-05 - accuracy: 0.3808 - val_loss: 0.0160 - val_accuracy: 0.3338\n",
      "Epoch 66/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 2.4878e-05 - accuracy: 0.3835 - val_loss: 0.0160 - val_accuracy: 0.3429\n",
      "Epoch 67/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 2.2229e-05 - accuracy: 0.3943 - val_loss: 0.0158 - val_accuracy: 0.3549\n",
      "Epoch 68/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 2.1666e-05 - accuracy: 0.3851 - val_loss: 0.0164 - val_accuracy: 0.3383\n",
      "Epoch 69/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 1.9639e-05 - accuracy: 0.3913 - val_loss: 0.0162 - val_accuracy: 0.3579\n",
      "Epoch 70/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 1.9430e-05 - accuracy: 0.3915 - val_loss: 0.0164 - val_accuracy: 0.3835\n",
      "Epoch 71/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 1.7609e-05 - accuracy: 0.3963 - val_loss: 0.0166 - val_accuracy: 0.3910\n",
      "Epoch 72/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 1.6492e-05 - accuracy: 0.4084 - val_loss: 0.0167 - val_accuracy: 0.3895\n",
      "Epoch 73/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 1.5623e-05 - accuracy: 0.4396 - val_loss: 0.0168 - val_accuracy: 0.4105\n",
      "Epoch 74/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 1.4979e-05 - accuracy: 0.4154 - val_loss: 0.0173 - val_accuracy: 0.3564\n",
      "Epoch 75/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 1.3632e-05 - accuracy: 0.4206 - val_loss: 0.0169 - val_accuracy: 0.3955\n",
      "Epoch 76/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 1.3050e-05 - accuracy: 0.4159 - val_loss: 0.0170 - val_accuracy: 0.4316\n",
      "Epoch 77/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 1.2515e-05 - accuracy: 0.4388 - val_loss: 0.0174 - val_accuracy: 0.3714\n",
      "Epoch 78/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 1.1930e-05 - accuracy: 0.4428 - val_loss: 0.0173 - val_accuracy: 0.3820\n",
      "Epoch 79/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 1.0499e-05 - accuracy: 0.4209 - val_loss: 0.0180 - val_accuracy: 0.3714\n",
      "Epoch 80/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 1.0788e-05 - accuracy: 0.4306 - val_loss: 0.0173 - val_accuracy: 0.4511\n",
      "Epoch 81/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 9.6019e-06 - accuracy: 0.4418 - val_loss: 0.0176 - val_accuracy: 0.4391\n",
      "Epoch 82/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 9.4330e-06 - accuracy: 0.4523 - val_loss: 0.0178 - val_accuracy: 0.4556\n",
      "Epoch 83/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 8.5684e-06 - accuracy: 0.4580 - val_loss: 0.0176 - val_accuracy: 0.4135\n",
      "Epoch 84/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 8.0153e-06 - accuracy: 0.4429 - val_loss: 0.0179 - val_accuracy: 0.4015\n",
      "Epoch 85/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 7.5106e-06 - accuracy: 0.4411 - val_loss: 0.0180 - val_accuracy: 0.4195\n",
      "Epoch 86/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 7.0478e-06 - accuracy: 0.4436 - val_loss: 0.0182 - val_accuracy: 0.4271\n",
      "Epoch 87/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 6.8060e-06 - accuracy: 0.4769 - val_loss: 0.0181 - val_accuracy: 0.4511\n",
      "Epoch 88/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 6.9025e-06 - accuracy: 0.4692 - val_loss: 0.0183 - val_accuracy: 0.4617\n",
      "Epoch 89/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 6.1038e-06 - accuracy: 0.4642 - val_loss: 0.0184 - val_accuracy: 0.4256\n",
      "Epoch 90/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 5.6433e-06 - accuracy: 0.4618 - val_loss: 0.0184 - val_accuracy: 0.4406\n",
      "Epoch 91/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 5.5063e-06 - accuracy: 0.4585 - val_loss: 0.0186 - val_accuracy: 0.4481\n",
      "Epoch 92/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 5.1298e-06 - accuracy: 0.4718 - val_loss: 0.0186 - val_accuracy: 0.4602\n",
      "Epoch 93/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 4.8367e-06 - accuracy: 0.4712 - val_loss: 0.0185 - val_accuracy: 0.4812\n",
      "Epoch 94/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 4.7688e-06 - accuracy: 0.4867 - val_loss: 0.0185 - val_accuracy: 0.4737\n",
      "Epoch 95/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 4.3642e-06 - accuracy: 0.4673 - val_loss: 0.0192 - val_accuracy: 0.4481\n",
      "Epoch 96/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 4.2798e-06 - accuracy: 0.4799 - val_loss: 0.0194 - val_accuracy: 0.4406\n",
      "Epoch 97/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 3.9262e-06 - accuracy: 0.4730 - val_loss: 0.0193 - val_accuracy: 0.4511\n",
      "Epoch 98/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 3.7339e-06 - accuracy: 0.4708 - val_loss: 0.0192 - val_accuracy: 0.4707\n",
      "Epoch 99/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 3.6813e-06 - accuracy: 0.4812 - val_loss: 0.0192 - val_accuracy: 0.4647\n",
      "Epoch 100/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 3.4781e-06 - accuracy: 0.4832 - val_loss: 0.0193 - val_accuracy: 0.4602\n",
      "Score for fold 2 : loss of 0.01928543485701084 ; F1-Macro: 0.9164782717910073 F1-Micro: 0.9988721804511278\n",
      "Training...\n",
      "Epoch 1/100\n",
      "94/94 [==============================] - 1s 2ms/step - loss: 0.0670 - accuracy: 0.3963 - val_loss: 0.0279 - val_accuracy: 0.7368\n",
      "Epoch 2/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.0087 - accuracy: 0.6219 - val_loss: 0.0269 - val_accuracy: 0.5489\n",
      "Epoch 3/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.0085 - accuracy: 0.5166 - val_loss: 0.0261 - val_accuracy: 0.5669\n",
      "Epoch 4/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.0081 - accuracy: 0.4927 - val_loss: 0.0264 - val_accuracy: 0.3398\n",
      "Epoch 5/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.0078 - accuracy: 0.3500 - val_loss: 0.0259 - val_accuracy: 0.5338\n",
      "Epoch 6/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.0074 - accuracy: 0.4194 - val_loss: 0.0258 - val_accuracy: 0.4481\n",
      "Epoch 7/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.0073 - accuracy: 0.3621 - val_loss: 0.0263 - val_accuracy: 0.5850\n",
      "Epoch 8/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.0067 - accuracy: 0.4155 - val_loss: 0.0272 - val_accuracy: 0.4030\n",
      "Epoch 9/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.0061 - accuracy: 0.3900 - val_loss: 0.0251 - val_accuracy: 0.4511\n",
      "Epoch 10/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.0057 - accuracy: 0.4037 - val_loss: 0.0251 - val_accuracy: 0.2827\n",
      "Epoch 11/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.0052 - accuracy: 0.3479 - val_loss: 0.0257 - val_accuracy: 0.4195\n",
      "Epoch 12/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.0046 - accuracy: 0.3118 - val_loss: 0.0274 - val_accuracy: 0.3564\n",
      "Epoch 13/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.0043 - accuracy: 0.2891 - val_loss: 0.0286 - val_accuracy: 0.2075\n",
      "Epoch 14/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.0039 - accuracy: 0.3233 - val_loss: 0.0289 - val_accuracy: 0.2511\n",
      "Epoch 15/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.0034 - accuracy: 0.2857 - val_loss: 0.0274 - val_accuracy: 0.3278\n",
      "Epoch 16/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.0033 - accuracy: 0.3051 - val_loss: 0.0301 - val_accuracy: 0.4060\n",
      "Epoch 17/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.0028 - accuracy: 0.3061 - val_loss: 0.0339 - val_accuracy: 0.2150\n",
      "Epoch 18/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.0026 - accuracy: 0.3168 - val_loss: 0.0315 - val_accuracy: 0.3083\n",
      "Epoch 19/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.0022 - accuracy: 0.3124 - val_loss: 0.0333 - val_accuracy: 0.3714\n",
      "Epoch 20/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.0022 - accuracy: 0.2516 - val_loss: 0.0395 - val_accuracy: 0.1353\n",
      "Epoch 21/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.0020 - accuracy: 0.3114 - val_loss: 0.0346 - val_accuracy: 0.4707\n",
      "Epoch 22/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.0018 - accuracy: 0.3300 - val_loss: 0.0364 - val_accuracy: 0.4211\n",
      "Epoch 23/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.0016 - accuracy: 0.3238 - val_loss: 0.0400 - val_accuracy: 0.2090\n",
      "Epoch 24/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.0015 - accuracy: 0.2996 - val_loss: 0.0409 - val_accuracy: 0.2632\n",
      "Epoch 25/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.0013 - accuracy: 0.3089 - val_loss: 0.0379 - val_accuracy: 0.2586\n",
      "Epoch 26/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94/94 [==============================] - 0s 1ms/step - loss: 0.0012 - accuracy: 0.2399 - val_loss: 0.0413 - val_accuracy: 0.2316\n",
      "Epoch 27/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.0011 - accuracy: 0.2732 - val_loss: 0.0431 - val_accuracy: 0.2481\n",
      "Epoch 28/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.0010 - accuracy: 0.2725 - val_loss: 0.0419 - val_accuracy: 0.2872\n",
      "Epoch 29/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 9.5150e-04 - accuracy: 0.2623 - val_loss: 0.0446 - val_accuracy: 0.2015\n",
      "Epoch 30/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 7.7687e-04 - accuracy: 0.2720 - val_loss: 0.0469 - val_accuracy: 0.1910\n",
      "Epoch 31/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 7.5581e-04 - accuracy: 0.2211 - val_loss: 0.0454 - val_accuracy: 0.1789\n",
      "Epoch 32/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 6.3955e-04 - accuracy: 0.2363 - val_loss: 0.0457 - val_accuracy: 0.2436\n",
      "Epoch 33/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 5.2392e-04 - accuracy: 0.2620 - val_loss: 0.0469 - val_accuracy: 0.2075\n",
      "Epoch 34/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 4.2969e-04 - accuracy: 0.1977 - val_loss: 0.0472 - val_accuracy: 0.2195\n",
      "Epoch 35/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 3.9041e-04 - accuracy: 0.2508 - val_loss: 0.0443 - val_accuracy: 0.2256\n",
      "Epoch 36/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 4.1163e-04 - accuracy: 0.2030 - val_loss: 0.0503 - val_accuracy: 0.2090\n",
      "Epoch 37/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 3.1944e-04 - accuracy: 0.2394 - val_loss: 0.0474 - val_accuracy: 0.2647\n",
      "Epoch 38/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 2.5890e-04 - accuracy: 0.2376 - val_loss: 0.0486 - val_accuracy: 0.2571\n",
      "Epoch 39/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 2.2868e-04 - accuracy: 0.1926 - val_loss: 0.0505 - val_accuracy: 0.2316\n",
      "Epoch 40/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 1.8505e-04 - accuracy: 0.2003 - val_loss: 0.0533 - val_accuracy: 0.1985\n",
      "Epoch 41/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 1.8493e-04 - accuracy: 0.2451 - val_loss: 0.0514 - val_accuracy: 0.2150\n",
      "Epoch 42/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 1.4998e-04 - accuracy: 0.1916 - val_loss: 0.0533 - val_accuracy: 0.2376\n",
      "Epoch 43/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 1.3551e-04 - accuracy: 0.2812 - val_loss: 0.0532 - val_accuracy: 0.2722\n",
      "Epoch 44/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 1.2048e-04 - accuracy: 0.2675 - val_loss: 0.0537 - val_accuracy: 0.2692\n",
      "Epoch 45/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 1.0588e-04 - accuracy: 0.2491 - val_loss: 0.0542 - val_accuracy: 0.2135\n",
      "Epoch 46/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 9.4216e-05 - accuracy: 0.2394 - val_loss: 0.0559 - val_accuracy: 0.2406\n",
      "Epoch 47/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 9.6589e-05 - accuracy: 0.2503 - val_loss: 0.0566 - val_accuracy: 0.3008\n",
      "Epoch 48/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 8.4134e-05 - accuracy: 0.2657 - val_loss: 0.0568 - val_accuracy: 0.2917\n",
      "Epoch 49/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 7.8229e-05 - accuracy: 0.2600 - val_loss: 0.0570 - val_accuracy: 0.2782\n",
      "Epoch 50/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 7.6056e-05 - accuracy: 0.2734 - val_loss: 0.0563 - val_accuracy: 0.2526\n",
      "Epoch 51/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 7.0194e-05 - accuracy: 0.2896 - val_loss: 0.0562 - val_accuracy: 0.3414\n",
      "Epoch 52/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 5.6868e-05 - accuracy: 0.2618 - val_loss: 0.0572 - val_accuracy: 0.3323\n",
      "Epoch 53/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 5.1838e-05 - accuracy: 0.2924 - val_loss: 0.0577 - val_accuracy: 0.2902\n",
      "Epoch 54/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 4.6077e-05 - accuracy: 0.3003 - val_loss: 0.0594 - val_accuracy: 0.2662\n",
      "Epoch 55/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 4.4850e-05 - accuracy: 0.2794 - val_loss: 0.0588 - val_accuracy: 0.3128\n",
      "Epoch 56/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 4.0880e-05 - accuracy: 0.2909 - val_loss: 0.0606 - val_accuracy: 0.3128\n",
      "Epoch 57/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 3.6731e-05 - accuracy: 0.2891 - val_loss: 0.0604 - val_accuracy: 0.2977\n",
      "Epoch 58/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 3.5727e-05 - accuracy: 0.3034 - val_loss: 0.0611 - val_accuracy: 0.3248\n",
      "Epoch 59/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 3.2596e-05 - accuracy: 0.3074 - val_loss: 0.0615 - val_accuracy: 0.3398\n",
      "Epoch 60/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 2.9739e-05 - accuracy: 0.3046 - val_loss: 0.0613 - val_accuracy: 0.3173\n",
      "Epoch 61/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 2.7891e-05 - accuracy: 0.2959 - val_loss: 0.0615 - val_accuracy: 0.3038\n",
      "Epoch 62/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 2.5595e-05 - accuracy: 0.3014 - val_loss: 0.0618 - val_accuracy: 0.3579\n",
      "Epoch 63/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 2.4948e-05 - accuracy: 0.3093 - val_loss: 0.0629 - val_accuracy: 0.3233\n",
      "Epoch 64/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 2.2791e-05 - accuracy: 0.3054 - val_loss: 0.0640 - val_accuracy: 0.2632\n",
      "Epoch 65/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 2.1731e-05 - accuracy: 0.2926 - val_loss: 0.0634 - val_accuracy: 0.3459\n",
      "Epoch 66/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 1.9500e-05 - accuracy: 0.3278 - val_loss: 0.0631 - val_accuracy: 0.3128\n",
      "Epoch 67/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 1.8539e-05 - accuracy: 0.3185 - val_loss: 0.0644 - val_accuracy: 0.3519\n",
      "Epoch 68/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 1.6697e-05 - accuracy: 0.3161 - val_loss: 0.0646 - val_accuracy: 0.3474\n",
      "Epoch 69/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 1.6435e-05 - accuracy: 0.3178 - val_loss: 0.0663 - val_accuracy: 0.3323\n",
      "Epoch 70/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 1.5791e-05 - accuracy: 0.3231 - val_loss: 0.0647 - val_accuracy: 0.3564\n",
      "Epoch 71/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 1.4254e-05 - accuracy: 0.3335 - val_loss: 0.0663 - val_accuracy: 0.3459\n",
      "Epoch 72/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 1.3348e-05 - accuracy: 0.3233 - val_loss: 0.0665 - val_accuracy: 0.3895\n",
      "Epoch 73/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 1.2985e-05 - accuracy: 0.3215 - val_loss: 0.0663 - val_accuracy: 0.3579\n",
      "Epoch 74/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 1.1748e-05 - accuracy: 0.3272 - val_loss: 0.0673 - val_accuracy: 0.3504\n",
      "Epoch 75/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 1.1262e-05 - accuracy: 0.3465 - val_loss: 0.0682 - val_accuracy: 0.3489\n",
      "Epoch 76/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 1.0228e-05 - accuracy: 0.3290 - val_loss: 0.0690 - val_accuracy: 0.3594\n",
      "Epoch 77/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 9.9712e-06 - accuracy: 0.3290 - val_loss: 0.0688 - val_accuracy: 0.3474\n",
      "Epoch 78/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 9.3722e-06 - accuracy: 0.3554 - val_loss: 0.0688 - val_accuracy: 0.3474\n",
      "Epoch 79/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 8.6988e-06 - accuracy: 0.3317 - val_loss: 0.0698 - val_accuracy: 0.3654\n",
      "Epoch 80/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 8.2960e-06 - accuracy: 0.3619 - val_loss: 0.0704 - val_accuracy: 0.3444\n",
      "Epoch 81/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 7.7434e-06 - accuracy: 0.3500 - val_loss: 0.0705 - val_accuracy: 0.3353\n",
      "Epoch 82/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 7.5085e-06 - accuracy: 0.3327 - val_loss: 0.0702 - val_accuracy: 0.3639\n",
      "Epoch 83/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 7.1256e-06 - accuracy: 0.3437 - val_loss: 0.0712 - val_accuracy: 0.3684\n",
      "Epoch 84/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 6.5415e-06 - accuracy: 0.3559 - val_loss: 0.0712 - val_accuracy: 0.3579\n",
      "Epoch 85/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 6.1833e-06 - accuracy: 0.3464 - val_loss: 0.0710 - val_accuracy: 0.3609\n",
      "Epoch 86/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 6.1061e-06 - accuracy: 0.3420 - val_loss: 0.0716 - val_accuracy: 0.3549\n",
      "Epoch 87/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 5.4045e-06 - accuracy: 0.3434 - val_loss: 0.0726 - val_accuracy: 0.3203\n",
      "Epoch 88/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 5.3208e-06 - accuracy: 0.3236 - val_loss: 0.0739 - val_accuracy: 0.3579\n",
      "Epoch 89/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 4.8971e-06 - accuracy: 0.3683 - val_loss: 0.0719 - val_accuracy: 0.3865\n",
      "Epoch 90/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 4.7863e-06 - accuracy: 0.3574 - val_loss: 0.0735 - val_accuracy: 0.3549\n",
      "Epoch 91/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 4.5078e-06 - accuracy: 0.3509 - val_loss: 0.0745 - val_accuracy: 0.3564\n",
      "Epoch 92/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 4.4269e-06 - accuracy: 0.3470 - val_loss: 0.0742 - val_accuracy: 0.3789\n",
      "Epoch 93/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 3.9547e-06 - accuracy: 0.3657 - val_loss: 0.0732 - val_accuracy: 0.3714\n",
      "Epoch 94/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 4.2219e-06 - accuracy: 0.3564 - val_loss: 0.0751 - val_accuracy: 0.3729\n",
      "Epoch 95/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 3.6221e-06 - accuracy: 0.3731 - val_loss: 0.0744 - val_accuracy: 0.3714\n",
      "Epoch 96/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 3.5036e-06 - accuracy: 0.3360 - val_loss: 0.0754 - val_accuracy: 0.3789\n",
      "Epoch 97/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 3.1916e-06 - accuracy: 0.3776 - val_loss: 0.0754 - val_accuracy: 0.3609\n",
      "Epoch 98/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 3.0412e-06 - accuracy: 0.3414 - val_loss: 0.0755 - val_accuracy: 0.3805\n",
      "Epoch 99/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 2.9179e-06 - accuracy: 0.3474 - val_loss: 0.0760 - val_accuracy: 0.3805\n",
      "Epoch 100/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 2.7394e-06 - accuracy: 0.3544 - val_loss: 0.0774 - val_accuracy: 0.3609\n",
      "Score for fold 3 : loss of 0.07735494524240494 ; F1-Macro: 0.41547112507184797 F1-Micro: 0.9941652550348202\n",
      "Training...\n",
      "Epoch 1/100\n",
      "94/94 [==============================] - 1s 3ms/step - loss: 0.0631 - accuracy: 0.5609 - val_loss: 0.0064 - val_accuracy: 0.2992\n",
      "Epoch 2/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.0109 - accuracy: 0.3131 - val_loss: 0.0066 - val_accuracy: 0.2286\n",
      "Epoch 3/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.0105 - accuracy: 0.4017 - val_loss: 0.0065 - val_accuracy: 0.3820\n",
      "Epoch 4/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.0102 - accuracy: 0.4889 - val_loss: 0.0062 - val_accuracy: 0.2150\n",
      "Epoch 5/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.0096 - accuracy: 0.3788 - val_loss: 0.0061 - val_accuracy: 0.2632\n",
      "Epoch 6/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.0093 - accuracy: 0.3200 - val_loss: 0.0067 - val_accuracy: 0.1023\n",
      "Epoch 7/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.0088 - accuracy: 0.3226 - val_loss: 0.0054 - val_accuracy: 0.7083\n",
      "Epoch 8/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.0082 - accuracy: 0.4754 - val_loss: 0.0054 - val_accuracy: 0.3729\n",
      "Epoch 9/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.0076 - accuracy: 0.3723 - val_loss: 0.0060 - val_accuracy: 0.1820\n",
      "Epoch 10/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.0071 - accuracy: 0.4239 - val_loss: 0.0052 - val_accuracy: 0.6195\n",
      "Epoch 11/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.0066 - accuracy: 0.4155 - val_loss: 0.0066 - val_accuracy: 0.1669\n",
      "Epoch 12/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.0060 - accuracy: 0.4470 - val_loss: 0.0059 - val_accuracy: 0.6602\n",
      "Epoch 13/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.0055 - accuracy: 0.5835 - val_loss: 0.0054 - val_accuracy: 0.4602\n",
      "Epoch 14/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.0049 - accuracy: 0.5499 - val_loss: 0.0054 - val_accuracy: 0.5203\n",
      "Epoch 15/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.0046 - accuracy: 0.6247 - val_loss: 0.0054 - val_accuracy: 0.7098\n",
      "Epoch 16/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.0043 - accuracy: 0.6361 - val_loss: 0.0058 - val_accuracy: 0.3038\n",
      "Epoch 17/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.0038 - accuracy: 0.6473 - val_loss: 0.0062 - val_accuracy: 0.4992\n",
      "Epoch 18/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.0034 - accuracy: 0.6214 - val_loss: 0.0062 - val_accuracy: 0.6000\n",
      "Epoch 19/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.0032 - accuracy: 0.6406 - val_loss: 0.0065 - val_accuracy: 0.3624\n",
      "Epoch 20/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.0029 - accuracy: 0.6180 - val_loss: 0.0067 - val_accuracy: 0.5609\n",
      "Epoch 21/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.0028 - accuracy: 0.6556 - val_loss: 0.0066 - val_accuracy: 0.6586\n",
      "Epoch 22/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.0023 - accuracy: 0.7591 - val_loss: 0.0070 - val_accuracy: 0.6165\n",
      "Epoch 23/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.0021 - accuracy: 0.6705 - val_loss: 0.0068 - val_accuracy: 0.5955\n",
      "Epoch 24/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.0019 - accuracy: 0.7223 - val_loss: 0.0077 - val_accuracy: 0.7609\n",
      "Epoch 25/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.0017 - accuracy: 0.7554 - val_loss: 0.0082 - val_accuracy: 0.7564\n",
      "Epoch 26/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.0016 - accuracy: 0.7350 - val_loss: 0.0076 - val_accuracy: 0.7744\n",
      "Epoch 27/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.0014 - accuracy: 0.6891 - val_loss: 0.0076 - val_accuracy: 0.6180\n",
      "Epoch 28/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.0014 - accuracy: 0.7078 - val_loss: 0.0077 - val_accuracy: 0.7203\n",
      "Epoch 29/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.0011 - accuracy: 0.6946 - val_loss: 0.0079 - val_accuracy: 0.7383\n",
      "Epoch 30/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.0011 - accuracy: 0.7562 - val_loss: 0.0080 - val_accuracy: 0.6722\n",
      "Epoch 31/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 8.4702e-04 - accuracy: 0.7330 - val_loss: 0.0084 - val_accuracy: 0.6301\n",
      "Epoch 32/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 7.9244e-04 - accuracy: 0.6744 - val_loss: 0.0083 - val_accuracy: 0.8150\n",
      "Epoch 33/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 6.8029e-04 - accuracy: 0.7484 - val_loss: 0.0084 - val_accuracy: 0.6737\n",
      "Epoch 34/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 6.8910e-04 - accuracy: 0.7021 - val_loss: 0.0085 - val_accuracy: 0.6211\n",
      "Epoch 35/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 5.6372e-04 - accuracy: 0.6987 - val_loss: 0.0089 - val_accuracy: 0.6857\n",
      "Epoch 36/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 4.2471e-04 - accuracy: 0.7086 - val_loss: 0.0087 - val_accuracy: 0.5474\n",
      "Epoch 37/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 3.9275e-04 - accuracy: 0.6819 - val_loss: 0.0089 - val_accuracy: 0.5820\n",
      "Epoch 38/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94/94 [==============================] - 0s 2ms/step - loss: 4.2673e-04 - accuracy: 0.6304 - val_loss: 0.0090 - val_accuracy: 0.6015\n",
      "Epoch 39/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 3.4174e-04 - accuracy: 0.6378 - val_loss: 0.0092 - val_accuracy: 0.6120\n",
      "Epoch 40/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 2.4873e-04 - accuracy: 0.6526 - val_loss: 0.0096 - val_accuracy: 0.5609\n",
      "Epoch 41/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 3.0164e-04 - accuracy: 0.6204 - val_loss: 0.0095 - val_accuracy: 0.6992\n",
      "Epoch 42/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 2.0710e-04 - accuracy: 0.6613 - val_loss: 0.0095 - val_accuracy: 0.5534\n",
      "Epoch 43/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 1.7459e-04 - accuracy: 0.6045 - val_loss: 0.0096 - val_accuracy: 0.5714\n",
      "Epoch 44/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 1.6318e-04 - accuracy: 0.6324 - val_loss: 0.0096 - val_accuracy: 0.6496\n",
      "Epoch 45/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 1.4724e-04 - accuracy: 0.6212 - val_loss: 0.0098 - val_accuracy: 0.5654\n",
      "Epoch 46/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 1.3277e-04 - accuracy: 0.5933 - val_loss: 0.0098 - val_accuracy: 0.6226\n",
      "Epoch 47/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 1.2235e-04 - accuracy: 0.6256 - val_loss: 0.0101 - val_accuracy: 0.5414\n",
      "Epoch 48/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 1.1644e-04 - accuracy: 0.6043 - val_loss: 0.0101 - val_accuracy: 0.5444\n",
      "Epoch 49/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 1.0405e-04 - accuracy: 0.6182 - val_loss: 0.0101 - val_accuracy: 0.5684\n",
      "Epoch 50/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 1.0032e-04 - accuracy: 0.5995 - val_loss: 0.0102 - val_accuracy: 0.5835\n",
      "Epoch 51/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 8.9926e-05 - accuracy: 0.6000 - val_loss: 0.0104 - val_accuracy: 0.5820\n",
      "Epoch 52/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 8.1185e-05 - accuracy: 0.5906 - val_loss: 0.0105 - val_accuracy: 0.5504\n",
      "Epoch 53/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 7.8536e-05 - accuracy: 0.5958 - val_loss: 0.0104 - val_accuracy: 0.6150\n",
      "Epoch 54/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 6.6112e-05 - accuracy: 0.5898 - val_loss: 0.0106 - val_accuracy: 0.5459\n",
      "Epoch 55/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 6.1943e-05 - accuracy: 0.5972 - val_loss: 0.0104 - val_accuracy: 0.6000\n",
      "Epoch 56/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 6.1612e-05 - accuracy: 0.5724 - val_loss: 0.0106 - val_accuracy: 0.5489\n",
      "Epoch 57/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 5.4228e-05 - accuracy: 0.5805 - val_loss: 0.0107 - val_accuracy: 0.5474\n",
      "Epoch 58/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 4.7295e-05 - accuracy: 0.5652 - val_loss: 0.0109 - val_accuracy: 0.5609\n",
      "Epoch 59/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 4.4975e-05 - accuracy: 0.6020 - val_loss: 0.0109 - val_accuracy: 0.5609\n",
      "Epoch 60/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 4.1673e-05 - accuracy: 0.5853 - val_loss: 0.0112 - val_accuracy: 0.5323\n",
      "Epoch 61/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 3.8139e-05 - accuracy: 0.5781 - val_loss: 0.0112 - val_accuracy: 0.5323\n",
      "Epoch 62/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 3.8190e-05 - accuracy: 0.5925 - val_loss: 0.0111 - val_accuracy: 0.5699\n",
      "Epoch 63/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 3.3713e-05 - accuracy: 0.5676 - val_loss: 0.0112 - val_accuracy: 0.5248\n",
      "Epoch 64/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 3.2762e-05 - accuracy: 0.5567 - val_loss: 0.0113 - val_accuracy: 0.5579\n",
      "Epoch 65/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 2.9709e-05 - accuracy: 0.5826 - val_loss: 0.0114 - val_accuracy: 0.5474\n",
      "Epoch 66/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 2.7843e-05 - accuracy: 0.5668 - val_loss: 0.0116 - val_accuracy: 0.5248\n",
      "Epoch 67/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 2.6081e-05 - accuracy: 0.5626 - val_loss: 0.0115 - val_accuracy: 0.5338\n",
      "Epoch 68/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 2.6481e-05 - accuracy: 0.5776 - val_loss: 0.0115 - val_accuracy: 0.5654\n",
      "Epoch 69/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 2.3682e-05 - accuracy: 0.5556 - val_loss: 0.0118 - val_accuracy: 0.5263\n",
      "Epoch 70/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 2.1636e-05 - accuracy: 0.5636 - val_loss: 0.0119 - val_accuracy: 0.5323\n",
      "Epoch 71/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 1.9915e-05 - accuracy: 0.5539 - val_loss: 0.0118 - val_accuracy: 0.5353\n",
      "Epoch 72/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 1.8431e-05 - accuracy: 0.5584 - val_loss: 0.0118 - val_accuracy: 0.5444\n",
      "Epoch 73/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 1.8352e-05 - accuracy: 0.5599 - val_loss: 0.0121 - val_accuracy: 0.5248\n",
      "Epoch 74/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 1.6415e-05 - accuracy: 0.5569 - val_loss: 0.0121 - val_accuracy: 0.5023\n",
      "Epoch 75/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 1.6887e-05 - accuracy: 0.5499 - val_loss: 0.0121 - val_accuracy: 0.5519\n",
      "Epoch 76/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 1.5135e-05 - accuracy: 0.5552 - val_loss: 0.0122 - val_accuracy: 0.5008\n",
      "Epoch 77/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 1.3233e-05 - accuracy: 0.5350 - val_loss: 0.0124 - val_accuracy: 0.5173\n",
      "Epoch 78/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 1.2857e-05 - accuracy: 0.5500 - val_loss: 0.0123 - val_accuracy: 0.5368\n",
      "Epoch 79/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 1.2491e-05 - accuracy: 0.5612 - val_loss: 0.0123 - val_accuracy: 0.5353\n",
      "Epoch 80/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 1.1524e-05 - accuracy: 0.5505 - val_loss: 0.0124 - val_accuracy: 0.5338\n",
      "Epoch 81/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 1.0696e-05 - accuracy: 0.5392 - val_loss: 0.0126 - val_accuracy: 0.4857\n",
      "Epoch 82/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 1.0105e-05 - accuracy: 0.5246 - val_loss: 0.0126 - val_accuracy: 0.5008\n",
      "Epoch 83/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 9.8134e-06 - accuracy: 0.5383 - val_loss: 0.0125 - val_accuracy: 0.5248\n",
      "Epoch 84/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 9.0235e-06 - accuracy: 0.5397 - val_loss: 0.0126 - val_accuracy: 0.5308\n",
      "Epoch 85/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 8.5793e-06 - accuracy: 0.5462 - val_loss: 0.0127 - val_accuracy: 0.5188\n",
      "Epoch 86/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 7.8347e-06 - accuracy: 0.5352 - val_loss: 0.0130 - val_accuracy: 0.4872\n",
      "Epoch 87/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 7.7228e-06 - accuracy: 0.5502 - val_loss: 0.0129 - val_accuracy: 0.4917\n",
      "Epoch 88/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 7.2690e-06 - accuracy: 0.5398 - val_loss: 0.0130 - val_accuracy: 0.5233\n",
      "Epoch 89/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 6.7518e-06 - accuracy: 0.5383 - val_loss: 0.0131 - val_accuracy: 0.4992\n",
      "Epoch 90/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 6.3542e-06 - accuracy: 0.5388 - val_loss: 0.0131 - val_accuracy: 0.5038\n",
      "Epoch 91/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 6.1542e-06 - accuracy: 0.5305 - val_loss: 0.0131 - val_accuracy: 0.5248\n",
      "Epoch 92/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 5.6301e-06 - accuracy: 0.5482 - val_loss: 0.0131 - val_accuracy: 0.5158\n",
      "Epoch 93/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 5.4482e-06 - accuracy: 0.5439 - val_loss: 0.0131 - val_accuracy: 0.5158\n",
      "Epoch 94/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 5.3225e-06 - accuracy: 0.5382 - val_loss: 0.0133 - val_accuracy: 0.5053\n",
      "Epoch 95/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 4.7983e-06 - accuracy: 0.5322 - val_loss: 0.0134 - val_accuracy: 0.5008\n",
      "Epoch 96/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 4.5956e-06 - accuracy: 0.5388 - val_loss: 0.0134 - val_accuracy: 0.5248\n",
      "Epoch 97/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 4.3491e-06 - accuracy: 0.5317 - val_loss: 0.0135 - val_accuracy: 0.5233\n",
      "Epoch 98/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 4.3551e-06 - accuracy: 0.5375 - val_loss: 0.0134 - val_accuracy: 0.5173\n",
      "Epoch 99/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 3.9293e-06 - accuracy: 0.5250 - val_loss: 0.0135 - val_accuracy: 0.5203\n",
      "Epoch 100/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 3.7840e-06 - accuracy: 0.5410 - val_loss: 0.0134 - val_accuracy: 0.4992\n",
      "Score for fold 4 : loss of 0.013447889126837254 ; F1-Macro: 0.8748116049105293 F1-Micro: 0.9988721804511279\n",
      "Training...\n",
      "Epoch 1/100\n",
      "94/94 [==============================] - 1s 2ms/step - loss: 0.0634 - accuracy: 0.0685 - val_loss: 0.0046 - val_accuracy: 0.0887\n",
      "Epoch 2/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.0110 - accuracy: 0.2742 - val_loss: 0.0047 - val_accuracy: 0.4045\n",
      "Epoch 3/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.0107 - accuracy: 0.3532 - val_loss: 0.0046 - val_accuracy: 0.3158\n",
      "Epoch 4/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.0101 - accuracy: 0.3345 - val_loss: 0.0043 - val_accuracy: 0.3143\n",
      "Epoch 5/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.0098 - accuracy: 0.3292 - val_loss: 0.0045 - val_accuracy: 0.1805\n",
      "Epoch 6/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.0095 - accuracy: 0.1534 - val_loss: 0.0044 - val_accuracy: 0.2150\n",
      "Epoch 7/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.0088 - accuracy: 0.2226 - val_loss: 0.0049 - val_accuracy: 0.2917\n",
      "Epoch 8/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.0081 - accuracy: 0.2707 - val_loss: 0.0051 - val_accuracy: 0.4331\n",
      "Epoch 9/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.0073 - accuracy: 0.3013 - val_loss: 0.0063 - val_accuracy: 0.1323\n",
      "Epoch 10/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.0067 - accuracy: 0.3960 - val_loss: 0.0058 - val_accuracy: 0.2466\n",
      "Epoch 11/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.0060 - accuracy: 0.4872 - val_loss: 0.0053 - val_accuracy: 0.8647\n",
      "Epoch 12/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.0059 - accuracy: 0.5683 - val_loss: 0.0062 - val_accuracy: 0.3504\n",
      "Epoch 13/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.0054 - accuracy: 0.4637 - val_loss: 0.0061 - val_accuracy: 0.5338\n",
      "Epoch 14/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.0046 - accuracy: 0.5121 - val_loss: 0.0062 - val_accuracy: 0.4782\n",
      "Epoch 15/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.0041 - accuracy: 0.5422 - val_loss: 0.0058 - val_accuracy: 0.4421\n",
      "Epoch 16/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.0040 - accuracy: 0.4924 - val_loss: 0.0062 - val_accuracy: 0.5594\n",
      "Epoch 17/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.0036 - accuracy: 0.4655 - val_loss: 0.0076 - val_accuracy: 0.3519\n",
      "Epoch 18/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.0032 - accuracy: 0.3571 - val_loss: 0.0061 - val_accuracy: 0.2180\n",
      "Epoch 19/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.0030 - accuracy: 0.4468 - val_loss: 0.0078 - val_accuracy: 0.4060\n",
      "Epoch 20/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.0026 - accuracy: 0.3061 - val_loss: 0.0067 - val_accuracy: 0.4436\n",
      "Epoch 21/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.0025 - accuracy: 0.3960 - val_loss: 0.0066 - val_accuracy: 0.3353\n",
      "Epoch 22/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.0023 - accuracy: 0.3200 - val_loss: 0.0074 - val_accuracy: 0.3218\n",
      "Epoch 23/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.0020 - accuracy: 0.3063 - val_loss: 0.0080 - val_accuracy: 0.2992\n",
      "Epoch 24/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.0017 - accuracy: 0.3500 - val_loss: 0.0069 - val_accuracy: 0.1459\n",
      "Epoch 25/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.0016 - accuracy: 0.2459 - val_loss: 0.0071 - val_accuracy: 0.3218\n",
      "Epoch 26/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.0013 - accuracy: 0.3317 - val_loss: 0.0073 - val_accuracy: 0.2391\n",
      "Epoch 27/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.0011 - accuracy: 0.2954 - val_loss: 0.0076 - val_accuracy: 0.2376\n",
      "Epoch 28/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 9.3045e-04 - accuracy: 0.2209 - val_loss: 0.0081 - val_accuracy: 0.2541\n",
      "Epoch 29/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 9.2129e-04 - accuracy: 0.2446 - val_loss: 0.0074 - val_accuracy: 0.1368\n",
      "Epoch 30/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 7.8642e-04 - accuracy: 0.2765 - val_loss: 0.0075 - val_accuracy: 0.3173\n",
      "Epoch 31/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 5.9567e-04 - accuracy: 0.2625 - val_loss: 0.0076 - val_accuracy: 0.1143\n",
      "Epoch 32/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 4.9157e-04 - accuracy: 0.1851 - val_loss: 0.0079 - val_accuracy: 0.1805\n",
      "Epoch 33/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 4.5798e-04 - accuracy: 0.2720 - val_loss: 0.0080 - val_accuracy: 0.2602\n",
      "Epoch 34/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 3.9415e-04 - accuracy: 0.1880 - val_loss: 0.0079 - val_accuracy: 0.1925\n",
      "Epoch 35/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 3.5490e-04 - accuracy: 0.2555 - val_loss: 0.0082 - val_accuracy: 0.1534\n",
      "Epoch 36/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 2.9278e-04 - accuracy: 0.1818 - val_loss: 0.0091 - val_accuracy: 0.1188\n",
      "Epoch 37/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 3.0999e-04 - accuracy: 0.1776 - val_loss: 0.0086 - val_accuracy: 0.2421\n",
      "Epoch 38/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 2.0853e-04 - accuracy: 0.2242 - val_loss: 0.0088 - val_accuracy: 0.2301\n",
      "Epoch 39/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 1.8196e-04 - accuracy: 0.2389 - val_loss: 0.0088 - val_accuracy: 0.2090\n",
      "Epoch 40/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 1.7273e-04 - accuracy: 0.1866 - val_loss: 0.0090 - val_accuracy: 0.2045\n",
      "Epoch 41/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 1.4404e-04 - accuracy: 0.1923 - val_loss: 0.0089 - val_accuracy: 0.1368\n",
      "Epoch 42/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 1.4538e-04 - accuracy: 0.1977 - val_loss: 0.0092 - val_accuracy: 0.2075\n",
      "Epoch 43/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 1.2095e-04 - accuracy: 0.1830 - val_loss: 0.0096 - val_accuracy: 0.1759\n",
      "Epoch 44/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 1.0989e-04 - accuracy: 0.1611 - val_loss: 0.0096 - val_accuracy: 0.1910\n",
      "Epoch 45/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 1.0103e-04 - accuracy: 0.2040 - val_loss: 0.0095 - val_accuracy: 0.1985\n",
      "Epoch 46/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 9.7177e-05 - accuracy: 0.1978 - val_loss: 0.0099 - val_accuracy: 0.2060\n",
      "Epoch 47/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 9.2649e-05 - accuracy: 0.2042 - val_loss: 0.0101 - val_accuracy: 0.2060\n",
      "Epoch 48/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 7.5966e-05 - accuracy: 0.1943 - val_loss: 0.0100 - val_accuracy: 0.1955\n",
      "Epoch 49/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 6.8911e-05 - accuracy: 0.1957 - val_loss: 0.0103 - val_accuracy: 0.1985\n",
      "Epoch 50/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94/94 [==============================] - 0s 1ms/step - loss: 6.4947e-05 - accuracy: 0.1684 - val_loss: 0.0102 - val_accuracy: 0.2075\n",
      "Epoch 51/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 6.0503e-05 - accuracy: 0.1895 - val_loss: 0.0103 - val_accuracy: 0.2045\n",
      "Epoch 52/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 5.6525e-05 - accuracy: 0.2140 - val_loss: 0.0104 - val_accuracy: 0.1774\n",
      "Epoch 53/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 5.1822e-05 - accuracy: 0.1933 - val_loss: 0.0104 - val_accuracy: 0.1985\n",
      "Epoch 54/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 4.7672e-05 - accuracy: 0.1818 - val_loss: 0.0108 - val_accuracy: 0.1624\n",
      "Epoch 55/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 4.3667e-05 - accuracy: 0.1815 - val_loss: 0.0105 - val_accuracy: 0.1729\n",
      "Epoch 56/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 3.8966e-05 - accuracy: 0.1721 - val_loss: 0.0112 - val_accuracy: 0.1639\n",
      "Epoch 57/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 4.0673e-05 - accuracy: 0.1662 - val_loss: 0.0105 - val_accuracy: 0.2075\n",
      "Epoch 58/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 3.7391e-05 - accuracy: 0.1943 - val_loss: 0.0111 - val_accuracy: 0.1970\n",
      "Epoch 59/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 3.3589e-05 - accuracy: 0.1766 - val_loss: 0.0110 - val_accuracy: 0.1744\n",
      "Epoch 60/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 3.1609e-05 - accuracy: 0.1893 - val_loss: 0.0111 - val_accuracy: 0.1910\n",
      "Epoch 61/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 2.9504e-05 - accuracy: 0.1930 - val_loss: 0.0114 - val_accuracy: 0.1639\n",
      "Epoch 62/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 2.7457e-05 - accuracy: 0.2084 - val_loss: 0.0111 - val_accuracy: 0.1880\n",
      "Epoch 63/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 2.4989e-05 - accuracy: 0.1815 - val_loss: 0.0114 - val_accuracy: 0.1820\n",
      "Epoch 64/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 2.3436e-05 - accuracy: 0.1681 - val_loss: 0.0113 - val_accuracy: 0.1880\n",
      "Epoch 65/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 2.2403e-05 - accuracy: 0.1846 - val_loss: 0.0115 - val_accuracy: 0.1835\n",
      "Epoch 66/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 2.1135e-05 - accuracy: 0.1791 - val_loss: 0.0115 - val_accuracy: 0.1925\n",
      "Epoch 67/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 1.9696e-05 - accuracy: 0.1853 - val_loss: 0.0117 - val_accuracy: 0.2120\n",
      "Epoch 68/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 1.8289e-05 - accuracy: 0.1886 - val_loss: 0.0117 - val_accuracy: 0.1940\n",
      "Epoch 69/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 1.7473e-05 - accuracy: 0.1788 - val_loss: 0.0118 - val_accuracy: 0.1820\n",
      "Epoch 70/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 1.6901e-05 - accuracy: 0.1865 - val_loss: 0.0120 - val_accuracy: 0.1789\n",
      "Epoch 71/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 1.5265e-05 - accuracy: 0.1788 - val_loss: 0.0120 - val_accuracy: 0.1880\n",
      "Epoch 72/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 1.4477e-05 - accuracy: 0.2010 - val_loss: 0.0121 - val_accuracy: 0.1684\n",
      "Epoch 73/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 1.3524e-05 - accuracy: 0.1671 - val_loss: 0.0119 - val_accuracy: 0.1654\n",
      "Epoch 74/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 1.2644e-05 - accuracy: 0.1768 - val_loss: 0.0124 - val_accuracy: 0.1820\n",
      "Epoch 75/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 1.1936e-05 - accuracy: 0.1850 - val_loss: 0.0122 - val_accuracy: 0.1805\n",
      "Epoch 76/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 1.1185e-05 - accuracy: 0.1843 - val_loss: 0.0122 - val_accuracy: 0.1714\n",
      "Epoch 77/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 1.0577e-05 - accuracy: 0.1806 - val_loss: 0.0124 - val_accuracy: 0.1714\n",
      "Epoch 78/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 9.9056e-06 - accuracy: 0.1753 - val_loss: 0.0125 - val_accuracy: 0.1669\n",
      "Epoch 79/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 9.4636e-06 - accuracy: 0.1691 - val_loss: 0.0126 - val_accuracy: 0.1729\n",
      "Epoch 80/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 8.6377e-06 - accuracy: 0.1935 - val_loss: 0.0125 - val_accuracy: 0.2075\n",
      "Epoch 81/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 8.8399e-06 - accuracy: 0.2015 - val_loss: 0.0127 - val_accuracy: 0.1925\n",
      "Epoch 82/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 8.1028e-06 - accuracy: 0.1796 - val_loss: 0.0127 - val_accuracy: 0.1820\n",
      "Epoch 83/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 7.4411e-06 - accuracy: 0.1794 - val_loss: 0.0128 - val_accuracy: 0.2000\n",
      "Epoch 84/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 7.2063e-06 - accuracy: 0.1977 - val_loss: 0.0130 - val_accuracy: 0.1940\n",
      "Epoch 85/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 6.5610e-06 - accuracy: 0.2069 - val_loss: 0.0131 - val_accuracy: 0.1865\n",
      "Epoch 86/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 6.4407e-06 - accuracy: 0.1815 - val_loss: 0.0130 - val_accuracy: 0.1654\n",
      "Epoch 87/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 6.0913e-06 - accuracy: 0.1604 - val_loss: 0.0131 - val_accuracy: 0.1654\n",
      "Epoch 88/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 5.6589e-06 - accuracy: 0.1905 - val_loss: 0.0133 - val_accuracy: 0.1774\n",
      "Epoch 89/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 5.4129e-06 - accuracy: 0.1831 - val_loss: 0.0133 - val_accuracy: 0.1850\n",
      "Epoch 90/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 5.0847e-06 - accuracy: 0.1953 - val_loss: 0.0134 - val_accuracy: 0.1880\n",
      "Epoch 91/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 4.6894e-06 - accuracy: 0.1810 - val_loss: 0.0136 - val_accuracy: 0.1729\n",
      "Epoch 92/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 4.5051e-06 - accuracy: 0.1789 - val_loss: 0.0135 - val_accuracy: 0.1669\n",
      "Epoch 93/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 4.2982e-06 - accuracy: 0.1813 - val_loss: 0.0137 - val_accuracy: 0.1669\n",
      "Epoch 94/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 4.2420e-06 - accuracy: 0.1840 - val_loss: 0.0135 - val_accuracy: 0.1910\n",
      "Epoch 95/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 3.9025e-06 - accuracy: 0.1793 - val_loss: 0.0135 - val_accuracy: 0.1759\n",
      "Epoch 96/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 3.6900e-06 - accuracy: 0.1846 - val_loss: 0.0138 - val_accuracy: 0.1805\n",
      "Epoch 97/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 3.5469e-06 - accuracy: 0.1908 - val_loss: 0.0137 - val_accuracy: 0.1925\n",
      "Epoch 98/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 3.3549e-06 - accuracy: 0.1825 - val_loss: 0.0138 - val_accuracy: 0.1835\n",
      "Epoch 99/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 3.2179e-06 - accuracy: 0.1992 - val_loss: 0.0138 - val_accuracy: 0.1865\n",
      "Epoch 100/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 2.9380e-06 - accuracy: 0.1753 - val_loss: 0.0141 - val_accuracy: 0.1684\n",
      "Score for fold 5 : loss of 0.014058946631848812 ; F1-Macro: 0.9165411646586344 F1-Micro: 0.9992481203007518\n",
      "Training...\n",
      "Epoch 1/100\n",
      "94/94 [==============================] - 1s 2ms/step - loss: 0.0560 - accuracy: 0.0977 - val_loss: 0.0058 - val_accuracy: 0.0150\n",
      "Epoch 2/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.0111 - accuracy: 0.1825 - val_loss: 0.0056 - val_accuracy: 0.3188\n",
      "Epoch 3/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.0106 - accuracy: 0.3970 - val_loss: 0.0058 - val_accuracy: 0.4211\n",
      "Epoch 4/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.0101 - accuracy: 0.4496 - val_loss: 0.0056 - val_accuracy: 0.5444\n",
      "Epoch 5/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.0097 - accuracy: 0.3656 - val_loss: 0.0059 - val_accuracy: 0.4256\n",
      "Epoch 6/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.0093 - accuracy: 0.3599 - val_loss: 0.0060 - val_accuracy: 0.5323\n",
      "Epoch 7/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.0086 - accuracy: 0.4174 - val_loss: 0.0066 - val_accuracy: 0.1053\n",
      "Epoch 8/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.0081 - accuracy: 0.2055 - val_loss: 0.0064 - val_accuracy: 0.0406\n",
      "Epoch 9/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.0074 - accuracy: 0.2207 - val_loss: 0.0063 - val_accuracy: 0.1880\n",
      "Epoch 10/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.0067 - accuracy: 0.1505 - val_loss: 0.0064 - val_accuracy: 0.1323\n",
      "Epoch 11/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.0063 - accuracy: 0.1918 - val_loss: 0.0061 - val_accuracy: 0.0331\n",
      "Epoch 12/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.0056 - accuracy: 0.0837 - val_loss: 0.0067 - val_accuracy: 0.2602\n",
      "Epoch 13/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.0054 - accuracy: 0.1198 - val_loss: 0.0075 - val_accuracy: 0.1759\n",
      "Epoch 14/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.0050 - accuracy: 0.1415 - val_loss: 0.0064 - val_accuracy: 0.2000\n",
      "Epoch 15/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.0046 - accuracy: 0.1544 - val_loss: 0.0073 - val_accuracy: 0.0767\n",
      "Epoch 16/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.0040 - accuracy: 0.1497 - val_loss: 0.0074 - val_accuracy: 0.2030\n",
      "Epoch 17/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.0039 - accuracy: 0.1661 - val_loss: 0.0067 - val_accuracy: 0.3729\n",
      "Epoch 18/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.0037 - accuracy: 0.2119 - val_loss: 0.0067 - val_accuracy: 0.2466\n",
      "Epoch 19/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.0032 - accuracy: 0.1960 - val_loss: 0.0073 - val_accuracy: 0.1128\n",
      "Epoch 20/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.0028 - accuracy: 0.0937 - val_loss: 0.0074 - val_accuracy: 0.1248\n",
      "Epoch 21/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.0029 - accuracy: 0.1668 - val_loss: 0.0073 - val_accuracy: 0.1895\n",
      "Epoch 22/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.0025 - accuracy: 0.2316 - val_loss: 0.0076 - val_accuracy: 0.1188\n",
      "Epoch 23/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.0023 - accuracy: 0.1245 - val_loss: 0.0072 - val_accuracy: 0.2617\n",
      "Epoch 24/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.0019 - accuracy: 0.2403 - val_loss: 0.0078 - val_accuracy: 0.3308\n",
      "Epoch 25/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.0018 - accuracy: 0.1972 - val_loss: 0.0079 - val_accuracy: 0.0586\n",
      "Epoch 26/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.0019 - accuracy: 0.1497 - val_loss: 0.0078 - val_accuracy: 0.0932\n",
      "Epoch 27/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.0016 - accuracy: 0.2647 - val_loss: 0.0079 - val_accuracy: 0.2180\n",
      "Epoch 28/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.0013 - accuracy: 0.1888 - val_loss: 0.0081 - val_accuracy: 0.2857\n",
      "Epoch 29/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.0012 - accuracy: 0.1489 - val_loss: 0.0092 - val_accuracy: 0.1474\n",
      "Epoch 30/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.0011 - accuracy: 0.2015 - val_loss: 0.0084 - val_accuracy: 0.2421\n",
      "Epoch 31/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.0011 - accuracy: 0.2475 - val_loss: 0.0084 - val_accuracy: 0.2481\n",
      "Epoch 32/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 8.6943e-04 - accuracy: 0.1731 - val_loss: 0.0093 - val_accuracy: 0.1398\n",
      "Epoch 33/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 7.0033e-04 - accuracy: 0.1796 - val_loss: 0.0093 - val_accuracy: 0.1549\n",
      "Epoch 34/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 6.0988e-04 - accuracy: 0.1749 - val_loss: 0.0095 - val_accuracy: 0.0992\n",
      "Epoch 35/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 5.1636e-04 - accuracy: 0.1594 - val_loss: 0.0093 - val_accuracy: 0.1759\n",
      "Epoch 36/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 4.4225e-04 - accuracy: 0.1925 - val_loss: 0.0096 - val_accuracy: 0.1218\n",
      "Epoch 37/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 3.8611e-04 - accuracy: 0.1449 - val_loss: 0.0093 - val_accuracy: 0.1789\n",
      "Epoch 38/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 3.6012e-04 - accuracy: 0.1784 - val_loss: 0.0093 - val_accuracy: 0.1714\n",
      "Epoch 39/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 2.8601e-04 - accuracy: 0.1479 - val_loss: 0.0095 - val_accuracy: 0.1519\n",
      "Epoch 40/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 2.5651e-04 - accuracy: 0.1562 - val_loss: 0.0096 - val_accuracy: 0.1218\n",
      "Epoch 41/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 2.2353e-04 - accuracy: 0.1469 - val_loss: 0.0097 - val_accuracy: 0.1338\n",
      "Epoch 42/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 2.0904e-04 - accuracy: 0.1505 - val_loss: 0.0096 - val_accuracy: 0.1624\n",
      "Epoch 43/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 1.8940e-04 - accuracy: 0.1552 - val_loss: 0.0097 - val_accuracy: 0.1609\n",
      "Epoch 44/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 1.6689e-04 - accuracy: 0.1415 - val_loss: 0.0101 - val_accuracy: 0.1098\n",
      "Epoch 45/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 1.4812e-04 - accuracy: 0.1343 - val_loss: 0.0101 - val_accuracy: 0.1233\n",
      "Epoch 46/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 1.3110e-04 - accuracy: 0.1288 - val_loss: 0.0100 - val_accuracy: 0.1504\n",
      "Epoch 47/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 1.1779e-04 - accuracy: 0.1410 - val_loss: 0.0103 - val_accuracy: 0.1248\n",
      "Epoch 48/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 1.0711e-04 - accuracy: 0.1375 - val_loss: 0.0103 - val_accuracy: 0.1429\n",
      "Epoch 49/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 1.0013e-04 - accuracy: 0.1360 - val_loss: 0.0103 - val_accuracy: 0.1414\n",
      "Epoch 50/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 8.9430e-05 - accuracy: 0.1241 - val_loss: 0.0105 - val_accuracy: 0.1233\n",
      "Epoch 51/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 7.8488e-05 - accuracy: 0.1238 - val_loss: 0.0107 - val_accuracy: 0.1068\n",
      "Epoch 52/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 7.2998e-05 - accuracy: 0.1155 - val_loss: 0.0108 - val_accuracy: 0.1188\n",
      "Epoch 53/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 7.2293e-05 - accuracy: 0.1180 - val_loss: 0.0108 - val_accuracy: 0.1218\n",
      "Epoch 54/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 6.2442e-05 - accuracy: 0.1138 - val_loss: 0.0106 - val_accuracy: 0.1263\n",
      "Epoch 55/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 6.0285e-05 - accuracy: 0.1328 - val_loss: 0.0108 - val_accuracy: 0.1368\n",
      "Epoch 56/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 5.6466e-05 - accuracy: 0.1196 - val_loss: 0.0109 - val_accuracy: 0.1383\n",
      "Epoch 57/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 4.9281e-05 - accuracy: 0.1338 - val_loss: 0.0110 - val_accuracy: 0.1278\n",
      "Epoch 58/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 4.4956e-05 - accuracy: 0.1196 - val_loss: 0.0110 - val_accuracy: 0.1128\n",
      "Epoch 59/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 4.2796e-05 - accuracy: 0.1094 - val_loss: 0.0111 - val_accuracy: 0.1293\n",
      "Epoch 60/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 3.9768e-05 - accuracy: 0.1315 - val_loss: 0.0113 - val_accuracy: 0.1323\n",
      "Epoch 61/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 3.6857e-05 - accuracy: 0.1098 - val_loss: 0.0113 - val_accuracy: 0.1233\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 62/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 3.4600e-05 - accuracy: 0.1372 - val_loss: 0.0114 - val_accuracy: 0.1173\n",
      "Epoch 63/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 3.3331e-05 - accuracy: 0.1038 - val_loss: 0.0115 - val_accuracy: 0.1143\n",
      "Epoch 64/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 2.9700e-05 - accuracy: 0.1170 - val_loss: 0.0116 - val_accuracy: 0.1293\n",
      "Epoch 65/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 3.0220e-05 - accuracy: 0.1158 - val_loss: 0.0117 - val_accuracy: 0.1143\n",
      "Epoch 66/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 2.7144e-05 - accuracy: 0.1198 - val_loss: 0.0118 - val_accuracy: 0.1188\n",
      "Epoch 67/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 2.4403e-05 - accuracy: 0.1101 - val_loss: 0.0117 - val_accuracy: 0.1218\n",
      "Epoch 68/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 2.2928e-05 - accuracy: 0.1145 - val_loss: 0.0120 - val_accuracy: 0.1218\n",
      "Epoch 69/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 2.1364e-05 - accuracy: 0.1178 - val_loss: 0.0118 - val_accuracy: 0.1368\n",
      "Epoch 70/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 2.1232e-05 - accuracy: 0.1215 - val_loss: 0.0119 - val_accuracy: 0.1293\n",
      "Epoch 71/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 1.9519e-05 - accuracy: 0.1175 - val_loss: 0.0121 - val_accuracy: 0.1218\n",
      "Epoch 72/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 1.8001e-05 - accuracy: 0.1176 - val_loss: 0.0122 - val_accuracy: 0.1098\n",
      "Epoch 73/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 1.6979e-05 - accuracy: 0.1160 - val_loss: 0.0122 - val_accuracy: 0.1158\n",
      "Epoch 74/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 1.5767e-05 - accuracy: 0.1138 - val_loss: 0.0121 - val_accuracy: 0.1263\n",
      "Epoch 75/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 1.5420e-05 - accuracy: 0.1313 - val_loss: 0.0122 - val_accuracy: 0.1143\n",
      "Epoch 76/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 1.4351e-05 - accuracy: 0.1200 - val_loss: 0.0124 - val_accuracy: 0.1113\n",
      "Epoch 77/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 1.3112e-05 - accuracy: 0.1106 - val_loss: 0.0123 - val_accuracy: 0.1173\n",
      "Epoch 78/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 1.2288e-05 - accuracy: 0.1124 - val_loss: 0.0125 - val_accuracy: 0.1143\n",
      "Epoch 79/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 1.1750e-05 - accuracy: 0.1116 - val_loss: 0.0126 - val_accuracy: 0.1038\n",
      "Epoch 80/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 1.0739e-05 - accuracy: 0.1021 - val_loss: 0.0126 - val_accuracy: 0.1143\n",
      "Epoch 81/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 1.0298e-05 - accuracy: 0.1084 - val_loss: 0.0126 - val_accuracy: 0.1158\n",
      "Epoch 82/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 1.0343e-05 - accuracy: 0.1223 - val_loss: 0.0127 - val_accuracy: 0.1098\n",
      "Epoch 83/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 9.1493e-06 - accuracy: 0.1043 - val_loss: 0.0130 - val_accuracy: 0.1143\n",
      "Epoch 84/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 8.4409e-06 - accuracy: 0.1158 - val_loss: 0.0130 - val_accuracy: 0.1008\n",
      "Epoch 85/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 8.1722e-06 - accuracy: 0.1128 - val_loss: 0.0131 - val_accuracy: 0.1143\n",
      "Epoch 86/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 7.5930e-06 - accuracy: 0.1128 - val_loss: 0.0129 - val_accuracy: 0.1038\n",
      "Epoch 87/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 7.2727e-06 - accuracy: 0.1126 - val_loss: 0.0133 - val_accuracy: 0.1038\n",
      "Epoch 88/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 6.8323e-06 - accuracy: 0.1094 - val_loss: 0.0131 - val_accuracy: 0.1113\n",
      "Epoch 89/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 6.6210e-06 - accuracy: 0.1043 - val_loss: 0.0132 - val_accuracy: 0.0992\n",
      "Epoch 90/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 6.1293e-06 - accuracy: 0.1151 - val_loss: 0.0133 - val_accuracy: 0.1038\n",
      "Epoch 91/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 5.7598e-06 - accuracy: 0.1053 - val_loss: 0.0133 - val_accuracy: 0.1068\n",
      "Epoch 92/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 5.5464e-06 - accuracy: 0.1048 - val_loss: 0.0134 - val_accuracy: 0.0977\n",
      "Epoch 93/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 5.4680e-06 - accuracy: 0.1071 - val_loss: 0.0134 - val_accuracy: 0.1098\n",
      "Epoch 94/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 4.9409e-06 - accuracy: 0.1063 - val_loss: 0.0136 - val_accuracy: 0.1068\n",
      "Epoch 95/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 4.6774e-06 - accuracy: 0.1069 - val_loss: 0.0136 - val_accuracy: 0.1068\n",
      "Epoch 96/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 4.3423e-06 - accuracy: 0.1043 - val_loss: 0.0139 - val_accuracy: 0.1023\n",
      "Epoch 97/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 4.2255e-06 - accuracy: 0.1093 - val_loss: 0.0137 - val_accuracy: 0.1128\n",
      "Epoch 98/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 3.9781e-06 - accuracy: 0.1181 - val_loss: 0.0137 - val_accuracy: 0.1083\n",
      "Epoch 99/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 3.7885e-06 - accuracy: 0.1053 - val_loss: 0.0137 - val_accuracy: 0.0962\n",
      "Epoch 100/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 3.7106e-06 - accuracy: 0.1119 - val_loss: 0.0140 - val_accuracy: 0.1038\n",
      "Score for fold 6 : loss of 0.01396168302744627 ; F1-Macro: 0.8330825181840983 F1-Micro: 0.9988717562993608\n",
      "Training...\n",
      "Epoch 1/100\n",
      "94/94 [==============================] - 1s 2ms/step - loss: 0.0603 - accuracy: 0.8543 - val_loss: 0.0110 - val_accuracy: 0.8977\n",
      "Epoch 2/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.0105 - accuracy: 0.7059 - val_loss: 0.0109 - val_accuracy: 0.5474\n",
      "Epoch 3/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.0103 - accuracy: 0.6266 - val_loss: 0.0106 - val_accuracy: 0.6722\n",
      "Epoch 4/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.0098 - accuracy: 0.5779 - val_loss: 0.0105 - val_accuracy: 0.3083\n",
      "Epoch 5/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.0094 - accuracy: 0.6359 - val_loss: 0.0108 - val_accuracy: 0.2015\n",
      "Epoch 6/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.0088 - accuracy: 0.5754 - val_loss: 0.0105 - val_accuracy: 0.9654\n",
      "Epoch 7/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.0086 - accuracy: 0.6409 - val_loss: 0.0103 - val_accuracy: 0.3609\n",
      "Epoch 8/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.0080 - accuracy: 0.5322 - val_loss: 0.0101 - val_accuracy: 0.4677\n",
      "Epoch 9/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.0074 - accuracy: 0.5930 - val_loss: 0.0100 - val_accuracy: 0.8135\n",
      "Epoch 10/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.0069 - accuracy: 0.7622 - val_loss: 0.0097 - val_accuracy: 0.6165\n",
      "Epoch 11/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.0066 - accuracy: 0.6916 - val_loss: 0.0099 - val_accuracy: 0.5414\n",
      "Epoch 12/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.0059 - accuracy: 0.7360 - val_loss: 0.0095 - val_accuracy: 0.7654\n",
      "Epoch 13/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.0055 - accuracy: 0.7131 - val_loss: 0.0093 - val_accuracy: 0.6632\n",
      "Epoch 14/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.0053 - accuracy: 0.8012 - val_loss: 0.0101 - val_accuracy: 0.9669\n",
      "Epoch 15/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.0047 - accuracy: 0.7801 - val_loss: 0.0104 - val_accuracy: 0.7203\n",
      "Epoch 16/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.0045 - accuracy: 0.7547 - val_loss: 0.0098 - val_accuracy: 0.9353\n",
      "Epoch 17/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.0041 - accuracy: 0.8037 - val_loss: 0.0088 - val_accuracy: 0.5323\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.0038 - accuracy: 0.7103 - val_loss: 0.0092 - val_accuracy: 0.8827\n",
      "Epoch 19/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.0034 - accuracy: 0.7841 - val_loss: 0.0093 - val_accuracy: 0.6812\n",
      "Epoch 20/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.0029 - accuracy: 0.7883 - val_loss: 0.0103 - val_accuracy: 0.9128\n",
      "Epoch 21/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.0029 - accuracy: 0.7145 - val_loss: 0.0094 - val_accuracy: 0.6015\n",
      "Epoch 22/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.0024 - accuracy: 0.7888 - val_loss: 0.0097 - val_accuracy: 0.6617\n",
      "Epoch 23/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.0021 - accuracy: 0.8124 - val_loss: 0.0094 - val_accuracy: 0.8060\n",
      "Epoch 24/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.0019 - accuracy: 0.7985 - val_loss: 0.0101 - val_accuracy: 0.8541\n",
      "Epoch 25/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.0018 - accuracy: 0.7913 - val_loss: 0.0104 - val_accuracy: 0.6481\n",
      "Epoch 26/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.0015 - accuracy: 0.7348 - val_loss: 0.0102 - val_accuracy: 0.7654\n",
      "Epoch 27/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.0013 - accuracy: 0.8473 - val_loss: 0.0112 - val_accuracy: 0.7684\n",
      "Epoch 28/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.0012 - accuracy: 0.8008 - val_loss: 0.0101 - val_accuracy: 0.7970\n",
      "Epoch 29/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 9.9923e-04 - accuracy: 0.8633 - val_loss: 0.0115 - val_accuracy: 0.8632\n",
      "Epoch 30/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 8.8637e-04 - accuracy: 0.8498 - val_loss: 0.0111 - val_accuracy: 0.8211\n",
      "Epoch 31/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 8.0798e-04 - accuracy: 0.8299 - val_loss: 0.0121 - val_accuracy: 0.8812\n",
      "Epoch 32/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 7.4234e-04 - accuracy: 0.8219 - val_loss: 0.0113 - val_accuracy: 0.8015\n",
      "Epoch 33/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 7.0086e-04 - accuracy: 0.8170 - val_loss: 0.0114 - val_accuracy: 0.6917\n",
      "Epoch 34/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 5.1588e-04 - accuracy: 0.8256 - val_loss: 0.0122 - val_accuracy: 0.8602\n",
      "Epoch 35/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 3.9711e-04 - accuracy: 0.8297 - val_loss: 0.0122 - val_accuracy: 0.8105\n",
      "Epoch 36/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 3.3860e-04 - accuracy: 0.8264 - val_loss: 0.0128 - val_accuracy: 0.8241\n",
      "Epoch 37/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 3.3480e-04 - accuracy: 0.8135 - val_loss: 0.0119 - val_accuracy: 0.7940\n",
      "Epoch 38/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 2.7807e-04 - accuracy: 0.8291 - val_loss: 0.0121 - val_accuracy: 0.8241\n",
      "Epoch 39/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 2.2857e-04 - accuracy: 0.8525 - val_loss: 0.0133 - val_accuracy: 0.8376\n",
      "Epoch 40/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 2.1118e-04 - accuracy: 0.8488 - val_loss: 0.0129 - val_accuracy: 0.7940\n",
      "Epoch 41/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 1.8286e-04 - accuracy: 0.8102 - val_loss: 0.0134 - val_accuracy: 0.8000\n",
      "Epoch 42/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 1.6743e-04 - accuracy: 0.8331 - val_loss: 0.0127 - val_accuracy: 0.8015\n",
      "Epoch 43/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 1.4881e-04 - accuracy: 0.8266 - val_loss: 0.0137 - val_accuracy: 0.7985\n",
      "Epoch 44/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 1.3397e-04 - accuracy: 0.7876 - val_loss: 0.0135 - val_accuracy: 0.8090\n",
      "Epoch 45/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 1.1801e-04 - accuracy: 0.8311 - val_loss: 0.0139 - val_accuracy: 0.7789\n",
      "Epoch 46/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 1.1115e-04 - accuracy: 0.7997 - val_loss: 0.0139 - val_accuracy: 0.8135\n",
      "Epoch 47/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 1.0085e-04 - accuracy: 0.8453 - val_loss: 0.0139 - val_accuracy: 0.7429\n",
      "Epoch 48/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 9.4256e-05 - accuracy: 0.7898 - val_loss: 0.0142 - val_accuracy: 0.7880\n",
      "Epoch 49/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 8.3447e-05 - accuracy: 0.7920 - val_loss: 0.0144 - val_accuracy: 0.7820\n",
      "Epoch 50/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 7.6362e-05 - accuracy: 0.8020 - val_loss: 0.0146 - val_accuracy: 0.7865\n",
      "Epoch 51/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 7.1734e-05 - accuracy: 0.8015 - val_loss: 0.0151 - val_accuracy: 0.7774\n",
      "Epoch 52/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 6.6403e-05 - accuracy: 0.7911 - val_loss: 0.0149 - val_accuracy: 0.7850\n",
      "Epoch 53/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 6.4310e-05 - accuracy: 0.7805 - val_loss: 0.0143 - val_accuracy: 0.7744\n",
      "Epoch 54/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 5.3225e-05 - accuracy: 0.8060 - val_loss: 0.0143 - val_accuracy: 0.7489\n",
      "Epoch 55/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 5.0836e-05 - accuracy: 0.7714 - val_loss: 0.0152 - val_accuracy: 0.7789\n",
      "Epoch 56/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 4.8541e-05 - accuracy: 0.7863 - val_loss: 0.0150 - val_accuracy: 0.7564\n",
      "Epoch 57/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 4.7796e-05 - accuracy: 0.7803 - val_loss: 0.0154 - val_accuracy: 0.7429\n",
      "Epoch 58/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 4.0807e-05 - accuracy: 0.7763 - val_loss: 0.0151 - val_accuracy: 0.7429\n",
      "Epoch 59/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 3.9059e-05 - accuracy: 0.7706 - val_loss: 0.0154 - val_accuracy: 0.7293\n",
      "Epoch 60/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 3.5652e-05 - accuracy: 0.7536 - val_loss: 0.0154 - val_accuracy: 0.7444\n",
      "Epoch 61/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 3.3504e-05 - accuracy: 0.7763 - val_loss: 0.0156 - val_accuracy: 0.7579\n",
      "Epoch 62/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 3.1900e-05 - accuracy: 0.7689 - val_loss: 0.0153 - val_accuracy: 0.7459\n",
      "Epoch 63/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 2.8585e-05 - accuracy: 0.7606 - val_loss: 0.0156 - val_accuracy: 0.7368\n",
      "Epoch 64/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 2.7151e-05 - accuracy: 0.7621 - val_loss: 0.0157 - val_accuracy: 0.7338\n",
      "Epoch 65/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 2.5865e-05 - accuracy: 0.7420 - val_loss: 0.0157 - val_accuracy: 0.7068\n",
      "Epoch 66/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 2.3756e-05 - accuracy: 0.7559 - val_loss: 0.0162 - val_accuracy: 0.7173\n",
      "Epoch 67/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 2.2112e-05 - accuracy: 0.7320 - val_loss: 0.0161 - val_accuracy: 0.7429\n",
      "Epoch 68/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 2.1035e-05 - accuracy: 0.7591 - val_loss: 0.0161 - val_accuracy: 0.7263\n",
      "Epoch 69/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 1.9791e-05 - accuracy: 0.7594 - val_loss: 0.0163 - val_accuracy: 0.7188\n",
      "Epoch 70/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 1.8177e-05 - accuracy: 0.7285 - val_loss: 0.0167 - val_accuracy: 0.7233\n",
      "Epoch 71/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 1.7663e-05 - accuracy: 0.7343 - val_loss: 0.0167 - val_accuracy: 0.7263\n",
      "Epoch 72/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 1.6835e-05 - accuracy: 0.7400 - val_loss: 0.0164 - val_accuracy: 0.7143\n",
      "Epoch 73/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 1.5229e-05 - accuracy: 0.7375 - val_loss: 0.0167 - val_accuracy: 0.6992\n",
      "Epoch 74/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 1.3992e-05 - accuracy: 0.7178 - val_loss: 0.0164 - val_accuracy: 0.7188\n",
      "Epoch 75/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 1.3806e-05 - accuracy: 0.7425 - val_loss: 0.0169 - val_accuracy: 0.7504\n",
      "Epoch 76/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 1.2561e-05 - accuracy: 0.7460 - val_loss: 0.0168 - val_accuracy: 0.7113\n",
      "Epoch 77/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 1.1320e-05 - accuracy: 0.7141 - val_loss: 0.0175 - val_accuracy: 0.6902\n",
      "Epoch 78/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 1.1832e-05 - accuracy: 0.7246 - val_loss: 0.0170 - val_accuracy: 0.7053\n",
      "Epoch 79/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 1.0609e-05 - accuracy: 0.7253 - val_loss: 0.0170 - val_accuracy: 0.7218\n",
      "Epoch 80/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 1.0052e-05 - accuracy: 0.7223 - val_loss: 0.0175 - val_accuracy: 0.6992\n",
      "Epoch 81/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 9.3472e-06 - accuracy: 0.7186 - val_loss: 0.0177 - val_accuracy: 0.7068\n",
      "Epoch 82/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 9.0251e-06 - accuracy: 0.7307 - val_loss: 0.0174 - val_accuracy: 0.6947\n",
      "Epoch 83/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 8.4920e-06 - accuracy: 0.7131 - val_loss: 0.0177 - val_accuracy: 0.7128\n",
      "Epoch 84/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 7.8436e-06 - accuracy: 0.7188 - val_loss: 0.0181 - val_accuracy: 0.6707\n",
      "Epoch 85/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 7.5650e-06 - accuracy: 0.7061 - val_loss: 0.0175 - val_accuracy: 0.7158\n",
      "Epoch 86/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 7.0082e-06 - accuracy: 0.7131 - val_loss: 0.0177 - val_accuracy: 0.6947\n",
      "Epoch 87/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 6.7685e-06 - accuracy: 0.6942 - val_loss: 0.0179 - val_accuracy: 0.6586\n",
      "Epoch 88/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 6.1695e-06 - accuracy: 0.6966 - val_loss: 0.0179 - val_accuracy: 0.6902\n",
      "Epoch 89/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 6.0627e-06 - accuracy: 0.7061 - val_loss: 0.0184 - val_accuracy: 0.6752\n",
      "Epoch 90/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 5.8377e-06 - accuracy: 0.7078 - val_loss: 0.0181 - val_accuracy: 0.6842\n",
      "Epoch 91/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 5.3094e-06 - accuracy: 0.7063 - val_loss: 0.0182 - val_accuracy: 0.6632\n",
      "Epoch 92/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 5.1973e-06 - accuracy: 0.6916 - val_loss: 0.0182 - val_accuracy: 0.6797\n",
      "Epoch 93/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 4.7726e-06 - accuracy: 0.6894 - val_loss: 0.0187 - val_accuracy: 0.6647\n",
      "Epoch 94/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 4.5893e-06 - accuracy: 0.7069 - val_loss: 0.0185 - val_accuracy: 0.6602\n",
      "Epoch 95/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 4.2489e-06 - accuracy: 0.6879 - val_loss: 0.0189 - val_accuracy: 0.6737\n",
      "Epoch 96/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 4.2153e-06 - accuracy: 0.6924 - val_loss: 0.0187 - val_accuracy: 0.6842\n",
      "Epoch 97/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 3.8875e-06 - accuracy: 0.6994 - val_loss: 0.0188 - val_accuracy: 0.6677\n",
      "Epoch 98/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 3.5750e-06 - accuracy: 0.6871 - val_loss: 0.0185 - val_accuracy: 0.6737\n",
      "Epoch 99/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 3.5133e-06 - accuracy: 0.6881 - val_loss: 0.0194 - val_accuracy: 0.6556\n",
      "Epoch 100/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 3.4130e-06 - accuracy: 0.6784 - val_loss: 0.0192 - val_accuracy: 0.6782\n",
      "Score for fold 7 : loss of 0.01920318603515625 ; F1-Macro: 0.5829568270957477 F1-Micro: 0.9977443609022556\n",
      "Training...\n",
      "Epoch 1/100\n",
      "94/94 [==============================] - 1s 3ms/step - loss: 0.0598 - accuracy: 0.9414 - val_loss: 0.0128 - val_accuracy: 0.9910\n",
      "Epoch 2/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.0102 - accuracy: 0.8114 - val_loss: 0.0122 - val_accuracy: 0.3865\n",
      "Epoch 3/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.0098 - accuracy: 0.6145 - val_loss: 0.0122 - val_accuracy: 0.5098\n",
      "Epoch 4/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.0094 - accuracy: 0.5584 - val_loss: 0.0127 - val_accuracy: 0.7323\n",
      "Epoch 5/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.0090 - accuracy: 0.5881 - val_loss: 0.0123 - val_accuracy: 0.3459\n",
      "Epoch 6/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.0086 - accuracy: 0.6750 - val_loss: 0.0124 - val_accuracy: 0.3368\n",
      "Epoch 7/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.0079 - accuracy: 0.4563 - val_loss: 0.0126 - val_accuracy: 0.7699\n",
      "Epoch 8/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.0073 - accuracy: 0.6348 - val_loss: 0.0124 - val_accuracy: 0.6767\n",
      "Epoch 9/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.0064 - accuracy: 0.6739 - val_loss: 0.0150 - val_accuracy: 0.9459\n",
      "Epoch 10/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.0062 - accuracy: 0.8344 - val_loss: 0.0136 - val_accuracy: 0.7248\n",
      "Epoch 11/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.0054 - accuracy: 0.8048 - val_loss: 0.0149 - val_accuracy: 0.8692\n",
      "Epoch 12/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.0048 - accuracy: 0.8424 - val_loss: 0.0153 - val_accuracy: 0.8722\n",
      "Epoch 13/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.0044 - accuracy: 0.8815 - val_loss: 0.0163 - val_accuracy: 0.8571\n",
      "Epoch 14/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.0040 - accuracy: 0.9322 - val_loss: 0.0173 - val_accuracy: 0.8481\n",
      "Epoch 15/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.0036 - accuracy: 0.9268 - val_loss: 0.0180 - val_accuracy: 0.9353\n",
      "Epoch 16/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.0037 - accuracy: 0.8769 - val_loss: 0.0178 - val_accuracy: 0.9113\n",
      "Epoch 17/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.0029 - accuracy: 0.9228 - val_loss: 0.0184 - val_accuracy: 0.8827\n",
      "Epoch 18/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.0027 - accuracy: 0.9155 - val_loss: 0.0190 - val_accuracy: 0.8902\n",
      "Epoch 19/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.0025 - accuracy: 0.8819 - val_loss: 0.0201 - val_accuracy: 0.8060\n",
      "Epoch 20/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.0022 - accuracy: 0.9061 - val_loss: 0.0200 - val_accuracy: 0.8962\n",
      "Epoch 21/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.0022 - accuracy: 0.9268 - val_loss: 0.0209 - val_accuracy: 0.9173\n",
      "Epoch 22/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.0018 - accuracy: 0.9218 - val_loss: 0.0214 - val_accuracy: 0.8421\n",
      "Epoch 23/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.0017 - accuracy: 0.8844 - val_loss: 0.0216 - val_accuracy: 0.8436\n",
      "Epoch 24/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.0016 - accuracy: 0.9143 - val_loss: 0.0223 - val_accuracy: 0.9278\n",
      "Epoch 25/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.0014 - accuracy: 0.9322 - val_loss: 0.0228 - val_accuracy: 0.9173\n",
      "Epoch 26/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.0013 - accuracy: 0.9203 - val_loss: 0.0237 - val_accuracy: 0.8767\n",
      "Epoch 27/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.0011 - accuracy: 0.9108 - val_loss: 0.0237 - val_accuracy: 0.8782\n",
      "Epoch 28/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.0010 - accuracy: 0.8864 - val_loss: 0.0238 - val_accuracy: 0.8632\n",
      "Epoch 29/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 9.2703e-04 - accuracy: 0.8710 - val_loss: 0.0242 - val_accuracy: 0.8917\n",
      "Epoch 30/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94/94 [==============================] - 0s 2ms/step - loss: 0.0011 - accuracy: 0.8859 - val_loss: 0.0241 - val_accuracy: 0.8917\n",
      "Epoch 31/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 7.3397e-04 - accuracy: 0.8877 - val_loss: 0.0249 - val_accuracy: 0.8977\n",
      "Epoch 32/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 6.2807e-04 - accuracy: 0.8832 - val_loss: 0.0255 - val_accuracy: 0.8767\n",
      "Epoch 33/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 5.6379e-04 - accuracy: 0.8966 - val_loss: 0.0254 - val_accuracy: 0.8902\n",
      "Epoch 34/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 4.6648e-04 - accuracy: 0.8767 - val_loss: 0.0261 - val_accuracy: 0.8737\n",
      "Epoch 35/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 4.2671e-04 - accuracy: 0.8780 - val_loss: 0.0260 - val_accuracy: 0.8902\n",
      "Epoch 36/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 3.7453e-04 - accuracy: 0.8647 - val_loss: 0.0269 - val_accuracy: 0.8617\n",
      "Epoch 37/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 2.8844e-04 - accuracy: 0.8627 - val_loss: 0.0267 - val_accuracy: 0.8767\n",
      "Epoch 38/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 2.6969e-04 - accuracy: 0.8408 - val_loss: 0.0271 - val_accuracy: 0.8541\n",
      "Epoch 39/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 2.5422e-04 - accuracy: 0.8640 - val_loss: 0.0283 - val_accuracy: 0.8165\n",
      "Epoch 40/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 1.8695e-04 - accuracy: 0.8470 - val_loss: 0.0281 - val_accuracy: 0.8391\n",
      "Epoch 41/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 1.7471e-04 - accuracy: 0.8436 - val_loss: 0.0286 - val_accuracy: 0.8496\n",
      "Epoch 42/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 1.5524e-04 - accuracy: 0.8404 - val_loss: 0.0286 - val_accuracy: 0.8120\n",
      "Epoch 43/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 1.4528e-04 - accuracy: 0.8408 - val_loss: 0.0288 - val_accuracy: 0.8241\n",
      "Epoch 44/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 1.2300e-04 - accuracy: 0.8485 - val_loss: 0.0295 - val_accuracy: 0.8120\n",
      "Epoch 45/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 1.2980e-04 - accuracy: 0.8053 - val_loss: 0.0295 - val_accuracy: 0.8226\n",
      "Epoch 46/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 1.0733e-04 - accuracy: 0.8316 - val_loss: 0.0300 - val_accuracy: 0.7985\n",
      "Epoch 47/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 9.5894e-05 - accuracy: 0.8095 - val_loss: 0.0303 - val_accuracy: 0.8150\n",
      "Epoch 48/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 8.0255e-05 - accuracy: 0.8271 - val_loss: 0.0301 - val_accuracy: 0.8496\n",
      "Epoch 49/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 7.7871e-05 - accuracy: 0.8216 - val_loss: 0.0309 - val_accuracy: 0.8060\n",
      "Epoch 50/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 6.6797e-05 - accuracy: 0.8062 - val_loss: 0.0311 - val_accuracy: 0.7774\n",
      "Epoch 51/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 6.1536e-05 - accuracy: 0.7957 - val_loss: 0.0312 - val_accuracy: 0.7654\n",
      "Epoch 52/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 5.6709e-05 - accuracy: 0.7823 - val_loss: 0.0315 - val_accuracy: 0.8060\n",
      "Epoch 53/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 5.4656e-05 - accuracy: 0.8095 - val_loss: 0.0316 - val_accuracy: 0.7880\n",
      "Epoch 54/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 4.7653e-05 - accuracy: 0.7970 - val_loss: 0.0316 - val_accuracy: 0.8045\n",
      "Epoch 55/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 4.4920e-05 - accuracy: 0.7821 - val_loss: 0.0325 - val_accuracy: 0.7609\n",
      "Epoch 56/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 4.3086e-05 - accuracy: 0.7704 - val_loss: 0.0325 - val_accuracy: 0.7654\n",
      "Epoch 57/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 3.9819e-05 - accuracy: 0.7997 - val_loss: 0.0321 - val_accuracy: 0.7835\n",
      "Epoch 58/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 3.8444e-05 - accuracy: 0.7709 - val_loss: 0.0326 - val_accuracy: 0.7639\n",
      "Epoch 59/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 3.4665e-05 - accuracy: 0.7681 - val_loss: 0.0329 - val_accuracy: 0.7714\n",
      "Epoch 60/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 3.0446e-05 - accuracy: 0.7758 - val_loss: 0.0335 - val_accuracy: 0.7444\n",
      "Epoch 61/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 2.9615e-05 - accuracy: 0.7676 - val_loss: 0.0330 - val_accuracy: 0.7474\n",
      "Epoch 62/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 2.8174e-05 - accuracy: 0.7584 - val_loss: 0.0339 - val_accuracy: 0.7654\n",
      "Epoch 63/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 2.5235e-05 - accuracy: 0.7589 - val_loss: 0.0338 - val_accuracy: 0.7383\n",
      "Epoch 64/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 2.4522e-05 - accuracy: 0.7619 - val_loss: 0.0343 - val_accuracy: 0.7203\n",
      "Epoch 65/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 2.2430e-05 - accuracy: 0.7450 - val_loss: 0.0341 - val_accuracy: 0.7383\n",
      "Epoch 66/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 2.0683e-05 - accuracy: 0.7460 - val_loss: 0.0346 - val_accuracy: 0.7278\n",
      "Epoch 67/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 1.9418e-05 - accuracy: 0.7338 - val_loss: 0.0347 - val_accuracy: 0.7398\n",
      "Epoch 68/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 1.7791e-05 - accuracy: 0.7505 - val_loss: 0.0351 - val_accuracy: 0.7293\n",
      "Epoch 69/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 1.7786e-05 - accuracy: 0.7527 - val_loss: 0.0354 - val_accuracy: 0.7218\n",
      "Epoch 70/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 1.6174e-05 - accuracy: 0.7353 - val_loss: 0.0356 - val_accuracy: 0.7248\n",
      "Epoch 71/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 1.4278e-05 - accuracy: 0.7370 - val_loss: 0.0360 - val_accuracy: 0.6947\n",
      "Epoch 72/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 1.4852e-05 - accuracy: 0.7338 - val_loss: 0.0358 - val_accuracy: 0.7218\n",
      "Epoch 73/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 1.3232e-05 - accuracy: 0.7298 - val_loss: 0.0360 - val_accuracy: 0.6977\n",
      "Epoch 74/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 1.3060e-05 - accuracy: 0.7200 - val_loss: 0.0357 - val_accuracy: 0.7368\n",
      "Epoch 75/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 1.2468e-05 - accuracy: 0.7245 - val_loss: 0.0364 - val_accuracy: 0.7098\n",
      "Epoch 76/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 1.0675e-05 - accuracy: 0.7023 - val_loss: 0.0368 - val_accuracy: 0.6767\n",
      "Epoch 77/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 1.0105e-05 - accuracy: 0.7044 - val_loss: 0.0368 - val_accuracy: 0.7248\n",
      "Epoch 78/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 9.6195e-06 - accuracy: 0.7191 - val_loss: 0.0370 - val_accuracy: 0.7173\n",
      "Epoch 79/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 9.2642e-06 - accuracy: 0.7141 - val_loss: 0.0371 - val_accuracy: 0.6812\n",
      "Epoch 80/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 8.4133e-06 - accuracy: 0.7049 - val_loss: 0.0372 - val_accuracy: 0.7008\n",
      "Epoch 81/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 8.1332e-06 - accuracy: 0.7078 - val_loss: 0.0372 - val_accuracy: 0.6827\n",
      "Epoch 82/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 7.6700e-06 - accuracy: 0.6972 - val_loss: 0.0376 - val_accuracy: 0.6947\n",
      "Epoch 83/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 7.3322e-06 - accuracy: 0.7063 - val_loss: 0.0378 - val_accuracy: 0.6917\n",
      "Epoch 84/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 6.9453e-06 - accuracy: 0.7003 - val_loss: 0.0380 - val_accuracy: 0.6962\n",
      "Epoch 85/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 6.3420e-06 - accuracy: 0.6862 - val_loss: 0.0383 - val_accuracy: 0.6571\n",
      "Epoch 86/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 5.8569e-06 - accuracy: 0.7156 - val_loss: 0.0388 - val_accuracy: 0.6571\n",
      "Epoch 87/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 6.3523e-06 - accuracy: 0.6837 - val_loss: 0.0383 - val_accuracy: 0.6887\n",
      "Epoch 88/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 5.5978e-06 - accuracy: 0.6889 - val_loss: 0.0388 - val_accuracy: 0.6707\n",
      "Epoch 89/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 5.0820e-06 - accuracy: 0.6835 - val_loss: 0.0387 - val_accuracy: 0.6887\n",
      "Epoch 90/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 4.8452e-06 - accuracy: 0.6804 - val_loss: 0.0393 - val_accuracy: 0.6707\n",
      "Epoch 91/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 4.5952e-06 - accuracy: 0.6695 - val_loss: 0.0393 - val_accuracy: 0.6797\n",
      "Epoch 92/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 4.4465e-06 - accuracy: 0.6854 - val_loss: 0.0393 - val_accuracy: 0.6632\n",
      "Epoch 93/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 4.3126e-06 - accuracy: 0.6708 - val_loss: 0.0397 - val_accuracy: 0.6406\n",
      "Epoch 94/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 3.8960e-06 - accuracy: 0.6623 - val_loss: 0.0399 - val_accuracy: 0.6481\n",
      "Epoch 95/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 3.7483e-06 - accuracy: 0.6872 - val_loss: 0.0401 - val_accuracy: 0.6677\n",
      "Epoch 96/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 3.5554e-06 - accuracy: 0.6585 - val_loss: 0.0399 - val_accuracy: 0.6722\n",
      "Epoch 97/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 3.5054e-06 - accuracy: 0.6734 - val_loss: 0.0400 - val_accuracy: 0.6451\n",
      "Epoch 98/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 3.3310e-06 - accuracy: 0.6617 - val_loss: 0.0403 - val_accuracy: 0.6556\n",
      "Epoch 99/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 3.0176e-06 - accuracy: 0.6710 - val_loss: 0.0405 - val_accuracy: 0.6586\n",
      "Epoch 100/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 3.1356e-06 - accuracy: 0.6617 - val_loss: 0.0412 - val_accuracy: 0.6526\n",
      "Score for fold 8 : loss of 0.041157759726047516 ; F1-Macro: 0.5825796589696587 F1-Micro: 0.9964252116650988\n",
      "Training...\n",
      "Epoch 1/100\n",
      "94/94 [==============================] - 1s 3ms/step - loss: 0.0639 - accuracy: 0.1191 - val_loss: 0.0058 - val_accuracy: 0.3955\n",
      "Epoch 2/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.0110 - accuracy: 0.4493 - val_loss: 0.0058 - val_accuracy: 0.5128\n",
      "Epoch 3/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.0106 - accuracy: 0.5034 - val_loss: 0.0056 - val_accuracy: 0.4331\n",
      "Epoch 4/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.0103 - accuracy: 0.4974 - val_loss: 0.0055 - val_accuracy: 0.4165\n",
      "Epoch 5/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.0098 - accuracy: 0.4209 - val_loss: 0.0060 - val_accuracy: 0.5113\n",
      "Epoch 6/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.0094 - accuracy: 0.3684 - val_loss: 0.0054 - val_accuracy: 0.3654\n",
      "Epoch 7/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.0087 - accuracy: 0.3208 - val_loss: 0.0053 - val_accuracy: 0.3053\n",
      "Epoch 8/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.0081 - accuracy: 0.3270 - val_loss: 0.0051 - val_accuracy: 0.2481\n",
      "Epoch 9/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.0076 - accuracy: 0.2707 - val_loss: 0.0061 - val_accuracy: 0.1414\n",
      "Epoch 10/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.0069 - accuracy: 0.2282 - val_loss: 0.0080 - val_accuracy: 0.2602\n",
      "Epoch 11/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.0064 - accuracy: 0.2845 - val_loss: 0.0053 - val_accuracy: 0.3895\n",
      "Epoch 12/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.0060 - accuracy: 0.2409 - val_loss: 0.0070 - val_accuracy: 0.2947\n",
      "Epoch 13/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.0055 - accuracy: 0.3099 - val_loss: 0.0061 - val_accuracy: 0.3880\n",
      "Epoch 14/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.0049 - accuracy: 0.2212 - val_loss: 0.0061 - val_accuracy: 0.2782\n",
      "Epoch 15/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.0047 - accuracy: 0.2670 - val_loss: 0.0061 - val_accuracy: 0.1985\n",
      "Epoch 16/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.0039 - accuracy: 0.2451 - val_loss: 0.0066 - val_accuracy: 0.3383\n",
      "Epoch 17/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.0038 - accuracy: 0.2563 - val_loss: 0.0064 - val_accuracy: 0.2060\n",
      "Epoch 18/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.0037 - accuracy: 0.2307 - val_loss: 0.0061 - val_accuracy: 0.1534\n",
      "Epoch 19/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.0031 - accuracy: 0.2269 - val_loss: 0.0071 - val_accuracy: 0.1534\n",
      "Epoch 20/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.0028 - accuracy: 0.2389 - val_loss: 0.0066 - val_accuracy: 0.1083\n",
      "Epoch 21/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.0024 - accuracy: 0.1365 - val_loss: 0.0070 - val_accuracy: 0.3714\n",
      "Epoch 22/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.0022 - accuracy: 0.1729 - val_loss: 0.0066 - val_accuracy: 0.1008\n",
      "Epoch 23/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.0019 - accuracy: 0.0937 - val_loss: 0.0072 - val_accuracy: 0.0932\n",
      "Epoch 24/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.0022 - accuracy: 0.1290 - val_loss: 0.0066 - val_accuracy: 0.2075\n",
      "Epoch 25/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.0017 - accuracy: 0.0810 - val_loss: 0.0079 - val_accuracy: 0.1820\n",
      "Epoch 26/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.0016 - accuracy: 0.0892 - val_loss: 0.0078 - val_accuracy: 0.0195\n",
      "Epoch 27/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.0013 - accuracy: 0.0705 - val_loss: 0.0076 - val_accuracy: 0.0301\n",
      "Epoch 28/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.0011 - accuracy: 0.0632 - val_loss: 0.0075 - val_accuracy: 0.0466\n",
      "Epoch 29/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 9.9701e-04 - accuracy: 0.0939 - val_loss: 0.0078 - val_accuracy: 0.1459\n",
      "Epoch 30/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 8.8625e-04 - accuracy: 0.0987 - val_loss: 0.0075 - val_accuracy: 0.1278\n",
      "Epoch 31/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 7.9316e-04 - accuracy: 0.1016 - val_loss: 0.0083 - val_accuracy: 0.0722\n",
      "Epoch 32/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 6.6682e-04 - accuracy: 0.0899 - val_loss: 0.0079 - val_accuracy: 0.1008\n",
      "Epoch 33/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 5.4483e-04 - accuracy: 0.0877 - val_loss: 0.0085 - val_accuracy: 0.1038\n",
      "Epoch 34/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 4.7780e-04 - accuracy: 0.0889 - val_loss: 0.0081 - val_accuracy: 0.1008\n",
      "Epoch 35/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 4.2892e-04 - accuracy: 0.1106 - val_loss: 0.0089 - val_accuracy: 0.1173\n",
      "Epoch 36/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 3.5514e-04 - accuracy: 0.1073 - val_loss: 0.0092 - val_accuracy: 0.1248\n",
      "Epoch 37/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 3.6742e-04 - accuracy: 0.1135 - val_loss: 0.0083 - val_accuracy: 0.1173\n",
      "Epoch 38/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 3.0314e-04 - accuracy: 0.1297 - val_loss: 0.0088 - val_accuracy: 0.1308\n",
      "Epoch 39/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 2.4809e-04 - accuracy: 0.1510 - val_loss: 0.0088 - val_accuracy: 0.1293\n",
      "Epoch 40/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 2.2463e-04 - accuracy: 0.1343 - val_loss: 0.0086 - val_accuracy: 0.1669\n",
      "Epoch 41/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 2.0460e-04 - accuracy: 0.1425 - val_loss: 0.0095 - val_accuracy: 0.1233\n",
      "Epoch 42/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94/94 [==============================] - 0s 2ms/step - loss: 1.8831e-04 - accuracy: 0.1233 - val_loss: 0.0092 - val_accuracy: 0.1308\n",
      "Epoch 43/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 1.7025e-04 - accuracy: 0.1490 - val_loss: 0.0093 - val_accuracy: 0.1579\n",
      "Epoch 44/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 1.2599e-04 - accuracy: 0.1519 - val_loss: 0.0101 - val_accuracy: 0.1173\n",
      "Epoch 45/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 1.2710e-04 - accuracy: 0.1345 - val_loss: 0.0098 - val_accuracy: 0.1429\n",
      "Epoch 46/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 1.0590e-04 - accuracy: 0.1587 - val_loss: 0.0099 - val_accuracy: 0.1669\n",
      "Epoch 47/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 9.4521e-05 - accuracy: 0.1729 - val_loss: 0.0101 - val_accuracy: 0.1970\n",
      "Epoch 48/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 9.5352e-05 - accuracy: 0.1664 - val_loss: 0.0101 - val_accuracy: 0.2060\n",
      "Epoch 49/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 8.6893e-05 - accuracy: 0.1758 - val_loss: 0.0103 - val_accuracy: 0.1654\n",
      "Epoch 50/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 7.6094e-05 - accuracy: 0.1796 - val_loss: 0.0104 - val_accuracy: 0.1925\n",
      "Epoch 51/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 6.9615e-05 - accuracy: 0.1801 - val_loss: 0.0105 - val_accuracy: 0.1970\n",
      "Epoch 52/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 6.6394e-05 - accuracy: 0.1958 - val_loss: 0.0105 - val_accuracy: 0.1669\n",
      "Epoch 53/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 5.7791e-05 - accuracy: 0.1791 - val_loss: 0.0104 - val_accuracy: 0.1624\n",
      "Epoch 54/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 5.3968e-05 - accuracy: 0.1703 - val_loss: 0.0110 - val_accuracy: 0.1338\n",
      "Epoch 55/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 5.1747e-05 - accuracy: 0.1541 - val_loss: 0.0107 - val_accuracy: 0.1789\n",
      "Epoch 56/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 4.5481e-05 - accuracy: 0.1671 - val_loss: 0.0111 - val_accuracy: 0.1639\n",
      "Epoch 57/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 4.4924e-05 - accuracy: 0.1916 - val_loss: 0.0106 - val_accuracy: 0.2105\n",
      "Epoch 58/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 4.0612e-05 - accuracy: 0.1831 - val_loss: 0.0111 - val_accuracy: 0.1684\n",
      "Epoch 59/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 3.6556e-05 - accuracy: 0.1746 - val_loss: 0.0111 - val_accuracy: 0.1970\n",
      "Epoch 60/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 3.5432e-05 - accuracy: 0.1880 - val_loss: 0.0115 - val_accuracy: 0.1714\n",
      "Epoch 61/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 3.4304e-05 - accuracy: 0.1704 - val_loss: 0.0112 - val_accuracy: 0.1910\n",
      "Epoch 62/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 2.9639e-05 - accuracy: 0.1820 - val_loss: 0.0117 - val_accuracy: 0.1624\n",
      "Epoch 63/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 2.9494e-05 - accuracy: 0.1769 - val_loss: 0.0118 - val_accuracy: 0.1910\n",
      "Epoch 64/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 2.7797e-05 - accuracy: 0.2017 - val_loss: 0.0116 - val_accuracy: 0.2060\n",
      "Epoch 65/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 2.4432e-05 - accuracy: 0.1970 - val_loss: 0.0117 - val_accuracy: 0.1910\n",
      "Epoch 66/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 2.2059e-05 - accuracy: 0.1828 - val_loss: 0.0119 - val_accuracy: 0.1910\n",
      "Epoch 67/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 2.1803e-05 - accuracy: 0.1868 - val_loss: 0.0122 - val_accuracy: 0.1910\n",
      "Epoch 68/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 1.9922e-05 - accuracy: 0.2067 - val_loss: 0.0121 - val_accuracy: 0.1774\n",
      "Epoch 69/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 1.8762e-05 - accuracy: 0.1751 - val_loss: 0.0122 - val_accuracy: 0.1850\n",
      "Epoch 70/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 1.7693e-05 - accuracy: 0.1913 - val_loss: 0.0124 - val_accuracy: 0.1744\n",
      "Epoch 71/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 1.6254e-05 - accuracy: 0.1865 - val_loss: 0.0121 - val_accuracy: 0.2211\n",
      "Epoch 72/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 1.5523e-05 - accuracy: 0.2028 - val_loss: 0.0125 - val_accuracy: 0.1820\n",
      "Epoch 73/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 1.4860e-05 - accuracy: 0.1850 - val_loss: 0.0123 - val_accuracy: 0.1835\n",
      "Epoch 74/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 1.3736e-05 - accuracy: 0.1945 - val_loss: 0.0127 - val_accuracy: 0.1744\n",
      "Epoch 75/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 1.2866e-05 - accuracy: 0.1825 - val_loss: 0.0128 - val_accuracy: 0.1850\n",
      "Epoch 76/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 1.2199e-05 - accuracy: 0.1868 - val_loss: 0.0128 - val_accuracy: 0.1805\n",
      "Epoch 77/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 1.1287e-05 - accuracy: 0.2027 - val_loss: 0.0133 - val_accuracy: 0.1805\n",
      "Epoch 78/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 1.1353e-05 - accuracy: 0.1784 - val_loss: 0.0127 - val_accuracy: 0.1955\n",
      "Epoch 79/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 1.0109e-05 - accuracy: 0.1923 - val_loss: 0.0134 - val_accuracy: 0.1805\n",
      "Epoch 80/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 9.5122e-06 - accuracy: 0.1840 - val_loss: 0.0132 - val_accuracy: 0.1774\n",
      "Epoch 81/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 8.9849e-06 - accuracy: 0.1898 - val_loss: 0.0132 - val_accuracy: 0.1820\n",
      "Epoch 82/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 8.6252e-06 - accuracy: 0.1885 - val_loss: 0.0131 - val_accuracy: 0.1985\n",
      "Epoch 83/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 8.1402e-06 - accuracy: 0.1896 - val_loss: 0.0136 - val_accuracy: 0.1669\n",
      "Epoch 84/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 7.9139e-06 - accuracy: 0.1866 - val_loss: 0.0134 - val_accuracy: 0.1925\n",
      "Epoch 85/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 7.2288e-06 - accuracy: 0.1816 - val_loss: 0.0135 - val_accuracy: 0.1865\n",
      "Epoch 86/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 6.8499e-06 - accuracy: 0.1883 - val_loss: 0.0137 - val_accuracy: 0.1684\n",
      "Epoch 87/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 6.6553e-06 - accuracy: 0.1835 - val_loss: 0.0136 - val_accuracy: 0.1910\n",
      "Epoch 88/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 6.1872e-06 - accuracy: 0.1835 - val_loss: 0.0137 - val_accuracy: 0.1820\n",
      "Epoch 89/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 5.5172e-06 - accuracy: 0.1846 - val_loss: 0.0142 - val_accuracy: 0.1774\n",
      "Epoch 90/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 5.9661e-06 - accuracy: 0.1990 - val_loss: 0.0135 - val_accuracy: 0.2180\n",
      "Epoch 91/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 5.1971e-06 - accuracy: 0.1870 - val_loss: 0.0139 - val_accuracy: 0.1759\n",
      "Epoch 92/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 4.9214e-06 - accuracy: 0.1918 - val_loss: 0.0137 - val_accuracy: 0.1985\n",
      "Epoch 93/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 4.6752e-06 - accuracy: 0.1840 - val_loss: 0.0141 - val_accuracy: 0.1895\n",
      "Epoch 94/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 4.3705e-06 - accuracy: 0.1855 - val_loss: 0.0141 - val_accuracy: 0.2090\n",
      "Epoch 95/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 4.1350e-06 - accuracy: 0.1840 - val_loss: 0.0143 - val_accuracy: 0.1759\n",
      "Epoch 96/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 3.8348e-06 - accuracy: 0.1803 - val_loss: 0.0143 - val_accuracy: 0.1955\n",
      "Epoch 97/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 3.7050e-06 - accuracy: 0.1925 - val_loss: 0.0145 - val_accuracy: 0.1669\n",
      "Epoch 98/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 3.4955e-06 - accuracy: 0.1748 - val_loss: 0.0143 - val_accuracy: 0.1880\n",
      "Epoch 99/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 3.3714e-06 - accuracy: 0.1863 - val_loss: 0.0146 - val_accuracy: 0.1820\n",
      "Epoch 100/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 3.0904e-06 - accuracy: 0.1701 - val_loss: 0.0148 - val_accuracy: 0.1624\n",
      "Score for fold 9 : loss of 0.014830554835498333 ; F1-Macro: 0.9164782717910073 F1-Micro: 0.9988721804511278\n",
      "Training...\n",
      "Epoch 1/100\n",
      "94/94 [==============================] - 1s 3ms/step - loss: 0.0564 - accuracy: 0.0386 - val_loss: 0.0142 - val_accuracy: 0.2857\n",
      "Epoch 2/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.0100 - accuracy: 0.4642 - val_loss: 0.0138 - val_accuracy: 0.5880\n",
      "Epoch 3/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.0097 - accuracy: 0.3783 - val_loss: 0.0137 - val_accuracy: 0.4947\n",
      "Epoch 4/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.0093 - accuracy: 0.4409 - val_loss: 0.0135 - val_accuracy: 0.5624\n",
      "Epoch 5/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.0089 - accuracy: 0.4157 - val_loss: 0.0135 - val_accuracy: 0.2165\n",
      "Epoch 6/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.0085 - accuracy: 0.4060 - val_loss: 0.0128 - val_accuracy: 0.5098\n",
      "Epoch 7/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.0082 - accuracy: 0.3746 - val_loss: 0.0127 - val_accuracy: 0.1699\n",
      "Epoch 8/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.0078 - accuracy: 0.2687 - val_loss: 0.0134 - val_accuracy: 0.1820\n",
      "Epoch 9/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.0072 - accuracy: 0.3048 - val_loss: 0.0127 - val_accuracy: 0.4331\n",
      "Epoch 10/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.0066 - accuracy: 0.2747 - val_loss: 0.0142 - val_accuracy: 0.0662\n",
      "Epoch 11/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.0063 - accuracy: 0.3181 - val_loss: 0.0126 - val_accuracy: 0.1910\n",
      "Epoch 12/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.0056 - accuracy: 0.3133 - val_loss: 0.0138 - val_accuracy: 0.3805\n",
      "Epoch 13/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.0051 - accuracy: 0.3649 - val_loss: 0.0137 - val_accuracy: 0.3158\n",
      "Epoch 14/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.0047 - accuracy: 0.3049 - val_loss: 0.0138 - val_accuracy: 0.3774\n",
      "Epoch 15/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.0042 - accuracy: 0.4175 - val_loss: 0.0145 - val_accuracy: 0.2887\n",
      "Epoch 16/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.0039 - accuracy: 0.3507 - val_loss: 0.0145 - val_accuracy: 0.4797\n",
      "Epoch 17/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.0034 - accuracy: 0.3701 - val_loss: 0.0168 - val_accuracy: 0.5459\n",
      "Epoch 18/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.0034 - accuracy: 0.4854 - val_loss: 0.0161 - val_accuracy: 0.4451\n",
      "Epoch 19/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.0031 - accuracy: 0.4094 - val_loss: 0.0149 - val_accuracy: 0.3113\n",
      "Epoch 20/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.0027 - accuracy: 0.5300 - val_loss: 0.0174 - val_accuracy: 0.3729\n",
      "Epoch 21/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.0024 - accuracy: 0.4247 - val_loss: 0.0157 - val_accuracy: 0.5594\n",
      "Epoch 22/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.0022 - accuracy: 0.6053 - val_loss: 0.0159 - val_accuracy: 0.4722\n",
      "Epoch 23/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.0020 - accuracy: 0.5626 - val_loss: 0.0170 - val_accuracy: 0.4677\n",
      "Epoch 24/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.0017 - accuracy: 0.5420 - val_loss: 0.0184 - val_accuracy: 0.6496\n",
      "Epoch 25/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.0016 - accuracy: 0.6035 - val_loss: 0.0190 - val_accuracy: 0.6105\n",
      "Epoch 26/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.0014 - accuracy: 0.6739 - val_loss: 0.0189 - val_accuracy: 0.6316\n",
      "Epoch 27/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.0012 - accuracy: 0.5034 - val_loss: 0.0194 - val_accuracy: 0.5233\n",
      "Epoch 28/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 9.4534e-04 - accuracy: 0.5522 - val_loss: 0.0202 - val_accuracy: 0.6015\n",
      "Epoch 29/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 8.6064e-04 - accuracy: 0.5512 - val_loss: 0.0208 - val_accuracy: 0.5368\n",
      "Epoch 30/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 7.9739e-04 - accuracy: 0.6025 - val_loss: 0.0216 - val_accuracy: 0.6526\n",
      "Epoch 31/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 6.4587e-04 - accuracy: 0.5733 - val_loss: 0.0210 - val_accuracy: 0.5850\n",
      "Epoch 32/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 5.1679e-04 - accuracy: 0.5958 - val_loss: 0.0217 - val_accuracy: 0.6526\n",
      "Epoch 33/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 4.7664e-04 - accuracy: 0.5317 - val_loss: 0.0216 - val_accuracy: 0.4632\n",
      "Epoch 34/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 3.7879e-04 - accuracy: 0.5861 - val_loss: 0.0226 - val_accuracy: 0.4782\n",
      "Epoch 35/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 3.3598e-04 - accuracy: 0.4991 - val_loss: 0.0230 - val_accuracy: 0.5414\n",
      "Epoch 36/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 3.0891e-04 - accuracy: 0.5647 - val_loss: 0.0235 - val_accuracy: 0.4692\n",
      "Epoch 37/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 2.3067e-04 - accuracy: 0.5043 - val_loss: 0.0237 - val_accuracy: 0.4872\n",
      "Epoch 38/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 2.1239e-04 - accuracy: 0.5073 - val_loss: 0.0244 - val_accuracy: 0.5338\n",
      "Epoch 39/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 1.8154e-04 - accuracy: 0.5378 - val_loss: 0.0245 - val_accuracy: 0.5353\n",
      "Epoch 40/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 1.6313e-04 - accuracy: 0.5143 - val_loss: 0.0245 - val_accuracy: 0.5895\n",
      "Epoch 41/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 1.5527e-04 - accuracy: 0.5206 - val_loss: 0.0256 - val_accuracy: 0.5519\n",
      "Epoch 42/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 1.3216e-04 - accuracy: 0.5190 - val_loss: 0.0262 - val_accuracy: 0.5038\n",
      "Epoch 43/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 1.2848e-04 - accuracy: 0.4784 - val_loss: 0.0264 - val_accuracy: 0.4872\n",
      "Epoch 44/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 1.0425e-04 - accuracy: 0.4865 - val_loss: 0.0264 - val_accuracy: 0.5128\n",
      "Epoch 45/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 9.5354e-05 - accuracy: 0.5044 - val_loss: 0.0268 - val_accuracy: 0.4992\n",
      "Epoch 46/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 8.9902e-05 - accuracy: 0.5114 - val_loss: 0.0264 - val_accuracy: 0.5398\n",
      "Epoch 47/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 8.1898e-05 - accuracy: 0.4929 - val_loss: 0.0276 - val_accuracy: 0.4632\n",
      "Epoch 48/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 7.2589e-05 - accuracy: 0.4954 - val_loss: 0.0280 - val_accuracy: 0.5143\n",
      "Epoch 49/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 6.6679e-05 - accuracy: 0.4852 - val_loss: 0.0279 - val_accuracy: 0.4692\n",
      "Epoch 50/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 6.2625e-05 - accuracy: 0.4638 - val_loss: 0.0279 - val_accuracy: 0.5323\n",
      "Epoch 51/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 5.6500e-05 - accuracy: 0.5089 - val_loss: 0.0289 - val_accuracy: 0.4571\n",
      "Epoch 52/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 5.1667e-05 - accuracy: 0.5250 - val_loss: 0.0289 - val_accuracy: 0.5083\n",
      "Epoch 53/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 4.6711e-05 - accuracy: 0.4937 - val_loss: 0.0291 - val_accuracy: 0.5038\n",
      "Epoch 54/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94/94 [==============================] - 0s 2ms/step - loss: 4.4495e-05 - accuracy: 0.5116 - val_loss: 0.0291 - val_accuracy: 0.4887\n",
      "Epoch 55/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 4.1128e-05 - accuracy: 0.4690 - val_loss: 0.0296 - val_accuracy: 0.4857\n",
      "Epoch 56/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 3.8211e-05 - accuracy: 0.5001 - val_loss: 0.0293 - val_accuracy: 0.5218\n",
      "Epoch 57/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 3.5630e-05 - accuracy: 0.4896 - val_loss: 0.0297 - val_accuracy: 0.5248\n",
      "Epoch 58/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 3.3011e-05 - accuracy: 0.5018 - val_loss: 0.0300 - val_accuracy: 0.5188\n",
      "Epoch 59/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 2.9827e-05 - accuracy: 0.4994 - val_loss: 0.0306 - val_accuracy: 0.4602\n",
      "Epoch 60/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 2.8377e-05 - accuracy: 0.4576 - val_loss: 0.0302 - val_accuracy: 0.4782\n",
      "Epoch 61/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 2.6353e-05 - accuracy: 0.4894 - val_loss: 0.0308 - val_accuracy: 0.4842\n",
      "Epoch 62/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 2.4815e-05 - accuracy: 0.4949 - val_loss: 0.0310 - val_accuracy: 0.4932\n",
      "Epoch 63/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 2.2955e-05 - accuracy: 0.4962 - val_loss: 0.0314 - val_accuracy: 0.4692\n",
      "Epoch 64/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 2.1727e-05 - accuracy: 0.4809 - val_loss: 0.0321 - val_accuracy: 0.4256\n",
      "Epoch 65/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 1.9709e-05 - accuracy: 0.4698 - val_loss: 0.0310 - val_accuracy: 0.4632\n",
      "Epoch 66/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 1.8279e-05 - accuracy: 0.4610 - val_loss: 0.0318 - val_accuracy: 0.4752\n",
      "Epoch 67/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 1.7570e-05 - accuracy: 0.5001 - val_loss: 0.0323 - val_accuracy: 0.4526\n",
      "Epoch 68/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 1.6648e-05 - accuracy: 0.4817 - val_loss: 0.0325 - val_accuracy: 0.4617\n",
      "Epoch 69/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 1.5566e-05 - accuracy: 0.4805 - val_loss: 0.0324 - val_accuracy: 0.5263\n",
      "Epoch 70/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 1.5122e-05 - accuracy: 0.4705 - val_loss: 0.0332 - val_accuracy: 0.4737\n",
      "Epoch 71/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 1.3894e-05 - accuracy: 0.5039 - val_loss: 0.0325 - val_accuracy: 0.5143\n",
      "Epoch 72/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 1.3832e-05 - accuracy: 0.4740 - val_loss: 0.0322 - val_accuracy: 0.4662\n",
      "Epoch 73/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 1.1883e-05 - accuracy: 0.4807 - val_loss: 0.0336 - val_accuracy: 0.5083\n",
      "Epoch 74/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 1.1216e-05 - accuracy: 0.5063 - val_loss: 0.0332 - val_accuracy: 0.4842\n",
      "Epoch 75/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 1.1395e-05 - accuracy: 0.4722 - val_loss: 0.0332 - val_accuracy: 0.4977\n",
      "Epoch 76/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 9.9364e-06 - accuracy: 0.4774 - val_loss: 0.0348 - val_accuracy: 0.4346\n",
      "Epoch 77/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 9.6624e-06 - accuracy: 0.4687 - val_loss: 0.0341 - val_accuracy: 0.4872\n",
      "Epoch 78/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 8.9915e-06 - accuracy: 0.4922 - val_loss: 0.0341 - val_accuracy: 0.4677\n",
      "Epoch 79/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 9.1984e-06 - accuracy: 0.4602 - val_loss: 0.0347 - val_accuracy: 0.4617\n",
      "Epoch 80/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 8.5618e-06 - accuracy: 0.4901 - val_loss: 0.0345 - val_accuracy: 0.4692\n",
      "Epoch 81/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 7.4668e-06 - accuracy: 0.4727 - val_loss: 0.0348 - val_accuracy: 0.5083\n",
      "Epoch 82/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 6.9569e-06 - accuracy: 0.4767 - val_loss: 0.0357 - val_accuracy: 0.4286\n",
      "Epoch 83/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 6.8453e-06 - accuracy: 0.4513 - val_loss: 0.0354 - val_accuracy: 0.4496\n",
      "Epoch 84/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 6.5715e-06 - accuracy: 0.4784 - val_loss: 0.0354 - val_accuracy: 0.4436\n",
      "Epoch 85/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 6.0571e-06 - accuracy: 0.4615 - val_loss: 0.0355 - val_accuracy: 0.4737\n",
      "Epoch 86/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 5.6665e-06 - accuracy: 0.4730 - val_loss: 0.0356 - val_accuracy: 0.5053\n",
      "Epoch 87/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 5.3331e-06 - accuracy: 0.4750 - val_loss: 0.0366 - val_accuracy: 0.4481\n",
      "Epoch 88/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 5.1696e-06 - accuracy: 0.4807 - val_loss: 0.0359 - val_accuracy: 0.4737\n",
      "Epoch 89/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 4.8533e-06 - accuracy: 0.4637 - val_loss: 0.0365 - val_accuracy: 0.4647\n",
      "Epoch 90/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 4.5555e-06 - accuracy: 0.4640 - val_loss: 0.0363 - val_accuracy: 0.4632\n",
      "Epoch 91/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 4.3651e-06 - accuracy: 0.4643 - val_loss: 0.0371 - val_accuracy: 0.4556\n",
      "Epoch 92/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 4.2455e-06 - accuracy: 0.4845 - val_loss: 0.0367 - val_accuracy: 0.4752\n",
      "Epoch 93/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 3.9602e-06 - accuracy: 0.4610 - val_loss: 0.0370 - val_accuracy: 0.4722\n",
      "Epoch 94/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 3.8355e-06 - accuracy: 0.4815 - val_loss: 0.0370 - val_accuracy: 0.4571\n",
      "Epoch 95/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 3.4256e-06 - accuracy: 0.4451 - val_loss: 0.0364 - val_accuracy: 0.4571\n",
      "Epoch 96/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 3.5182e-06 - accuracy: 0.4705 - val_loss: 0.0374 - val_accuracy: 0.4767\n",
      "Epoch 97/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 3.1785e-06 - accuracy: 0.4596 - val_loss: 0.0377 - val_accuracy: 0.4511\n",
      "Epoch 98/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 3.0473e-06 - accuracy: 0.4715 - val_loss: 0.0382 - val_accuracy: 0.4316\n",
      "Epoch 99/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 2.8442e-06 - accuracy: 0.4568 - val_loss: 0.0385 - val_accuracy: 0.4737\n",
      "Epoch 100/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 2.7261e-06 - accuracy: 0.4830 - val_loss: 0.0386 - val_accuracy: 0.4571\n",
      "Score for fold 10 : loss of 0.03855862841010094 ; F1-Macro: 0.6660387780382465 F1-Micro: 0.9969902182091799\n",
      "------------------------------------------------------------------------\n",
      "Score per fold\n",
      "------------------------------------------------------------------------\n",
      "> Fold 1  - Loss: 0.03683343902230263 - F1-Macro: 0.5827684324335776 %\n",
      "------------------------------------------------------------------------\n",
      "> Fold 2  - Loss: 0.01928543485701084 - F1-Macro: 0.9164782717910073 %\n",
      "------------------------------------------------------------------------\n",
      "> Fold 3  - Loss: 0.07735494524240494 - F1-Macro: 0.41547112507184797 %\n",
      "------------------------------------------------------------------------\n",
      "> Fold 4  - Loss: 0.013447889126837254 - F1-Macro: 0.8748116049105293 %\n",
      "------------------------------------------------------------------------\n",
      "> Fold 5  - Loss: 0.014058946631848812 - F1-Macro: 0.9165411646586344 %\n",
      "------------------------------------------------------------------------\n",
      "> Fold 6  - Loss: 0.01396168302744627 - F1-Macro: 0.8330825181840983 %\n",
      "------------------------------------------------------------------------\n",
      "> Fold 7  - Loss: 0.01920318603515625 - F1-Macro: 0.5829568270957477 %\n",
      "------------------------------------------------------------------------\n",
      "> Fold 8  - Loss: 0.041157759726047516 - F1-Macro: 0.5825796589696587 %\n",
      "------------------------------------------------------------------------\n",
      "> Fold 9  - Loss: 0.014830554835498333 - F1-Macro: 0.9164782717910073 %\n",
      "------------------------------------------------------------------------\n",
      "> Fold 10  - Loss: 0.03855862841010094 - F1-Macro: 0.6660387780382465 %\n",
      "------------------------------------------------------------------------\n",
      "Average scores for all folds:\n",
      "> F1-Macro: 0.7287206652944355 (+- 0.17434935460887105 )\n",
      "> F1-Micro: 0.9977240324024397 (+- 0.0015093967912386207 )\n",
      "> Loss: 0.02886924669146538\n",
      "------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   F1-Macro  F1-Macro_std  F1-Micro  F1-Micro_std  F1-Weighted  \\\n",
      "0  0.728721      0.174349  0.997724      0.001509     0.996935   \n",
      "\n",
      "   F1-Weighted_std               Dataset                method  \n",
      "0         0.002019  Universities_DBpedia  Concatenated Vectors  \n",
      "Model: \"sequential_9\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_18 (Dense)            (None, 434)               188790    \n",
      "                                                                 \n",
      " Gelu (Activation)           (None, 434)               0         \n",
      "                                                                 \n",
      " dense_19 (Dense)            (None, 12)                5220      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 194,010\n",
      "Trainable params: 194,010\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "K_FOLD = 10\n",
    "mlb = MultiLabelBinarizer()\n",
    "fold_no = 1\n",
    "loss_per_fold, f1_macro, f1_micro, f1_weighted = [], [], [], []\n",
    "kfold = KFold(n_splits=K_FOLD, shuffle=True, random_state=42)\n",
    "targets = mlb.fit_transform(r_new['Class'])\n",
    "wrong_sbert = []\n",
    "for train, test_new in kfold.split(conc_input, targets):\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Dense(conc_input[train].shape[1], input_dim=conc_input[train].shape[1]))\n",
    "    model.add(Activation(gelu, name='Gelu'))\n",
    "    model.add(Dense(targets[train].shape[1], activation='sigmoid'))\n",
    "    # Compile model\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    print('Training...')\n",
    "    history = model.fit(conc_input[train], targets[train], batch_size=64, validation_data=(conc_input[test_new], targets[test_new]), epochs=100)\n",
    "    y_pred = model.predict(conc_input[test_new])\n",
    "    y_pred[y_pred>=0.5]=1\n",
    "    y_pred[y_pred<0.5]=0\n",
    "    \n",
    "    # Generate F1 scores\n",
    "    scores = model.evaluate(conc_input[test_new], targets[test_new], verbose=0)\n",
    "    f1_macro.append(f1_score(targets[test_new], y_pred, average='macro', zero_division=1))\n",
    "    f1_micro.append(f1_score(targets[test_new], y_pred, average='micro', zero_division=1))\n",
    "    f1_weighted.append(f1_score(targets[test_new], y_pred, average='weighted', zero_division=1))\n",
    "    \n",
    "    for m in range(len(test_new)):\n",
    "        comp = targets[test_new][m] ==  y_pred[m]\n",
    "        if not(comp.all()):\n",
    "            #wrong_sbert.append((test_new[m], y_pred[m], targets[test_new][m]))\n",
    "            wrong_sbert.append(test_new[m])\n",
    "\n",
    "    \n",
    "\n",
    "    print('Score for fold', fold_no, ':', model.metrics_names[0], 'of', scores[0], ';', 'F1-Macro:', f1_macro[-1], 'F1-Micro:', f1_micro[-1])\n",
    "    loss_per_fold.append(scores[0])\n",
    "\n",
    "    fold_no += 1\n",
    "    \n",
    "# Provide average scores\n",
    "print('------------------------------------------------------------------------')\n",
    "print('Score per fold')\n",
    "for i in range(0, len(loss_per_fold)):\n",
    "    print('------------------------------------------------------------------------')\n",
    "    print('> Fold', i+1, ' - Loss:', loss_per_fold[i], '- F1-Macro:', f1_macro[i], '%')\n",
    "print('------------------------------------------------------------------------')\n",
    "print('Average scores for all folds:')\n",
    "print('> F1-Macro:', np.mean(f1_macro), '(+-', np.std(f1_macro), ')')\n",
    "print('> F1-Micro:', np.mean(f1_micro), '(+-', np.std(f1_micro), ')')\n",
    "print('> Loss:', np.mean(loss_per_fold))\n",
    "print('------------------------------------------------------------------------')\n",
    "\n",
    "# Save results to file\n",
    "result = {}\n",
    "f1_macro = np.array(f1_macro)\n",
    "f1_micro = np.array(f1_micro)\n",
    "f1_weighted = np.array(f1_weighted)\n",
    "result['F1-Macro'] = np.mean(f1_macro)\n",
    "result['F1-Macro_std'] = np.std(f1_macro)\n",
    "result['F1-Micro'] = np.mean(f1_micro)\n",
    "result['F1-Micro_std'] = np.std(f1_micro)\n",
    "result['F1-Weighted'] = np.mean(f1_weighted)\n",
    "result['F1-Weighted_std'] = np.std(f1_weighted)\n",
    "result['Dataset'] = parser.dataset\n",
    "result['method'] = 'Concatenated Vectors'\n",
    "df_result = pd.DataFrame([result])\n",
    "print(df_result)\n",
    "\n",
    "if os.path.isfile('./evaluation_instance_type.csv'):\n",
    "    df_result.to_csv('./evaluation_instance_type.csv', mode='a', header=False, index=False)\n",
    "# else:\n",
    "    df_result.to_csv('./evaluation_instance_type.csv', index=False)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "id": "1a7fe322",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "invalid index to scalar variable.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_2180/547281045.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mwrong_id_ridle\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0melement\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mwrong_ridle\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[0mwrong_id_ridle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0melement\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m     \u001b[0mwrong_id_ridle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msort\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: invalid index to scalar variable."
     ]
    }
   ],
   "source": [
    "wrong_id_ridle = []\n",
    "for element in wrong_ridle:\n",
    "    wrong_id_ridle.append(element[0])\n",
    "    wrong_id_ridle.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b35af44",
   "metadata": {},
   "outputs": [],
   "source": [
    "wrong_id_bert = []\n",
    "for element in wrong_sbert:\n",
    "    wrong_id_bert.append(element[0])\n",
    "    wrong_id_bert.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4ce5ba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_bert = []\n",
    "for element in wrong_sbert:\n",
    "    pred_bert.append(element[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "id": "dead708f",
   "metadata": {},
   "outputs": [],
   "source": [
    "targets_bert = []\n",
    "for element in wrong_sbert:\n",
    "    targets_bert.append(element[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "id": "4997134c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_ridle = []\n",
    "for element in wrong_ridle:\n",
    "    pred_ridle.append(element[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "id": "bd706bbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "targets_ridle = []\n",
    "for element in wrong_ridle:\n",
    "    targets_ridle.append(element[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1209dd29",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_pickle(\"./Misclassification.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "id": "a86c0179",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.at['{}'.format(parser.dataset), \"Ridle misclassified\"] = len(wrong_ridle)\n",
    "df1.at['{}'.format(parser.dataset), \"Sbert misclassified\"] = len(wrong_sbert)\n",
    "df1.at['{}'.format(parser.dataset), \"Misclassified in both\"] = set(wrong_id_ridle).intersection(wrong_id_bert)\n",
    "df1.at['{}'.format(parser.dataset), \"Prediction Bert\"] = pred_bert\n",
    "df1.at['{}'.format(parser.dataset), \"Target Bert\"] = targets_bert\n",
    "df1.at['{}'.format(parser.dataset), \"ID list Bert\"] = wrong_id_bert\n",
    "df1.at['{}'.format(parser.dataset), \"Prediction Ridle\"] = pred_ridle\n",
    "df1.at['{}'.format(parser.dataset), \"Target Ridle\"] = targets_ridle\n",
    "df1.at['{}'.format(parser.dataset), \"ID list Ridle\"] = wrong_id_ridle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "id": "46cb2eaa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>Ridle misclassified</th>\n",
       "      <th>Sbert misclassified</th>\n",
       "      <th>Misclassified in both</th>\n",
       "      <th>ID list Bert</th>\n",
       "      <th>Prediction Bert</th>\n",
       "      <th>Target Bert</th>\n",
       "      <th>ID list Ridle</th>\n",
       "      <th>Prediction Ridle</th>\n",
       "      <th>Target Ridle</th>\n",
       "      <th>USE misclassified</th>\n",
       "      <th>ID list USE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Books_DBpedia</th>\n",
       "      <td>Books_DBpedia</td>\n",
       "      <td>22</td>\n",
       "      <td>23</td>\n",
       "      <td>{4366, 6548, 5665, 6438, 1959, 1065, 7340, 939...</td>\n",
       "      <td>[311, 1065, 1401, 1959, 1985, 2047, 3337, 3441...</td>\n",
       "      <td>[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "      <td>[[0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...</td>\n",
       "      <td>[1065, 1401, 1959, 1985, 2047, 2925, 3441, 436...</td>\n",
       "      <td>[[0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "      <td>[[0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0,...</td>\n",
       "      <td>21</td>\n",
       "      <td>[600, 1142, 1492, 2071, 2099, 2162, 3593, 4559...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ChemicalCompounds_DBpedia</th>\n",
       "      <td>ChemicalCompounds_DBpedia</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>{5286, 2406, 7216, 1906, 4186, 3452}</td>\n",
       "      <td>[1906, 2406, 3452, 4186, 5286, 5323, 7216, 7929]</td>\n",
       "      <td>[[0.0, 1.0, 1.0, 0.0, 0.0], [0.0, 1.0, 1.0, 0....</td>\n",
       "      <td>[[0, 0, 0, 1, 0], [0, 0, 0, 1, 0], [1, 0, 0, 0...</td>\n",
       "      <td>[1906, 2406, 3452, 4186, 5286, 7216]</td>\n",
       "      <td>[[0.0, 1.0, 1.0, 0.0, 0.0], [0.0, 1.0, 1.0, 0....</td>\n",
       "      <td>[[0, 0, 0, 1, 0], [0, 0, 0, 1, 0], [0, 0, 0, 1...</td>\n",
       "      <td>8</td>\n",
       "      <td>[1928, 2428, 3476, 4212, 5314, 5351, 7248, 7963]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Company_DBpedia</th>\n",
       "      <td>Company_DBpedia</td>\n",
       "      <td>142</td>\n",
       "      <td>133</td>\n",
       "      <td>{3587, 7172, 4101, 7180, 3089, 6677, 4632, 259...</td>\n",
       "      <td>[133, 156, 182, 218, 489, 716, 818, 1068, 1114...</td>\n",
       "      <td>[[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "      <td>[[1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,...</td>\n",
       "      <td>[62, 119, 123, 133, 156, 182, 291, 489, 607, 6...</td>\n",
       "      <td>[[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "      <td>[[1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,...</td>\n",
       "      <td>242</td>\n",
       "      <td>[2, 4, 6, 7, 8, 11, 30, 40, 108, 110, 154, 170...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DBp_2016-04</th>\n",
       "      <td>DBp_2016-04</td>\n",
       "      <td>5959</td>\n",
       "      <td>4179</td>\n",
       "      <td>{8193, 16389, 16391, 8201, 32788, 32789, 24602...</td>\n",
       "      <td>[646, 1282, 1414, 1603, 1703, 1736, 2247, 2269...</td>\n",
       "      <td>[[0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0,...</td>\n",
       "      <td>[[0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,...</td>\n",
       "      <td>[646, 1282, 1414, 1599, 1603, 1655, 1682, 1703...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>6419</td>\n",
       "      <td>[63, 110, 128, 133, 153, 160, 227, 232, 320, 3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Person_DBpedia</th>\n",
       "      <td>Person_DBpedia</td>\n",
       "      <td>2831</td>\n",
       "      <td>2606</td>\n",
       "      <td>{8192, 2, 24580, 4, 24585, 12, 19, 24606, 32, ...</td>\n",
       "      <td>[216, 261, 274, 278, 474, 852, 880, 963, 1087,...</td>\n",
       "      <td>[[0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "      <td>[[0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...</td>\n",
       "      <td>[216, 261, 274, 278, 775, 852, 880, 963, 1246,...</td>\n",
       "      <td>[[0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "      <td>[[0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...</td>\n",
       "      <td>5533</td>\n",
       "      <td>[2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Songs_DBpedia</th>\n",
       "      <td>Songs_DBpedia</td>\n",
       "      <td>151</td>\n",
       "      <td>181</td>\n",
       "      <td>{0, 2560, 3073, 3588, 6, 1545, 3082, 3601, 361...</td>\n",
       "      <td>[0, 6, 9, 35, 80, 121, 142, 149, 168, 196, 199...</td>\n",
       "      <td>[[0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0]...</td>\n",
       "      <td>[[0, 0, 0, 0, 1, 0, 1, 0, 1], [0, 0, 0, 0, 1, ...</td>\n",
       "      <td>[0, 6, 80, 163, 168, 199, 223, 248, 260, 293, ...</td>\n",
       "      <td>[[0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0]...</td>\n",
       "      <td>[[0, 0, 0, 0, 1, 1, 0, 0, 1], [0, 0, 0, 0, 1, ...</td>\n",
       "      <td>281</td>\n",
       "      <td>[0, 3, 9, 13, 15, 16, 22, 28, 44, 95, 107, 114...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>umls</th>\n",
       "      <td>umls</td>\n",
       "      <td>52</td>\n",
       "      <td>45</td>\n",
       "      <td>{0, 1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 1...</td>\n",
       "      <td>[0, 1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 1...</td>\n",
       "      <td>[[0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "      <td>[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0,...</td>\n",
       "      <td>[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...</td>\n",
       "      <td>[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "      <td>[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0,...</td>\n",
       "      <td>48</td>\n",
       "      <td>[9, 10, 17, 20, 22, 25, 26, 27, 34, 39, 40, 44...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Universities_DBpedia</th>\n",
       "      <td>Universities_DBpedia</td>\n",
       "      <td>35</td>\n",
       "      <td>37</td>\n",
       "      <td>{4362, 652, 1165, 4625, 4755, 3991, 3993, 4122...</td>\n",
       "      <td>[304, 462, 548, 652, 1095, 1120, 1133, 1165, 1...</td>\n",
       "      <td>[[1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0,...</td>\n",
       "      <td>[[0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0], [0, 0, ...</td>\n",
       "      <td>[462, 548, 652, 843, 1015, 1095, 1120, 1133, 1...</td>\n",
       "      <td>[[1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0,...</td>\n",
       "      <td>[[0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0], [0, 0, ...</td>\n",
       "      <td>39</td>\n",
       "      <td>[526, 617, 726, 931, 1201, 1226, 1239, 1271, 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Books_Dbpedia</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   0 Ridle misclassified  \\\n",
       "Books_DBpedia                          Books_DBpedia                  22   \n",
       "ChemicalCompounds_DBpedia  ChemicalCompounds_DBpedia                   6   \n",
       "Company_DBpedia                      Company_DBpedia                 142   \n",
       "DBp_2016-04                              DBp_2016-04                5959   \n",
       "Person_DBpedia                        Person_DBpedia                2831   \n",
       "Songs_DBpedia                          Songs_DBpedia                 151   \n",
       "umls                                            umls                  52   \n",
       "Universities_DBpedia            Universities_DBpedia                  35   \n",
       "Books_Dbpedia                                    NaN                 NaN   \n",
       "\n",
       "                          Sbert misclassified  \\\n",
       "Books_DBpedia                              23   \n",
       "ChemicalCompounds_DBpedia                   8   \n",
       "Company_DBpedia                           133   \n",
       "DBp_2016-04                              4179   \n",
       "Person_DBpedia                           2606   \n",
       "Songs_DBpedia                             181   \n",
       "umls                                       45   \n",
       "Universities_DBpedia                       37   \n",
       "Books_Dbpedia                             NaN   \n",
       "\n",
       "                                                       Misclassified in both  \\\n",
       "Books_DBpedia              {4366, 6548, 5665, 6438, 1959, 1065, 7340, 939...   \n",
       "ChemicalCompounds_DBpedia               {5286, 2406, 7216, 1906, 4186, 3452}   \n",
       "Company_DBpedia            {3587, 7172, 4101, 7180, 3089, 6677, 4632, 259...   \n",
       "DBp_2016-04                {8193, 16389, 16391, 8201, 32788, 32789, 24602...   \n",
       "Person_DBpedia             {8192, 2, 24580, 4, 24585, 12, 19, 24606, 32, ...   \n",
       "Songs_DBpedia              {0, 2560, 3073, 3588, 6, 1545, 3082, 3601, 361...   \n",
       "umls                       {0, 1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 1...   \n",
       "Universities_DBpedia       {4362, 652, 1165, 4625, 4755, 3991, 3993, 4122...   \n",
       "Books_Dbpedia                                                            NaN   \n",
       "\n",
       "                                                                ID list Bert  \\\n",
       "Books_DBpedia              [311, 1065, 1401, 1959, 1985, 2047, 3337, 3441...   \n",
       "ChemicalCompounds_DBpedia   [1906, 2406, 3452, 4186, 5286, 5323, 7216, 7929]   \n",
       "Company_DBpedia            [133, 156, 182, 218, 489, 716, 818, 1068, 1114...   \n",
       "DBp_2016-04                [646, 1282, 1414, 1603, 1703, 1736, 2247, 2269...   \n",
       "Person_DBpedia             [216, 261, 274, 278, 474, 852, 880, 963, 1087,...   \n",
       "Songs_DBpedia              [0, 6, 9, 35, 80, 121, 142, 149, 168, 196, 199...   \n",
       "umls                       [0, 1, 2, 3, 5, 6, 8, 9, 10, 11, 12, 13, 14, 1...   \n",
       "Universities_DBpedia       [304, 462, 548, 652, 1095, 1120, 1133, 1165, 1...   \n",
       "Books_Dbpedia                                                            NaN   \n",
       "\n",
       "                                                             Prediction Bert  \\\n",
       "Books_DBpedia              [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...   \n",
       "ChemicalCompounds_DBpedia  [[0.0, 1.0, 1.0, 0.0, 0.0], [0.0, 1.0, 1.0, 0....   \n",
       "Company_DBpedia            [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...   \n",
       "DBp_2016-04                [[0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0,...   \n",
       "Person_DBpedia             [[0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...   \n",
       "Songs_DBpedia              [[0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0]...   \n",
       "umls                       [[0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0,...   \n",
       "Universities_DBpedia       [[1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0,...   \n",
       "Books_Dbpedia                                                            NaN   \n",
       "\n",
       "                                                                 Target Bert  \\\n",
       "Books_DBpedia              [[0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...   \n",
       "ChemicalCompounds_DBpedia  [[0, 0, 0, 1, 0], [0, 0, 0, 1, 0], [1, 0, 0, 0...   \n",
       "Company_DBpedia            [[1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,...   \n",
       "DBp_2016-04                [[0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,...   \n",
       "Person_DBpedia             [[0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...   \n",
       "Songs_DBpedia              [[0, 0, 0, 0, 1, 0, 1, 0, 1], [0, 0, 0, 0, 1, ...   \n",
       "umls                       [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0,...   \n",
       "Universities_DBpedia       [[0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0], [0, 0, ...   \n",
       "Books_Dbpedia                                                            NaN   \n",
       "\n",
       "                                                               ID list Ridle  \\\n",
       "Books_DBpedia              [1065, 1401, 1959, 1985, 2047, 2925, 3441, 436...   \n",
       "ChemicalCompounds_DBpedia               [1906, 2406, 3452, 4186, 5286, 7216]   \n",
       "Company_DBpedia            [62, 119, 123, 133, 156, 182, 291, 489, 607, 6...   \n",
       "DBp_2016-04                [646, 1282, 1414, 1599, 1603, 1655, 1682, 1703...   \n",
       "Person_DBpedia             [216, 261, 274, 278, 775, 852, 880, 963, 1246,...   \n",
       "Songs_DBpedia              [0, 6, 80, 163, 168, 199, 223, 248, 260, 293, ...   \n",
       "umls                       [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...   \n",
       "Universities_DBpedia       [462, 548, 652, 843, 1015, 1095, 1120, 1133, 1...   \n",
       "Books_Dbpedia                                                            NaN   \n",
       "\n",
       "                                                            Prediction Ridle  \\\n",
       "Books_DBpedia              [[0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0,...   \n",
       "ChemicalCompounds_DBpedia  [[0.0, 1.0, 1.0, 0.0, 0.0], [0.0, 1.0, 1.0, 0....   \n",
       "Company_DBpedia            [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...   \n",
       "DBp_2016-04                                                                    \n",
       "Person_DBpedia             [[0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...   \n",
       "Songs_DBpedia              [[0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0]...   \n",
       "umls                       [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...   \n",
       "Universities_DBpedia       [[1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0,...   \n",
       "Books_Dbpedia                                                            NaN   \n",
       "\n",
       "                                                                Target Ridle  \\\n",
       "Books_DBpedia              [[0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0,...   \n",
       "ChemicalCompounds_DBpedia  [[0, 0, 0, 1, 0], [0, 0, 0, 1, 0], [0, 0, 0, 1...   \n",
       "Company_DBpedia            [[1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,...   \n",
       "DBp_2016-04                                                                    \n",
       "Person_DBpedia             [[0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...   \n",
       "Songs_DBpedia              [[0, 0, 0, 0, 1, 1, 0, 0, 1], [0, 0, 0, 0, 1, ...   \n",
       "umls                       [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0,...   \n",
       "Universities_DBpedia       [[0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0], [0, 0, ...   \n",
       "Books_Dbpedia                                                            NaN   \n",
       "\n",
       "                          USE misclassified  \\\n",
       "Books_DBpedia                            21   \n",
       "ChemicalCompounds_DBpedia                 8   \n",
       "Company_DBpedia                         242   \n",
       "DBp_2016-04                            6419   \n",
       "Person_DBpedia                         5533   \n",
       "Songs_DBpedia                           281   \n",
       "umls                                     48   \n",
       "Universities_DBpedia                     39   \n",
       "Books_Dbpedia                           NaN   \n",
       "\n",
       "                                                                 ID list USE  \n",
       "Books_DBpedia              [600, 1142, 1492, 2071, 2099, 2162, 3593, 4559...  \n",
       "ChemicalCompounds_DBpedia   [1928, 2428, 3476, 4212, 5314, 5351, 7248, 7963]  \n",
       "Company_DBpedia            [2, 4, 6, 7, 8, 11, 30, 40, 108, 110, 154, 170...  \n",
       "DBp_2016-04                [63, 110, 128, 133, 153, 160, 227, 232, 320, 3...  \n",
       "Person_DBpedia             [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 1...  \n",
       "Songs_DBpedia              [0, 3, 9, 13, 15, 16, 22, 28, 44, 95, 107, 114...  \n",
       "umls                       [9, 10, 17, 20, 22, 25, 26, 27, 34, 39, 40, 44...  \n",
       "Universities_DBpedia       [526, 617, 726, 931, 1201, 1226, 1239, 1271, 1...  \n",
       "Books_Dbpedia                                                            NaN  "
      ]
     },
     "execution_count": 350,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "id": "504b3d6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.to_pickle(\"./Misclassification.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9ba7dbd",
   "metadata": {},
   "source": [
    "Run the code below if you want to specify the dataset from Misclassification.pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "143c2a67",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = df1.iloc[2]['Prediction Bert']\n",
    "targ = df1.iloc[2]['Target Bert']\n",
    "ids = df1.iloc[2]['ID list Bert']\n",
    "false_negative = {}\n",
    "false_positive = {}\n",
    "for i in range(len(pred)):\n",
    "    for j in range(len(pred[i])):\n",
    "        if targ[i][j] == 1 and pred[i][j] == 0:\n",
    "            if mlb.classes_[j] in false_negative.keys():\n",
    "                false_negative[mlb.classes_[j]].append(ids[i])\n",
    "            else: \n",
    "                false_negative[mlb.classes_[j]] = [ids[i]] \n",
    "            \n",
    "        elif targ[i][j] == 0 and pred[i][j] == 1:\n",
    "            if mlb.classes_[j] in false_positive.keys():\n",
    "                false_positive[mlb.classes_[j]].append(ids[i])\n",
    "            else: \n",
    "                false_positive[mlb.classes_[j]] = [ids[i]] \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04a907cc",
   "metadata": {},
   "source": [
    "Run the code below, if you ran the Neural Network before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d209e80a",
   "metadata": {},
   "outputs": [],
   "source": [
    "false_negative = {}\n",
    "false_positive = {}\n",
    "for i in range(len(pred_bert)):\n",
    "    for j in range(len(pred_bert[i])):\n",
    "        if targets_bert[i][j] == 1 and pred_bert[i][j] == 0:\n",
    "            if mlb.classes_[j] in false_negative.keys():\n",
    "                false_negative[mlb.classes_[j]].append(r['S'].iloc[wrong_id_bert[i]])\n",
    "            else: \n",
    "                false_negative[mlb.classes_[j]] = [r['S'].iloc[wrong_id_bert[i]]] \n",
    "            \n",
    "        elif targets_bert[i][j] == 0 and pred_bert[i][j] == 1:\n",
    "            if mlb.classes_[j] in false_positive.keys():\n",
    "                false_positive[mlb.classes_[j]].append(r['S'].iloc[wrong_id_bert[i]])\n",
    "            else: \n",
    "                false_positive[mlb.classes_[j]] = [r['S'].iloc[wrong_id_bert[i]]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2854b3d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "fn = pd.DataFrame.from_dict(false_negative, orient='index')\n",
    "fn.to_pickle(\"./false_negative/'{}'.pkl\".format(parser.dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "aeee0a0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "fp = pd.DataFrame.from_dict(false_positive, orient='index')\n",
    "fp.to_pickle(\"./false_positive/'{}'.pkl\".format(parser.dataset))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f5be12f",
   "metadata": {},
   "source": [
    "# Only Sentence Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "4be5f01c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training...\n",
      "Epoch 1/100\n",
      "421/421 [==============================] - 2s 3ms/step - loss: 0.0593 - accuracy: 0.9776 - val_loss: 0.0209 - val_accuracy: 0.9860\n",
      "Epoch 2/100\n",
      "421/421 [==============================] - 1s 3ms/step - loss: 0.0168 - accuracy: 0.9845 - val_loss: 0.0143 - val_accuracy: 0.9883\n",
      "Epoch 3/100\n",
      "421/421 [==============================] - 1s 3ms/step - loss: 0.0125 - accuracy: 0.8704 - val_loss: 0.0118 - val_accuracy: 0.9411\n",
      "Epoch 4/100\n",
      "421/421 [==============================] - 1s 3ms/step - loss: 0.0107 - accuracy: 0.8006 - val_loss: 0.0107 - val_accuracy: 0.6622\n",
      "Epoch 5/100\n",
      "421/421 [==============================] - 1s 3ms/step - loss: 0.0097 - accuracy: 0.4766 - val_loss: 0.0101 - val_accuracy: 0.9391\n",
      "Epoch 6/100\n",
      "421/421 [==============================] - 1s 3ms/step - loss: 0.0089 - accuracy: 0.4879 - val_loss: 0.0097 - val_accuracy: 0.8023\n",
      "Epoch 7/100\n",
      "421/421 [==============================] - 1s 3ms/step - loss: 0.0084 - accuracy: 0.5041 - val_loss: 0.0095 - val_accuracy: 0.9264\n",
      "Epoch 8/100\n",
      "421/421 [==============================] - 1s 3ms/step - loss: 0.0080 - accuracy: 0.6046 - val_loss: 0.0091 - val_accuracy: 0.6030\n",
      "Epoch 9/100\n",
      "421/421 [==============================] - 1s 3ms/step - loss: 0.0076 - accuracy: 0.5684 - val_loss: 0.0091 - val_accuracy: 0.8870\n",
      "Epoch 10/100\n",
      "421/421 [==============================] - 1s 3ms/step - loss: 0.0072 - accuracy: 0.5893 - val_loss: 0.0091 - val_accuracy: 0.3866\n",
      "Epoch 11/100\n",
      "421/421 [==============================] - 1s 3ms/step - loss: 0.0070 - accuracy: 0.5349 - val_loss: 0.0090 - val_accuracy: 0.6890\n",
      "Epoch 12/100\n",
      "421/421 [==============================] - 1s 3ms/step - loss: 0.0067 - accuracy: 0.6628 - val_loss: 0.0088 - val_accuracy: 0.5903\n",
      "Epoch 13/100\n",
      "421/421 [==============================] - 1s 3ms/step - loss: 0.0065 - accuracy: 0.7322 - val_loss: 0.0088 - val_accuracy: 0.5676\n",
      "Epoch 14/100\n",
      "421/421 [==============================] - 1s 3ms/step - loss: 0.0063 - accuracy: 0.6557 - val_loss: 0.0088 - val_accuracy: 0.8987\n",
      "Epoch 15/100\n",
      "421/421 [==============================] - 1s 3ms/step - loss: 0.0060 - accuracy: 0.7122 - val_loss: 0.0089 - val_accuracy: 0.7980\n",
      "Epoch 16/100\n",
      "421/421 [==============================] - 1s 3ms/step - loss: 0.0058 - accuracy: 0.7704 - val_loss: 0.0089 - val_accuracy: 0.7304\n",
      "Epoch 17/100\n",
      "421/421 [==============================] - 1s 3ms/step - loss: 0.0056 - accuracy: 0.7300 - val_loss: 0.0090 - val_accuracy: 0.9542\n",
      "Epoch 18/100\n",
      "421/421 [==============================] - 1s 3ms/step - loss: 0.0054 - accuracy: 0.7912 - val_loss: 0.0089 - val_accuracy: 0.6181\n",
      "Epoch 19/100\n",
      "421/421 [==============================] - 1s 3ms/step - loss: 0.0052 - accuracy: 0.7891 - val_loss: 0.0091 - val_accuracy: 0.8836\n",
      "Epoch 20/100\n",
      "421/421 [==============================] - 1s 3ms/step - loss: 0.0050 - accuracy: 0.8187 - val_loss: 0.0090 - val_accuracy: 0.8395\n",
      "Epoch 21/100\n",
      "421/421 [==============================] - 2s 4ms/step - loss: 0.0048 - accuracy: 0.8538 - val_loss: 0.0092 - val_accuracy: 0.8043\n",
      "Epoch 22/100\n",
      "421/421 [==============================] - 1s 3ms/step - loss: 0.0046 - accuracy: 0.8861 - val_loss: 0.0092 - val_accuracy: 0.8920\n",
      "Epoch 23/100\n",
      "421/421 [==============================] - 1s 3ms/step - loss: 0.0044 - accuracy: 0.8791 - val_loss: 0.0093 - val_accuracy: 0.8967\n",
      "Epoch 24/100\n",
      "421/421 [==============================] - 1s 3ms/step - loss: 0.0042 - accuracy: 0.8778 - val_loss: 0.0094 - val_accuracy: 0.9672\n",
      "Epoch 25/100\n",
      "421/421 [==============================] - 1s 3ms/step - loss: 0.0040 - accuracy: 0.9184 - val_loss: 0.0096 - val_accuracy: 0.9341\n",
      "Epoch 26/100\n",
      "421/421 [==============================] - 1s 3ms/step - loss: 0.0038 - accuracy: 0.9115 - val_loss: 0.0098 - val_accuracy: 0.9027\n",
      "Epoch 27/100\n",
      "421/421 [==============================] - 1s 3ms/step - loss: 0.0035 - accuracy: 0.9031 - val_loss: 0.0100 - val_accuracy: 0.8993\n",
      "Epoch 28/100\n",
      "421/421 [==============================] - 1s 3ms/step - loss: 0.0033 - accuracy: 0.9091 - val_loss: 0.0101 - val_accuracy: 0.8900\n",
      "Epoch 29/100\n",
      "421/421 [==============================] - 1s 3ms/step - loss: 0.0031 - accuracy: 0.8956 - val_loss: 0.0104 - val_accuracy: 0.9060\n",
      "Epoch 30/100\n",
      "421/421 [==============================] - 1s 3ms/step - loss: 0.0029 - accuracy: 0.9016 - val_loss: 0.0105 - val_accuracy: 0.9090\n",
      "Epoch 31/100\n",
      "421/421 [==============================] - 1s 3ms/step - loss: 0.0027 - accuracy: 0.8824 - val_loss: 0.0107 - val_accuracy: 0.8759\n",
      "Epoch 32/100\n",
      "421/421 [==============================] - 1s 3ms/step - loss: 0.0025 - accuracy: 0.8830 - val_loss: 0.0110 - val_accuracy: 0.9114\n",
      "Epoch 33/100\n",
      "421/421 [==============================] - 1s 3ms/step - loss: 0.0023 - accuracy: 0.8773 - val_loss: 0.0113 - val_accuracy: 0.8582\n",
      "Epoch 34/100\n",
      "421/421 [==============================] - 1s 3ms/step - loss: 0.0021 - accuracy: 0.8633 - val_loss: 0.0113 - val_accuracy: 0.8886\n",
      "Epoch 35/100\n",
      "421/421 [==============================] - 1s 3ms/step - loss: 0.0019 - accuracy: 0.8578 - val_loss: 0.0116 - val_accuracy: 0.8756\n",
      "Epoch 36/100\n",
      "421/421 [==============================] - 1s 3ms/step - loss: 0.0017 - accuracy: 0.8538 - val_loss: 0.0120 - val_accuracy: 0.8532\n",
      "Epoch 37/100\n",
      "421/421 [==============================] - 1s 3ms/step - loss: 0.0016 - accuracy: 0.8244 - val_loss: 0.0121 - val_accuracy: 0.8395\n",
      "Epoch 38/100\n",
      "421/421 [==============================] - 1s 3ms/step - loss: 0.0014 - accuracy: 0.8222 - val_loss: 0.0124 - val_accuracy: 0.8171\n",
      "Epoch 39/100\n",
      "421/421 [==============================] - 1s 3ms/step - loss: 0.0012 - accuracy: 0.8128 - val_loss: 0.0127 - val_accuracy: 0.8110\n",
      "Epoch 40/100\n",
      "421/421 [==============================] - 1s 3ms/step - loss: 0.0011 - accuracy: 0.7959 - val_loss: 0.0132 - val_accuracy: 0.8030\n",
      "Epoch 41/100\n",
      "421/421 [==============================] - 1s 3ms/step - loss: 9.7758e-04 - accuracy: 0.7960 - val_loss: 0.0133 - val_accuracy: 0.8227\n",
      "Epoch 42/100\n",
      "421/421 [==============================] - 1s 3ms/step - loss: 8.6476e-04 - accuracy: 0.7905 - val_loss: 0.0137 - val_accuracy: 0.8090\n",
      "Epoch 43/100\n",
      "421/421 [==============================] - 1s 3ms/step - loss: 7.6030e-04 - accuracy: 0.7767 - val_loss: 0.0139 - val_accuracy: 0.7839\n",
      "Epoch 44/100\n",
      "421/421 [==============================] - 1s 3ms/step - loss: 6.6490e-04 - accuracy: 0.7684 - val_loss: 0.0144 - val_accuracy: 0.7418\n",
      "Epoch 45/100\n",
      "421/421 [==============================] - 1s 3ms/step - loss: 5.8025e-04 - accuracy: 0.7424 - val_loss: 0.0146 - val_accuracy: 0.7682\n",
      "Epoch 46/100\n",
      "421/421 [==============================] - 1s 3ms/step - loss: 5.0777e-04 - accuracy: 0.7412 - val_loss: 0.0151 - val_accuracy: 0.7582\n",
      "Epoch 47/100\n",
      "421/421 [==============================] - 1s 3ms/step - loss: 4.4668e-04 - accuracy: 0.7267 - val_loss: 0.0154 - val_accuracy: 0.7388\n",
      "Epoch 48/100\n",
      "421/421 [==============================] - 1s 3ms/step - loss: 3.8410e-04 - accuracy: 0.7245 - val_loss: 0.0158 - val_accuracy: 0.7298\n",
      "Epoch 49/100\n",
      "421/421 [==============================] - 1s 3ms/step - loss: 3.3026e-04 - accuracy: 0.7008 - val_loss: 0.0162 - val_accuracy: 0.7040\n",
      "Epoch 50/100\n",
      "421/421 [==============================] - 1s 3ms/step - loss: 2.9321e-04 - accuracy: 0.6870 - val_loss: 0.0165 - val_accuracy: 0.6990\n",
      "Epoch 51/100\n",
      "421/421 [==============================] - 1s 3ms/step - loss: 2.5808e-04 - accuracy: 0.6755 - val_loss: 0.0168 - val_accuracy: 0.6702\n",
      "Epoch 52/100\n",
      "421/421 [==============================] - 1s 3ms/step - loss: 2.2204e-04 - accuracy: 0.6651 - val_loss: 0.0173 - val_accuracy: 0.6482\n",
      "Epoch 53/100\n",
      "421/421 [==============================] - 1s 3ms/step - loss: 1.9158e-04 - accuracy: 0.6585 - val_loss: 0.0176 - val_accuracy: 0.6786\n",
      "Epoch 54/100\n",
      "421/421 [==============================] - 1s 4ms/step - loss: 1.7442e-04 - accuracy: 0.6469 - val_loss: 0.0179 - val_accuracy: 0.6401\n",
      "Epoch 55/100\n",
      "421/421 [==============================] - 2s 4ms/step - loss: 1.6717e-04 - accuracy: 0.6350 - val_loss: 0.0183 - val_accuracy: 0.6010\n",
      "Epoch 56/100\n",
      "421/421 [==============================] - 2s 4ms/step - loss: 1.3311e-04 - accuracy: 0.6191 - val_loss: 0.0187 - val_accuracy: 0.6271\n",
      "Epoch 57/100\n",
      "421/421 [==============================] - 1s 3ms/step - loss: 1.1891e-04 - accuracy: 0.6065 - val_loss: 0.0190 - val_accuracy: 0.6391\n",
      "Epoch 58/100\n",
      "421/421 [==============================] - 1s 3ms/step - loss: 1.2062e-04 - accuracy: 0.6095 - val_loss: 0.0193 - val_accuracy: 0.5953\n",
      "Epoch 59/100\n",
      "421/421 [==============================] - 1s 3ms/step - loss: 9.4639e-05 - accuracy: 0.5853 - val_loss: 0.0195 - val_accuracy: 0.6000\n",
      "Epoch 60/100\n",
      "421/421 [==============================] - 1s 3ms/step - loss: 9.2998e-05 - accuracy: 0.5941 - val_loss: 0.0200 - val_accuracy: 0.5753\n",
      "Epoch 61/100\n",
      "421/421 [==============================] - 2s 4ms/step - loss: 8.1363e-05 - accuracy: 0.5808 - val_loss: 0.0203 - val_accuracy: 0.5676\n",
      "Epoch 62/100\n",
      "421/421 [==============================] - 2s 4ms/step - loss: 8.3783e-05 - accuracy: 0.5615 - val_loss: 0.0208 - val_accuracy: 0.5602\n",
      "Epoch 63/100\n",
      "421/421 [==============================] - 2s 4ms/step - loss: 7.5050e-05 - accuracy: 0.5582 - val_loss: 0.0213 - val_accuracy: 0.5452\n",
      "Epoch 64/100\n",
      "421/421 [==============================] - 2s 4ms/step - loss: 6.8310e-05 - accuracy: 0.5486 - val_loss: 0.0214 - val_accuracy: 0.5776\n",
      "Epoch 65/100\n",
      "421/421 [==============================] - 2s 4ms/step - loss: 1.2118e-04 - accuracy: 0.5311 - val_loss: 0.0213 - val_accuracy: 0.5378\n",
      "Epoch 66/100\n",
      "421/421 [==============================] - 2s 4ms/step - loss: 5.8781e-05 - accuracy: 0.5287 - val_loss: 0.0215 - val_accuracy: 0.5064\n",
      "Epoch 67/100\n",
      "421/421 [==============================] - 2s 5ms/step - loss: 5.5308e-05 - accuracy: 0.5065 - val_loss: 0.0218 - val_accuracy: 0.5087\n",
      "Epoch 68/100\n",
      "421/421 [==============================] - 2s 4ms/step - loss: 5.0381e-05 - accuracy: 0.5105 - val_loss: 0.0221 - val_accuracy: 0.5084\n",
      "Epoch 69/100\n",
      "421/421 [==============================] - 2s 4ms/step - loss: 5.2403e-05 - accuracy: 0.5087 - val_loss: 0.0224 - val_accuracy: 0.4946\n",
      "Epoch 70/100\n",
      "421/421 [==============================] - 2s 4ms/step - loss: 5.4886e-05 - accuracy: 0.5027 - val_loss: 0.0227 - val_accuracy: 0.4987\n",
      "Epoch 71/100\n",
      "421/421 [==============================] - 2s 4ms/step - loss: 4.1568e-05 - accuracy: 0.5024 - val_loss: 0.0227 - val_accuracy: 0.4916\n",
      "Epoch 72/100\n",
      "421/421 [==============================] - 2s 4ms/step - loss: 5.2600e-05 - accuracy: 0.4853 - val_loss: 0.0231 - val_accuracy: 0.4903\n",
      "Epoch 73/100\n",
      "421/421 [==============================] - 2s 4ms/step - loss: 4.3887e-05 - accuracy: 0.4869 - val_loss: 0.0233 - val_accuracy: 0.4642\n",
      "Epoch 74/100\n",
      "421/421 [==============================] - 2s 4ms/step - loss: 3.2814e-05 - accuracy: 0.4757 - val_loss: 0.0233 - val_accuracy: 0.4769\n",
      "Epoch 75/100\n",
      "421/421 [==============================] - 2s 4ms/step - loss: 4.3346e-05 - accuracy: 0.4751 - val_loss: 0.0237 - val_accuracy: 0.4468\n",
      "Epoch 76/100\n",
      "421/421 [==============================] - 2s 4ms/step - loss: 4.7678e-05 - accuracy: 0.4600 - val_loss: 0.0237 - val_accuracy: 0.4495\n",
      "Epoch 77/100\n",
      "421/421 [==============================] - 2s 4ms/step - loss: 2.7439e-05 - accuracy: 0.4604 - val_loss: 0.0242 - val_accuracy: 0.4388\n",
      "Epoch 78/100\n",
      "421/421 [==============================] - 2s 4ms/step - loss: 3.4456e-05 - accuracy: 0.4586 - val_loss: 0.0241 - val_accuracy: 0.4642\n",
      "Epoch 79/100\n",
      "421/421 [==============================] - 1s 4ms/step - loss: 3.5602e-05 - accuracy: 0.4591 - val_loss: 0.0244 - val_accuracy: 0.4505\n",
      "Epoch 80/100\n",
      "421/421 [==============================] - 2s 4ms/step - loss: 3.8267e-05 - accuracy: 0.4503 - val_loss: 0.0244 - val_accuracy: 0.4518\n",
      "Epoch 81/100\n",
      "421/421 [==============================] - 2s 4ms/step - loss: 3.0026e-05 - accuracy: 0.4471 - val_loss: 0.0249 - val_accuracy: 0.4351\n",
      "Epoch 82/100\n",
      "421/421 [==============================] - 2s 4ms/step - loss: 3.3510e-05 - accuracy: 0.4452 - val_loss: 0.0248 - val_accuracy: 0.4224\n",
      "Epoch 83/100\n",
      "421/421 [==============================] - 2s 4ms/step - loss: 2.5454e-05 - accuracy: 0.4336 - val_loss: 0.0251 - val_accuracy: 0.4515\n",
      "Epoch 84/100\n",
      "421/421 [==============================] - 2s 4ms/step - loss: 3.3408e-05 - accuracy: 0.4456 - val_loss: 0.0254 - val_accuracy: 0.4251\n",
      "Epoch 85/100\n",
      "421/421 [==============================] - 1s 4ms/step - loss: 3.7245e-05 - accuracy: 0.4247 - val_loss: 0.0253 - val_accuracy: 0.4237\n",
      "Epoch 86/100\n",
      "421/421 [==============================] - 1s 3ms/step - loss: 2.5549e-05 - accuracy: 0.4294 - val_loss: 0.0255 - val_accuracy: 0.4187\n",
      "Epoch 87/100\n",
      "421/421 [==============================] - 1s 3ms/step - loss: 2.5476e-05 - accuracy: 0.4261 - val_loss: 0.0257 - val_accuracy: 0.4047\n",
      "Epoch 88/100\n",
      "421/421 [==============================] - 1s 3ms/step - loss: 2.8482e-05 - accuracy: 0.4179 - val_loss: 0.0258 - val_accuracy: 0.4161\n",
      "Epoch 89/100\n",
      "421/421 [==============================] - 1s 3ms/step - loss: 2.3784e-05 - accuracy: 0.4352 - val_loss: 0.0259 - val_accuracy: 0.4094\n",
      "Epoch 90/100\n",
      "421/421 [==============================] - 1s 3ms/step - loss: 2.0425e-05 - accuracy: 0.4150 - val_loss: 0.0262 - val_accuracy: 0.4087\n",
      "Epoch 91/100\n",
      "421/421 [==============================] - 1s 3ms/step - loss: 2.4551e-05 - accuracy: 0.4096 - val_loss: 0.0262 - val_accuracy: 0.4064\n",
      "Epoch 92/100\n",
      "421/421 [==============================] - 1s 3ms/step - loss: 2.8919e-05 - accuracy: 0.4078 - val_loss: 0.0265 - val_accuracy: 0.4010\n",
      "Epoch 93/100\n",
      "421/421 [==============================] - 1s 3ms/step - loss: 1.7438e-05 - accuracy: 0.4100 - val_loss: 0.0266 - val_accuracy: 0.3973\n",
      "Epoch 94/100\n",
      "421/421 [==============================] - 1s 3ms/step - loss: 2.2491e-05 - accuracy: 0.4095 - val_loss: 0.0266 - val_accuracy: 0.3916\n",
      "Epoch 95/100\n",
      "421/421 [==============================] - 1s 3ms/step - loss: 2.2031e-05 - accuracy: 0.3956 - val_loss: 0.0267 - val_accuracy: 0.3903\n",
      "Epoch 96/100\n",
      "421/421 [==============================] - 1s 3ms/step - loss: 1.8773e-05 - accuracy: 0.4010 - val_loss: 0.0269 - val_accuracy: 0.3816\n",
      "Epoch 97/100\n",
      "421/421 [==============================] - 1s 3ms/step - loss: 2.0342e-05 - accuracy: 0.3939 - val_loss: 0.0270 - val_accuracy: 0.3826\n",
      "Epoch 98/100\n",
      "421/421 [==============================] - 1s 3ms/step - loss: 2.3539e-05 - accuracy: 0.3956 - val_loss: 0.0271 - val_accuracy: 0.3776\n",
      "Epoch 99/100\n",
      "421/421 [==============================] - 1s 3ms/step - loss: 2.2159e-05 - accuracy: 0.3938 - val_loss: 0.0271 - val_accuracy: 0.3793\n",
      "Epoch 100/100\n",
      "421/421 [==============================] - 1s 3ms/step - loss: 1.5811e-05 - accuracy: 0.3920 - val_loss: 0.0274 - val_accuracy: 0.3863\n",
      "Score for fold 1 : loss of 0.02735821343958378 ; F1-Macro: 0.6494053422253019 F1-Micro: 0.9390153572663079\n",
      "Training...\n",
      "Epoch 1/100\n",
      "421/421 [==============================] - 2s 3ms/step - loss: 0.0587 - accuracy: 0.8732 - val_loss: 0.0205 - val_accuracy: 0.9666\n",
      "Epoch 2/100\n",
      "421/421 [==============================] - 1s 4ms/step - loss: 0.0166 - accuracy: 0.9800 - val_loss: 0.0139 - val_accuracy: 0.9816\n",
      "Epoch 3/100\n",
      "421/421 [==============================] - 2s 4ms/step - loss: 0.0124 - accuracy: 0.8042 - val_loss: 0.0116 - val_accuracy: 0.9087\n",
      "Epoch 4/100\n",
      "421/421 [==============================] - 1s 3ms/step - loss: 0.0106 - accuracy: 0.8492 - val_loss: 0.0105 - val_accuracy: 0.6946\n",
      "Epoch 5/100\n",
      "421/421 [==============================] - 1s 3ms/step - loss: 0.0096 - accuracy: 0.6556 - val_loss: 0.0098 - val_accuracy: 0.4438\n",
      "Epoch 6/100\n",
      "421/421 [==============================] - 1s 3ms/step - loss: 0.0089 - accuracy: 0.5955 - val_loss: 0.0094 - val_accuracy: 0.5599\n",
      "Epoch 7/100\n",
      "421/421 [==============================] - 1s 3ms/step - loss: 0.0083 - accuracy: 0.5513 - val_loss: 0.0091 - val_accuracy: 0.7702\n",
      "Epoch 8/100\n",
      "421/421 [==============================] - 1s 3ms/step - loss: 0.0079 - accuracy: 0.5854 - val_loss: 0.0090 - val_accuracy: 0.2716\n",
      "Epoch 9/100\n",
      "421/421 [==============================] - 1s 3ms/step - loss: 0.0075 - accuracy: 0.5580 - val_loss: 0.0088 - val_accuracy: 0.3796\n",
      "Epoch 10/100\n",
      "421/421 [==============================] - 1s 3ms/step - loss: 0.0072 - accuracy: 0.5865 - val_loss: 0.0087 - val_accuracy: 0.5087\n",
      "Epoch 11/100\n",
      "421/421 [==============================] - 1s 4ms/step - loss: 0.0069 - accuracy: 0.6346 - val_loss: 0.0086 - val_accuracy: 0.8863\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/100\n",
      "421/421 [==============================] - 1s 3ms/step - loss: 0.0067 - accuracy: 0.6558 - val_loss: 0.0085 - val_accuracy: 0.6428\n",
      "Epoch 13/100\n",
      "421/421 [==============================] - 1s 3ms/step - loss: 0.0064 - accuracy: 0.7033 - val_loss: 0.0086 - val_accuracy: 0.6679\n",
      "Epoch 14/100\n",
      "421/421 [==============================] - 1s 3ms/step - loss: 0.0062 - accuracy: 0.7009 - val_loss: 0.0087 - val_accuracy: 0.5064\n",
      "Epoch 15/100\n",
      "421/421 [==============================] - 1s 4ms/step - loss: 0.0060 - accuracy: 0.6875 - val_loss: 0.0086 - val_accuracy: 0.6468\n",
      "Epoch 16/100\n",
      "421/421 [==============================] - 2s 4ms/step - loss: 0.0058 - accuracy: 0.6282 - val_loss: 0.0086 - val_accuracy: 0.4876\n",
      "Epoch 17/100\n",
      "421/421 [==============================] - 2s 4ms/step - loss: 0.0056 - accuracy: 0.7290 - val_loss: 0.0087 - val_accuracy: 0.6900\n",
      "Epoch 18/100\n",
      "421/421 [==============================] - 2s 4ms/step - loss: 0.0054 - accuracy: 0.7343 - val_loss: 0.0087 - val_accuracy: 0.8020\n",
      "Epoch 19/100\n",
      "421/421 [==============================] - 2s 4ms/step - loss: 0.0052 - accuracy: 0.7615 - val_loss: 0.0088 - val_accuracy: 0.4926\n",
      "Epoch 20/100\n",
      "421/421 [==============================] - 1s 3ms/step - loss: 0.0050 - accuracy: 0.7093 - val_loss: 0.0088 - val_accuracy: 0.5789\n",
      "Epoch 21/100\n",
      "421/421 [==============================] - 1s 3ms/step - loss: 0.0048 - accuracy: 0.7157 - val_loss: 0.0089 - val_accuracy: 0.6826\n",
      "Epoch 22/100\n",
      "421/421 [==============================] - 1s 3ms/step - loss: 0.0045 - accuracy: 0.8187 - val_loss: 0.0090 - val_accuracy: 0.7565\n",
      "Epoch 23/100\n",
      "421/421 [==============================] - 1s 3ms/step - loss: 0.0044 - accuracy: 0.7737 - val_loss: 0.0092 - val_accuracy: 0.7669\n",
      "Epoch 24/100\n",
      "421/421 [==============================] - 2s 4ms/step - loss: 0.0042 - accuracy: 0.7646 - val_loss: 0.0093 - val_accuracy: 0.7261\n",
      "Epoch 25/100\n",
      "421/421 [==============================] - 2s 4ms/step - loss: 0.0039 - accuracy: 0.8146 - val_loss: 0.0093 - val_accuracy: 0.7796\n",
      "Epoch 26/100\n",
      "421/421 [==============================] - 2s 4ms/step - loss: 0.0037 - accuracy: 0.8156 - val_loss: 0.0095 - val_accuracy: 0.6702\n",
      "Epoch 27/100\n",
      "421/421 [==============================] - 2s 4ms/step - loss: 0.0035 - accuracy: 0.7719 - val_loss: 0.0096 - val_accuracy: 0.7883\n",
      "Epoch 28/100\n",
      "421/421 [==============================] - 2s 4ms/step - loss: 0.0033 - accuracy: 0.8096 - val_loss: 0.0098 - val_accuracy: 0.8013\n",
      "Epoch 29/100\n",
      "421/421 [==============================] - 1s 3ms/step - loss: 0.0031 - accuracy: 0.8093 - val_loss: 0.0099 - val_accuracy: 0.7545\n",
      "Epoch 30/100\n",
      "421/421 [==============================] - 1s 4ms/step - loss: 0.0029 - accuracy: 0.7826 - val_loss: 0.0101 - val_accuracy: 0.8080\n",
      "Epoch 31/100\n",
      "421/421 [==============================] - 1s 4ms/step - loss: 0.0027 - accuracy: 0.7962 - val_loss: 0.0103 - val_accuracy: 0.7856\n",
      "Epoch 32/100\n",
      "421/421 [==============================] - 1s 4ms/step - loss: 0.0024 - accuracy: 0.7608 - val_loss: 0.0106 - val_accuracy: 0.7304\n",
      "Epoch 33/100\n",
      "421/421 [==============================] - 1s 3ms/step - loss: 0.0022 - accuracy: 0.7450 - val_loss: 0.0108 - val_accuracy: 0.8201\n",
      "Epoch 34/100\n",
      "421/421 [==============================] - 1s 3ms/step - loss: 0.0020 - accuracy: 0.7589 - val_loss: 0.0112 - val_accuracy: 0.7147\n",
      "Epoch 35/100\n",
      "421/421 [==============================] - 2s 4ms/step - loss: 0.0019 - accuracy: 0.7383 - val_loss: 0.0113 - val_accuracy: 0.7498\n",
      "Epoch 36/100\n",
      "421/421 [==============================] - 1s 3ms/step - loss: 0.0017 - accuracy: 0.7304 - val_loss: 0.0116 - val_accuracy: 0.7211\n",
      "Epoch 37/100\n",
      "421/421 [==============================] - 1s 3ms/step - loss: 0.0015 - accuracy: 0.7246 - val_loss: 0.0119 - val_accuracy: 0.7147\n",
      "Epoch 38/100\n",
      "421/421 [==============================] - 1s 3ms/step - loss: 0.0014 - accuracy: 0.7145 - val_loss: 0.0120 - val_accuracy: 0.7100\n",
      "Epoch 39/100\n",
      "421/421 [==============================] - 2s 4ms/step - loss: 0.0012 - accuracy: 0.7072 - val_loss: 0.0125 - val_accuracy: 0.6926\n",
      "Epoch 40/100\n",
      "421/421 [==============================] - 1s 4ms/step - loss: 0.0011 - accuracy: 0.6857 - val_loss: 0.0128 - val_accuracy: 0.6833\n",
      "Epoch 41/100\n",
      "421/421 [==============================] - 1s 4ms/step - loss: 9.6590e-04 - accuracy: 0.6724 - val_loss: 0.0130 - val_accuracy: 0.7067\n",
      "Epoch 42/100\n",
      "421/421 [==============================] - 1s 3ms/step - loss: 8.5666e-04 - accuracy: 0.6755 - val_loss: 0.0133 - val_accuracy: 0.6702\n",
      "Epoch 43/100\n",
      "421/421 [==============================] - 1s 3ms/step - loss: 7.4743e-04 - accuracy: 0.6506 - val_loss: 0.0136 - val_accuracy: 0.6472\n",
      "Epoch 44/100\n",
      "421/421 [==============================] - 1s 3ms/step - loss: 6.5980e-04 - accuracy: 0.6512 - val_loss: 0.0142 - val_accuracy: 0.6508\n",
      "Epoch 45/100\n",
      "421/421 [==============================] - 1s 4ms/step - loss: 5.6822e-04 - accuracy: 0.6321 - val_loss: 0.0144 - val_accuracy: 0.6090\n",
      "Epoch 46/100\n",
      "421/421 [==============================] - 1s 3ms/step - loss: 4.9830e-04 - accuracy: 0.6192 - val_loss: 0.0150 - val_accuracy: 0.6151\n",
      "Epoch 47/100\n",
      "421/421 [==============================] - 1s 4ms/step - loss: 4.3095e-04 - accuracy: 0.6108 - val_loss: 0.0153 - val_accuracy: 0.6047\n",
      "Epoch 48/100\n",
      "421/421 [==============================] - 1s 3ms/step - loss: 3.7136e-04 - accuracy: 0.5927 - val_loss: 0.0156 - val_accuracy: 0.6084\n",
      "Epoch 49/100\n",
      "421/421 [==============================] - 2s 4ms/step - loss: 3.2652e-04 - accuracy: 0.5855 - val_loss: 0.0159 - val_accuracy: 0.5475\n",
      "Epoch 50/100\n",
      "421/421 [==============================] - 1s 3ms/step - loss: 2.8284e-04 - accuracy: 0.5636 - val_loss: 0.0162 - val_accuracy: 0.5769\n",
      "Epoch 51/100\n",
      "421/421 [==============================] - 1s 4ms/step - loss: 2.3846e-04 - accuracy: 0.5721 - val_loss: 0.0166 - val_accuracy: 0.5555\n",
      "Epoch 52/100\n",
      "421/421 [==============================] - 1s 3ms/step - loss: 2.0934e-04 - accuracy: 0.5393 - val_loss: 0.0171 - val_accuracy: 0.5425\n",
      "Epoch 53/100\n",
      "421/421 [==============================] - 1s 3ms/step - loss: 1.8748e-04 - accuracy: 0.5483 - val_loss: 0.0174 - val_accuracy: 0.4997\n",
      "Epoch 54/100\n",
      "421/421 [==============================] - 1s 4ms/step - loss: 1.5568e-04 - accuracy: 0.5138 - val_loss: 0.0179 - val_accuracy: 0.5482\n",
      "Epoch 55/100\n",
      "421/421 [==============================] - 1s 3ms/step - loss: 1.4498e-04 - accuracy: 0.5187 - val_loss: 0.0181 - val_accuracy: 0.5033\n",
      "Epoch 56/100\n",
      "421/421 [==============================] - 1s 4ms/step - loss: 1.2449e-04 - accuracy: 0.4996 - val_loss: 0.0186 - val_accuracy: 0.5385\n",
      "Epoch 57/100\n",
      "421/421 [==============================] - 1s 3ms/step - loss: 1.1439e-04 - accuracy: 0.5046 - val_loss: 0.0190 - val_accuracy: 0.4659\n",
      "Epoch 58/100\n",
      "421/421 [==============================] - 1s 3ms/step - loss: 9.2390e-05 - accuracy: 0.4866 - val_loss: 0.0195 - val_accuracy: 0.5171\n",
      "Epoch 59/100\n",
      "421/421 [==============================] - 1s 3ms/step - loss: 8.7836e-05 - accuracy: 0.4821 - val_loss: 0.0196 - val_accuracy: 0.4769\n",
      "Epoch 60/100\n",
      "421/421 [==============================] - 2s 4ms/step - loss: 7.5132e-05 - accuracy: 0.4830 - val_loss: 0.0200 - val_accuracy: 0.4518\n",
      "Epoch 61/100\n",
      "421/421 [==============================] - 2s 4ms/step - loss: 7.1012e-05 - accuracy: 0.4599 - val_loss: 0.0203 - val_accuracy: 0.4672\n",
      "Epoch 62/100\n",
      "421/421 [==============================] - 2s 4ms/step - loss: 6.2752e-05 - accuracy: 0.4647 - val_loss: 0.0206 - val_accuracy: 0.4515\n",
      "Epoch 63/100\n",
      "421/421 [==============================] - 2s 4ms/step - loss: 5.2864e-05 - accuracy: 0.4555 - val_loss: 0.0212 - val_accuracy: 0.4311\n",
      "Epoch 64/100\n",
      "421/421 [==============================] - 2s 4ms/step - loss: 5.8233e-05 - accuracy: 0.4445 - val_loss: 0.0214 - val_accuracy: 0.4358\n",
      "Epoch 65/100\n",
      "421/421 [==============================] - 1s 3ms/step - loss: 5.6260e-05 - accuracy: 0.4403 - val_loss: 0.0217 - val_accuracy: 0.4445\n",
      "Epoch 66/100\n",
      "421/421 [==============================] - 1s 4ms/step - loss: 5.0701e-05 - accuracy: 0.4303 - val_loss: 0.0221 - val_accuracy: 0.4301\n",
      "Epoch 67/100\n",
      "421/421 [==============================] - 1s 4ms/step - loss: 4.4281e-05 - accuracy: 0.4371 - val_loss: 0.0223 - val_accuracy: 0.4184\n",
      "Epoch 68/100\n",
      "421/421 [==============================] - 1s 4ms/step - loss: 3.8572e-05 - accuracy: 0.4194 - val_loss: 0.0226 - val_accuracy: 0.4117\n",
      "Epoch 69/100\n",
      "421/421 [==============================] - 1s 4ms/step - loss: 2.9895e-05 - accuracy: 0.4164 - val_loss: 0.0228 - val_accuracy: 0.4054\n",
      "Epoch 70/100\n",
      "421/421 [==============================] - 1s 3ms/step - loss: 4.9449e-05 - accuracy: 0.4107 - val_loss: 0.0231 - val_accuracy: 0.4084\n",
      "Epoch 71/100\n",
      "421/421 [==============================] - 1s 3ms/step - loss: 4.4481e-05 - accuracy: 0.3980 - val_loss: 0.0234 - val_accuracy: 0.4033\n",
      "Epoch 72/100\n",
      "421/421 [==============================] - 1s 3ms/step - loss: 3.5089e-05 - accuracy: 0.4020 - val_loss: 0.0236 - val_accuracy: 0.3943\n",
      "Epoch 73/100\n",
      "421/421 [==============================] - 1s 3ms/step - loss: 3.1246e-05 - accuracy: 0.3994 - val_loss: 0.0239 - val_accuracy: 0.3682\n",
      "Epoch 74/100\n",
      "421/421 [==============================] - 1s 3ms/step - loss: 2.5167e-05 - accuracy: 0.3901 - val_loss: 0.0240 - val_accuracy: 0.3843\n",
      "Epoch 75/100\n",
      "421/421 [==============================] - 1s 3ms/step - loss: 2.5173e-05 - accuracy: 0.3902 - val_loss: 0.0245 - val_accuracy: 0.3669\n",
      "Epoch 76/100\n",
      "421/421 [==============================] - 1s 3ms/step - loss: 2.7486e-05 - accuracy: 0.3914 - val_loss: 0.0248 - val_accuracy: 0.3582\n",
      "Epoch 77/100\n",
      "421/421 [==============================] - 1s 3ms/step - loss: 2.8095e-05 - accuracy: 0.3822 - val_loss: 0.0250 - val_accuracy: 0.3545\n",
      "Epoch 78/100\n",
      "421/421 [==============================] - 1s 3ms/step - loss: 1.8499e-05 - accuracy: 0.3794 - val_loss: 0.0252 - val_accuracy: 0.3522\n",
      "Epoch 79/100\n",
      "421/421 [==============================] - 1s 3ms/step - loss: 2.2617e-05 - accuracy: 0.3751 - val_loss: 0.0255 - val_accuracy: 0.3702\n",
      "Epoch 80/100\n",
      "421/421 [==============================] - 1s 3ms/step - loss: 1.6113e-05 - accuracy: 0.3786 - val_loss: 0.0256 - val_accuracy: 0.3545\n",
      "Epoch 81/100\n",
      "421/421 [==============================] - 1s 3ms/step - loss: 3.0775e-05 - accuracy: 0.3736 - val_loss: 0.0258 - val_accuracy: 0.3448\n",
      "Epoch 82/100\n",
      "421/421 [==============================] - 1s 3ms/step - loss: 2.6872e-05 - accuracy: 0.3551 - val_loss: 0.0258 - val_accuracy: 0.3548\n",
      "Epoch 83/100\n",
      "421/421 [==============================] - 1s 3ms/step - loss: 2.5272e-05 - accuracy: 0.3603 - val_loss: 0.0260 - val_accuracy: 0.3381\n",
      "Epoch 84/100\n",
      "421/421 [==============================] - 1s 3ms/step - loss: 1.7987e-05 - accuracy: 0.3601 - val_loss: 0.0263 - val_accuracy: 0.3512\n",
      "Epoch 85/100\n",
      "421/421 [==============================] - 1s 3ms/step - loss: 1.9929e-05 - accuracy: 0.3579 - val_loss: 0.0263 - val_accuracy: 0.3247\n",
      "Epoch 86/100\n",
      "421/421 [==============================] - 1s 3ms/step - loss: 1.4277e-05 - accuracy: 0.3501 - val_loss: 0.0268 - val_accuracy: 0.3478\n",
      "Epoch 87/100\n",
      "421/421 [==============================] - 1s 3ms/step - loss: 2.1584e-05 - accuracy: 0.3570 - val_loss: 0.0268 - val_accuracy: 0.3458\n",
      "Epoch 88/100\n",
      "421/421 [==============================] - 2s 4ms/step - loss: 2.2477e-05 - accuracy: 0.3493 - val_loss: 0.0270 - val_accuracy: 0.3385\n",
      "Epoch 89/100\n",
      "421/421 [==============================] - 1s 3ms/step - loss: 1.6441e-05 - accuracy: 0.3473 - val_loss: 0.0269 - val_accuracy: 0.3361\n",
      "Epoch 90/100\n",
      "421/421 [==============================] - 1s 3ms/step - loss: 1.6752e-05 - accuracy: 0.3479 - val_loss: 0.0272 - val_accuracy: 0.3274\n",
      "Epoch 91/100\n",
      "421/421 [==============================] - 1s 3ms/step - loss: 1.5993e-05 - accuracy: 0.3492 - val_loss: 0.0274 - val_accuracy: 0.3258\n",
      "Epoch 92/100\n",
      "421/421 [==============================] - 1s 3ms/step - loss: 1.3207e-05 - accuracy: 0.3416 - val_loss: 0.0276 - val_accuracy: 0.3268\n",
      "Epoch 93/100\n",
      "421/421 [==============================] - 1s 3ms/step - loss: 2.0379e-05 - accuracy: 0.3360 - val_loss: 0.0275 - val_accuracy: 0.3197\n",
      "Epoch 94/100\n",
      "421/421 [==============================] - 1s 3ms/step - loss: 1.2226e-05 - accuracy: 0.3392 - val_loss: 0.0278 - val_accuracy: 0.3288\n",
      "Epoch 95/100\n",
      "421/421 [==============================] - 1s 3ms/step - loss: 1.5121e-05 - accuracy: 0.3350 - val_loss: 0.0280 - val_accuracy: 0.3274\n",
      "Epoch 96/100\n",
      "421/421 [==============================] - 1s 3ms/step - loss: 1.7414e-05 - accuracy: 0.3365 - val_loss: 0.0280 - val_accuracy: 0.3107\n",
      "Epoch 97/100\n",
      "421/421 [==============================] - 1s 3ms/step - loss: 1.6659e-05 - accuracy: 0.3299 - val_loss: 0.0282 - val_accuracy: 0.3181\n",
      "Epoch 98/100\n",
      "421/421 [==============================] - 1s 3ms/step - loss: 1.3413e-05 - accuracy: 0.3322 - val_loss: 0.0282 - val_accuracy: 0.3124\n",
      "Epoch 99/100\n",
      "421/421 [==============================] - 1s 3ms/step - loss: 1.5928e-05 - accuracy: 0.3309 - val_loss: 0.0283 - val_accuracy: 0.3107\n",
      "Epoch 100/100\n",
      "421/421 [==============================] - 1s 3ms/step - loss: 9.4781e-06 - accuracy: 0.3268 - val_loss: 0.0285 - val_accuracy: 0.3161\n",
      "Score for fold 2 : loss of 0.02847907319664955 ; F1-Macro: 0.7240974102951583 F1-Micro: 0.9410319410319411\n",
      "Training...\n",
      "Epoch 1/100\n",
      "421/421 [==============================] - 2s 4ms/step - loss: 0.0585 - accuracy: 0.4900 - val_loss: 0.0201 - val_accuracy: 0.9144\n",
      "Epoch 2/100\n",
      "421/421 [==============================] - 1s 3ms/step - loss: 0.0165 - accuracy: 0.9802 - val_loss: 0.0137 - val_accuracy: 0.9689\n",
      "Epoch 3/100\n",
      "421/421 [==============================] - 1s 3ms/step - loss: 0.0125 - accuracy: 0.8843 - val_loss: 0.0115 - val_accuracy: 0.7348\n",
      "Epoch 4/100\n",
      "421/421 [==============================] - 1s 4ms/step - loss: 0.0107 - accuracy: 0.7054 - val_loss: 0.0104 - val_accuracy: 0.9040\n",
      "Epoch 5/100\n",
      "421/421 [==============================] - 1s 3ms/step - loss: 0.0097 - accuracy: 0.6926 - val_loss: 0.0097 - val_accuracy: 0.6946\n",
      "Epoch 6/100\n",
      "421/421 [==============================] - 1s 3ms/step - loss: 0.0089 - accuracy: 0.4634 - val_loss: 0.0093 - val_accuracy: 0.8769\n",
      "Epoch 7/100\n",
      "421/421 [==============================] - 1s 3ms/step - loss: 0.0084 - accuracy: 0.6066 - val_loss: 0.0090 - val_accuracy: 0.1766\n",
      "Epoch 8/100\n",
      "421/421 [==============================] - 1s 3ms/step - loss: 0.0080 - accuracy: 0.5276 - val_loss: 0.0087 - val_accuracy: 0.2308\n",
      "Epoch 9/100\n",
      "421/421 [==============================] - 1s 3ms/step - loss: 0.0076 - accuracy: 0.5140 - val_loss: 0.0086 - val_accuracy: 0.4478\n",
      "Epoch 10/100\n",
      "421/421 [==============================] - 1s 3ms/step - loss: 0.0073 - accuracy: 0.6015 - val_loss: 0.0086 - val_accuracy: 0.4452\n",
      "Epoch 11/100\n",
      "421/421 [==============================] - 1s 3ms/step - loss: 0.0070 - accuracy: 0.5565 - val_loss: 0.0084 - val_accuracy: 0.6736\n",
      "Epoch 12/100\n",
      "421/421 [==============================] - 1s 3ms/step - loss: 0.0068 - accuracy: 0.6527 - val_loss: 0.0083 - val_accuracy: 0.6773\n",
      "Epoch 13/100\n",
      "421/421 [==============================] - 1s 3ms/step - loss: 0.0065 - accuracy: 0.7121 - val_loss: 0.0083 - val_accuracy: 0.6398\n",
      "Epoch 14/100\n",
      "421/421 [==============================] - 1s 3ms/step - loss: 0.0063 - accuracy: 0.6939 - val_loss: 0.0082 - val_accuracy: 0.5816\n",
      "Epoch 15/100\n",
      "421/421 [==============================] - 1s 4ms/step - loss: 0.0061 - accuracy: 0.7078 - val_loss: 0.0081 - val_accuracy: 0.7849\n",
      "Epoch 16/100\n",
      "421/421 [==============================] - 1s 3ms/step - loss: 0.0058 - accuracy: 0.7348 - val_loss: 0.0082 - val_accuracy: 0.8836\n",
      "Epoch 17/100\n",
      "421/421 [==============================] - 1s 3ms/step - loss: 0.0056 - accuracy: 0.7638 - val_loss: 0.0083 - val_accuracy: 0.8054\n",
      "Epoch 18/100\n",
      "421/421 [==============================] - 1s 3ms/step - loss: 0.0054 - accuracy: 0.7577 - val_loss: 0.0082 - val_accuracy: 0.6853\n",
      "Epoch 19/100\n",
      "421/421 [==============================] - 1s 3ms/step - loss: 0.0052 - accuracy: 0.7584 - val_loss: 0.0082 - val_accuracy: 0.8007\n",
      "Epoch 20/100\n",
      "421/421 [==============================] - 1s 3ms/step - loss: 0.0050 - accuracy: 0.7396 - val_loss: 0.0083 - val_accuracy: 0.7324\n",
      "Epoch 21/100\n",
      "421/421 [==============================] - 1s 3ms/step - loss: 0.0048 - accuracy: 0.7914 - val_loss: 0.0083 - val_accuracy: 0.7696\n",
      "Epoch 22/100\n",
      "421/421 [==============================] - 1s 3ms/step - loss: 0.0046 - accuracy: 0.8035 - val_loss: 0.0085 - val_accuracy: 0.7980\n",
      "Epoch 23/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "421/421 [==============================] - 1s 3ms/step - loss: 0.0044 - accuracy: 0.8172 - val_loss: 0.0084 - val_accuracy: 0.8097\n",
      "Epoch 24/100\n",
      "421/421 [==============================] - 1s 4ms/step - loss: 0.0042 - accuracy: 0.8498 - val_loss: 0.0085 - val_accuracy: 0.9274\n",
      "Epoch 25/100\n",
      "421/421 [==============================] - 1s 3ms/step - loss: 0.0040 - accuracy: 0.8510 - val_loss: 0.0086 - val_accuracy: 0.9040\n",
      "Epoch 26/100\n",
      "421/421 [==============================] - 1s 3ms/step - loss: 0.0038 - accuracy: 0.8625 - val_loss: 0.0087 - val_accuracy: 0.8819\n",
      "Epoch 27/100\n",
      "421/421 [==============================] - 1s 3ms/step - loss: 0.0035 - accuracy: 0.8807 - val_loss: 0.0089 - val_accuracy: 0.8896\n",
      "Epoch 28/100\n",
      "421/421 [==============================] - 1s 3ms/step - loss: 0.0034 - accuracy: 0.8863 - val_loss: 0.0090 - val_accuracy: 0.8809\n",
      "Epoch 29/100\n",
      "421/421 [==============================] - 1s 3ms/step - loss: 0.0031 - accuracy: 0.8811 - val_loss: 0.0092 - val_accuracy: 0.9171\n",
      "Epoch 30/100\n",
      "421/421 [==============================] - 1s 3ms/step - loss: 0.0029 - accuracy: 0.8725 - val_loss: 0.0094 - val_accuracy: 0.9388\n",
      "Epoch 31/100\n",
      "421/421 [==============================] - 1s 3ms/step - loss: 0.0027 - accuracy: 0.8838 - val_loss: 0.0096 - val_accuracy: 0.9050\n",
      "Epoch 32/100\n",
      "421/421 [==============================] - 2s 4ms/step - loss: 0.0025 - accuracy: 0.8780 - val_loss: 0.0098 - val_accuracy: 0.9114\n",
      "Epoch 33/100\n",
      "421/421 [==============================] - 2s 4ms/step - loss: 0.0023 - accuracy: 0.8712 - val_loss: 0.0100 - val_accuracy: 0.8886\n",
      "Epoch 34/100\n",
      "421/421 [==============================] - 2s 4ms/step - loss: 0.0021 - accuracy: 0.8662 - val_loss: 0.0101 - val_accuracy: 0.8766\n",
      "Epoch 35/100\n",
      "421/421 [==============================] - 1s 4ms/step - loss: 0.0019 - accuracy: 0.8558 - val_loss: 0.0103 - val_accuracy: 0.8612\n",
      "Epoch 36/100\n",
      "421/421 [==============================] - 2s 4ms/step - loss: 0.0017 - accuracy: 0.8448 - val_loss: 0.0105 - val_accuracy: 0.8441\n",
      "Epoch 37/100\n",
      "421/421 [==============================] - 2s 4ms/step - loss: 0.0015 - accuracy: 0.8557 - val_loss: 0.0109 - val_accuracy: 0.8462\n",
      "Epoch 38/100\n",
      "421/421 [==============================] - 1s 3ms/step - loss: 0.0014 - accuracy: 0.8344 - val_loss: 0.0110 - val_accuracy: 0.8174\n",
      "Epoch 39/100\n",
      "421/421 [==============================] - 1s 4ms/step - loss: 0.0012 - accuracy: 0.8304 - val_loss: 0.0112 - val_accuracy: 0.8391\n",
      "Epoch 40/100\n",
      "421/421 [==============================] - 1s 3ms/step - loss: 0.0011 - accuracy: 0.8245 - val_loss: 0.0116 - val_accuracy: 0.8214\n",
      "Epoch 41/100\n",
      "421/421 [==============================] - 1s 3ms/step - loss: 9.8308e-04 - accuracy: 0.8099 - val_loss: 0.0117 - val_accuracy: 0.8311\n",
      "Epoch 42/100\n",
      "421/421 [==============================] - 1s 3ms/step - loss: 8.7349e-04 - accuracy: 0.7976 - val_loss: 0.0121 - val_accuracy: 0.8445\n",
      "Epoch 43/100\n",
      "421/421 [==============================] - 1s 3ms/step - loss: 7.5654e-04 - accuracy: 0.8049 - val_loss: 0.0125 - val_accuracy: 0.7946\n",
      "Epoch 44/100\n",
      "421/421 [==============================] - 1s 3ms/step - loss: 6.7275e-04 - accuracy: 0.8008 - val_loss: 0.0129 - val_accuracy: 0.7699\n",
      "Epoch 45/100\n",
      "421/421 [==============================] - 1s 3ms/step - loss: 5.8591e-04 - accuracy: 0.7747 - val_loss: 0.0132 - val_accuracy: 0.7883\n",
      "Epoch 46/100\n",
      "421/421 [==============================] - 1s 3ms/step - loss: 5.0881e-04 - accuracy: 0.7811 - val_loss: 0.0134 - val_accuracy: 0.7696\n",
      "Epoch 47/100\n",
      "421/421 [==============================] - 1s 3ms/step - loss: 4.4469e-04 - accuracy: 0.7600 - val_loss: 0.0138 - val_accuracy: 0.7843\n",
      "Epoch 48/100\n",
      "421/421 [==============================] - 1s 4ms/step - loss: 3.8838e-04 - accuracy: 0.7666 - val_loss: 0.0142 - val_accuracy: 0.7475\n",
      "Epoch 49/100\n",
      "421/421 [==============================] - 1s 3ms/step - loss: 3.4734e-04 - accuracy: 0.7480 - val_loss: 0.0145 - val_accuracy: 0.8144\n",
      "Epoch 50/100\n",
      "421/421 [==============================] - 1s 4ms/step - loss: 2.9169e-04 - accuracy: 0.7502 - val_loss: 0.0151 - val_accuracy: 0.7518\n",
      "Epoch 51/100\n",
      "421/421 [==============================] - 1s 4ms/step - loss: 2.4952e-04 - accuracy: 0.7425 - val_loss: 0.0151 - val_accuracy: 0.7602\n",
      "Epoch 52/100\n",
      "421/421 [==============================] - 2s 4ms/step - loss: 2.2599e-04 - accuracy: 0.7280 - val_loss: 0.0155 - val_accuracy: 0.7244\n",
      "Epoch 53/100\n",
      "421/421 [==============================] - 2s 4ms/step - loss: 1.9467e-04 - accuracy: 0.7170 - val_loss: 0.0158 - val_accuracy: 0.7084\n",
      "Epoch 54/100\n",
      "421/421 [==============================] - 1s 4ms/step - loss: 1.7574e-04 - accuracy: 0.7102 - val_loss: 0.0161 - val_accuracy: 0.6826\n",
      "Epoch 55/100\n",
      "421/421 [==============================] - 2s 4ms/step - loss: 1.4383e-04 - accuracy: 0.7048 - val_loss: 0.0164 - val_accuracy: 0.7167\n",
      "Epoch 56/100\n",
      "421/421 [==============================] - 1s 4ms/step - loss: 1.4043e-04 - accuracy: 0.6953 - val_loss: 0.0170 - val_accuracy: 0.6595\n",
      "Epoch 57/100\n",
      "421/421 [==============================] - 2s 4ms/step - loss: 1.4870e-04 - accuracy: 0.6787 - val_loss: 0.0170 - val_accuracy: 0.6542\n",
      "Epoch 58/100\n",
      "421/421 [==============================] - 1s 3ms/step - loss: 1.0831e-04 - accuracy: 0.6753 - val_loss: 0.0172 - val_accuracy: 0.6595\n",
      "Epoch 59/100\n",
      "421/421 [==============================] - 2s 4ms/step - loss: 1.0461e-04 - accuracy: 0.6666 - val_loss: 0.0175 - val_accuracy: 0.6405\n",
      "Epoch 60/100\n",
      "421/421 [==============================] - 1s 3ms/step - loss: 8.1297e-05 - accuracy: 0.6657 - val_loss: 0.0180 - val_accuracy: 0.6813\n",
      "Epoch 61/100\n",
      "421/421 [==============================] - 1s 4ms/step - loss: 9.2714e-05 - accuracy: 0.6620 - val_loss: 0.0181 - val_accuracy: 0.6729\n",
      "Epoch 62/100\n",
      "421/421 [==============================] - 1s 3ms/step - loss: 7.8658e-05 - accuracy: 0.6486 - val_loss: 0.0184 - val_accuracy: 0.6445\n",
      "Epoch 63/100\n",
      "421/421 [==============================] - 1s 4ms/step - loss: 6.5841e-05 - accuracy: 0.6453 - val_loss: 0.0188 - val_accuracy: 0.6635\n",
      "Epoch 64/100\n",
      "421/421 [==============================] - 1s 3ms/step - loss: 7.5220e-05 - accuracy: 0.6334 - val_loss: 0.0190 - val_accuracy: 0.6385\n",
      "Epoch 65/100\n",
      "421/421 [==============================] - 1s 3ms/step - loss: 5.4842e-05 - accuracy: 0.6312 - val_loss: 0.0194 - val_accuracy: 0.6184\n",
      "Epoch 66/100\n",
      "421/421 [==============================] - 1s 4ms/step - loss: 4.8492e-05 - accuracy: 0.6261 - val_loss: 0.0196 - val_accuracy: 0.6154\n",
      "Epoch 67/100\n",
      "421/421 [==============================] - 2s 4ms/step - loss: 5.7863e-05 - accuracy: 0.6030 - val_loss: 0.0201 - val_accuracy: 0.6227\n",
      "Epoch 68/100\n",
      "421/421 [==============================] - 1s 3ms/step - loss: 5.2891e-05 - accuracy: 0.6054 - val_loss: 0.0204 - val_accuracy: 0.6090\n",
      "Epoch 69/100\n",
      "421/421 [==============================] - 1s 4ms/step - loss: 5.4743e-05 - accuracy: 0.6017 - val_loss: 0.0202 - val_accuracy: 0.6134\n",
      "Epoch 70/100\n",
      "421/421 [==============================] - 2s 5ms/step - loss: 4.4312e-05 - accuracy: 0.5937 - val_loss: 0.0204 - val_accuracy: 0.5813\n",
      "Epoch 71/100\n",
      "421/421 [==============================] - 2s 4ms/step - loss: 3.9827e-05 - accuracy: 0.5911 - val_loss: 0.0207 - val_accuracy: 0.5793\n",
      "Epoch 72/100\n",
      "421/421 [==============================] - 2s 4ms/step - loss: 3.9787e-05 - accuracy: 0.5771 - val_loss: 0.0210 - val_accuracy: 0.6037\n",
      "Epoch 73/100\n",
      "421/421 [==============================] - 1s 4ms/step - loss: 3.4539e-05 - accuracy: 0.5742 - val_loss: 0.0213 - val_accuracy: 0.5957\n",
      "Epoch 74/100\n",
      "421/421 [==============================] - 2s 4ms/step - loss: 4.1138e-05 - accuracy: 0.5774 - val_loss: 0.0212 - val_accuracy: 0.5742\n",
      "Epoch 75/100\n",
      "421/421 [==============================] - 2s 4ms/step - loss: 3.0922e-05 - accuracy: 0.5723 - val_loss: 0.0215 - val_accuracy: 0.5652\n",
      "Epoch 76/100\n",
      "421/421 [==============================] - 2s 4ms/step - loss: 2.3148e-05 - accuracy: 0.5642 - val_loss: 0.0217 - val_accuracy: 0.5706\n",
      "Epoch 77/100\n",
      "421/421 [==============================] - 2s 4ms/step - loss: 3.8490e-05 - accuracy: 0.5564 - val_loss: 0.0222 - val_accuracy: 0.5502\n",
      "Epoch 78/100\n",
      "421/421 [==============================] - 2s 4ms/step - loss: 3.1823e-05 - accuracy: 0.5525 - val_loss: 0.0221 - val_accuracy: 0.5535\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 79/100\n",
      "421/421 [==============================] - 2s 4ms/step - loss: 3.7025e-05 - accuracy: 0.5515 - val_loss: 0.0220 - val_accuracy: 0.5408\n",
      "Epoch 80/100\n",
      "421/421 [==============================] - 2s 4ms/step - loss: 2.5886e-05 - accuracy: 0.5421 - val_loss: 0.0224 - val_accuracy: 0.5562\n",
      "Epoch 81/100\n",
      "421/421 [==============================] - 2s 4ms/step - loss: 2.6795e-05 - accuracy: 0.5410 - val_loss: 0.0226 - val_accuracy: 0.5411\n",
      "Epoch 82/100\n",
      "421/421 [==============================] - 2s 4ms/step - loss: 2.9883e-05 - accuracy: 0.5376 - val_loss: 0.0228 - val_accuracy: 0.5268\n",
      "Epoch 83/100\n",
      "421/421 [==============================] - 1s 4ms/step - loss: 3.2576e-05 - accuracy: 0.5246 - val_loss: 0.0228 - val_accuracy: 0.5375\n",
      "Epoch 84/100\n",
      "421/421 [==============================] - 1s 4ms/step - loss: 2.3169e-05 - accuracy: 0.5264 - val_loss: 0.0229 - val_accuracy: 0.5301\n",
      "Epoch 85/100\n",
      "421/421 [==============================] - 1s 4ms/step - loss: 1.8323e-05 - accuracy: 0.5277 - val_loss: 0.0233 - val_accuracy: 0.5151\n",
      "Epoch 86/100\n",
      "421/421 [==============================] - 2s 4ms/step - loss: 2.4699e-05 - accuracy: 0.5130 - val_loss: 0.0233 - val_accuracy: 0.5207\n",
      "Epoch 87/100\n",
      "421/421 [==============================] - 2s 4ms/step - loss: 1.9885e-05 - accuracy: 0.5210 - val_loss: 0.0233 - val_accuracy: 0.5134\n",
      "Epoch 88/100\n",
      "421/421 [==============================] - 2s 4ms/step - loss: 2.7901e-05 - accuracy: 0.5183 - val_loss: 0.0236 - val_accuracy: 0.5027\n",
      "Epoch 89/100\n",
      "421/421 [==============================] - 2s 4ms/step - loss: 2.0872e-05 - accuracy: 0.5051 - val_loss: 0.0237 - val_accuracy: 0.5144\n",
      "Epoch 90/100\n",
      "421/421 [==============================] - 2s 4ms/step - loss: 1.9023e-05 - accuracy: 0.5053 - val_loss: 0.0236 - val_accuracy: 0.5124\n",
      "Epoch 91/100\n",
      "421/421 [==============================] - 2s 4ms/step - loss: 1.4669e-05 - accuracy: 0.5007 - val_loss: 0.0239 - val_accuracy: 0.4993\n",
      "Epoch 92/100\n",
      "421/421 [==============================] - 2s 4ms/step - loss: 1.9169e-05 - accuracy: 0.4951 - val_loss: 0.0242 - val_accuracy: 0.5134\n",
      "Epoch 93/100\n",
      "421/421 [==============================] - 2s 4ms/step - loss: 2.1140e-05 - accuracy: 0.5008 - val_loss: 0.0240 - val_accuracy: 0.5050\n",
      "Epoch 94/100\n",
      "421/421 [==============================] - 2s 4ms/step - loss: 1.7622e-05 - accuracy: 0.4922 - val_loss: 0.0242 - val_accuracy: 0.4980\n",
      "Epoch 95/100\n",
      "421/421 [==============================] - 2s 4ms/step - loss: 1.9167e-05 - accuracy: 0.4925 - val_loss: 0.0242 - val_accuracy: 0.4843\n",
      "Epoch 96/100\n",
      "421/421 [==============================] - 2s 4ms/step - loss: 2.0513e-05 - accuracy: 0.4866 - val_loss: 0.0244 - val_accuracy: 0.4863\n",
      "Epoch 97/100\n",
      "421/421 [==============================] - 2s 4ms/step - loss: 1.5870e-05 - accuracy: 0.4841 - val_loss: 0.0243 - val_accuracy: 0.5020\n",
      "Epoch 98/100\n",
      "421/421 [==============================] - 2s 4ms/step - loss: 1.8632e-05 - accuracy: 0.4815 - val_loss: 0.0246 - val_accuracy: 0.4923\n",
      "Epoch 99/100\n",
      "421/421 [==============================] - 2s 4ms/step - loss: 1.6204e-05 - accuracy: 0.4821 - val_loss: 0.0246 - val_accuracy: 0.4759\n",
      "Epoch 100/100\n",
      "421/421 [==============================] - 2s 4ms/step - loss: 1.1933e-05 - accuracy: 0.4823 - val_loss: 0.0248 - val_accuracy: 0.4886\n",
      "Score for fold 3 : loss of 0.024841681122779846 ; F1-Macro: 0.7192175068252838 F1-Micro: 0.9434707479634659\n",
      "Training...\n",
      "Epoch 1/100\n",
      "421/421 [==============================] - 2s 4ms/step - loss: 0.0589 - accuracy: 0.9534 - val_loss: 0.0219 - val_accuracy: 0.9903\n",
      "Epoch 2/100\n",
      "421/421 [==============================] - 2s 4ms/step - loss: 0.0165 - accuracy: 0.9944 - val_loss: 0.0153 - val_accuracy: 0.9923\n",
      "Epoch 3/100\n",
      "421/421 [==============================] - 2s 4ms/step - loss: 0.0123 - accuracy: 0.9847 - val_loss: 0.0130 - val_accuracy: 0.9856\n",
      "Epoch 4/100\n",
      "421/421 [==============================] - 2s 4ms/step - loss: 0.0105 - accuracy: 0.9454 - val_loss: 0.0118 - val_accuracy: 0.9010\n",
      "Epoch 5/100\n",
      "421/421 [==============================] - 2s 4ms/step - loss: 0.0095 - accuracy: 0.8893 - val_loss: 0.0110 - val_accuracy: 0.9635\n",
      "Epoch 6/100\n",
      "421/421 [==============================] - 2s 4ms/step - loss: 0.0088 - accuracy: 0.8438 - val_loss: 0.0105 - val_accuracy: 0.7538\n",
      "Epoch 7/100\n",
      "421/421 [==============================] - 2s 4ms/step - loss: 0.0083 - accuracy: 0.7202 - val_loss: 0.0102 - val_accuracy: 0.9699\n",
      "Epoch 8/100\n",
      "421/421 [==============================] - 2s 4ms/step - loss: 0.0079 - accuracy: 0.7300 - val_loss: 0.0100 - val_accuracy: 0.4435\n",
      "Epoch 9/100\n",
      "421/421 [==============================] - 2s 4ms/step - loss: 0.0075 - accuracy: 0.7457 - val_loss: 0.0099 - val_accuracy: 0.7960\n",
      "Epoch 10/100\n",
      "421/421 [==============================] - 2s 4ms/step - loss: 0.0072 - accuracy: 0.7867 - val_loss: 0.0098 - val_accuracy: 0.7358\n",
      "Epoch 11/100\n",
      "421/421 [==============================] - 2s 4ms/step - loss: 0.0069 - accuracy: 0.7906 - val_loss: 0.0096 - val_accuracy: 0.5923\n",
      "Epoch 12/100\n",
      "421/421 [==============================] - 2s 4ms/step - loss: 0.0067 - accuracy: 0.7576 - val_loss: 0.0095 - val_accuracy: 0.6736\n",
      "Epoch 13/100\n",
      "421/421 [==============================] - 2s 4ms/step - loss: 0.0064 - accuracy: 0.7949 - val_loss: 0.0096 - val_accuracy: 0.8331\n",
      "Epoch 14/100\n",
      "421/421 [==============================] - 1s 4ms/step - loss: 0.0062 - accuracy: 0.8129 - val_loss: 0.0095 - val_accuracy: 0.6478\n",
      "Epoch 15/100\n",
      "421/421 [==============================] - 2s 4ms/step - loss: 0.0060 - accuracy: 0.7719 - val_loss: 0.0094 - val_accuracy: 0.8308\n",
      "Epoch 16/100\n",
      "421/421 [==============================] - 2s 4ms/step - loss: 0.0058 - accuracy: 0.8015 - val_loss: 0.0096 - val_accuracy: 0.8813\n",
      "Epoch 17/100\n",
      "421/421 [==============================] - 2s 4ms/step - loss: 0.0056 - accuracy: 0.8229 - val_loss: 0.0096 - val_accuracy: 0.9344\n",
      "Epoch 18/100\n",
      "421/421 [==============================] - 2s 4ms/step - loss: 0.0054 - accuracy: 0.8044 - val_loss: 0.0096 - val_accuracy: 0.7980\n",
      "Epoch 19/100\n",
      "421/421 [==============================] - 2s 4ms/step - loss: 0.0052 - accuracy: 0.8102 - val_loss: 0.0097 - val_accuracy: 0.7114\n",
      "Epoch 20/100\n",
      "421/421 [==============================] - 2s 4ms/step - loss: 0.0050 - accuracy: 0.7892 - val_loss: 0.0097 - val_accuracy: 0.8308\n",
      "Epoch 21/100\n",
      "421/421 [==============================] - 2s 4ms/step - loss: 0.0048 - accuracy: 0.8066 - val_loss: 0.0098 - val_accuracy: 0.8411\n",
      "Epoch 22/100\n",
      "421/421 [==============================] - 2s 4ms/step - loss: 0.0046 - accuracy: 0.8238 - val_loss: 0.0099 - val_accuracy: 0.8147\n",
      "Epoch 23/100\n",
      "421/421 [==============================] - 2s 4ms/step - loss: 0.0044 - accuracy: 0.8195 - val_loss: 0.0100 - val_accuracy: 0.8097\n",
      "Epoch 24/100\n",
      "421/421 [==============================] - 2s 4ms/step - loss: 0.0042 - accuracy: 0.8352 - val_loss: 0.0100 - val_accuracy: 0.8127\n",
      "Epoch 25/100\n",
      "421/421 [==============================] - 2s 4ms/step - loss: 0.0040 - accuracy: 0.8166 - val_loss: 0.0103 - val_accuracy: 0.8528\n",
      "Epoch 26/100\n",
      "421/421 [==============================] - 2s 4ms/step - loss: 0.0038 - accuracy: 0.8586 - val_loss: 0.0104 - val_accuracy: 0.8284\n",
      "Epoch 27/100\n",
      "421/421 [==============================] - 2s 4ms/step - loss: 0.0035 - accuracy: 0.8486 - val_loss: 0.0105 - val_accuracy: 0.8261\n",
      "Epoch 28/100\n",
      "421/421 [==============================] - 2s 4ms/step - loss: 0.0033 - accuracy: 0.8619 - val_loss: 0.0107 - val_accuracy: 0.8231\n",
      "Epoch 29/100\n",
      "421/421 [==============================] - 2s 4ms/step - loss: 0.0031 - accuracy: 0.8515 - val_loss: 0.0109 - val_accuracy: 0.8361\n",
      "Epoch 30/100\n",
      "421/421 [==============================] - 2s 4ms/step - loss: 0.0029 - accuracy: 0.8473 - val_loss: 0.0111 - val_accuracy: 0.8057\n",
      "Epoch 31/100\n",
      "421/421 [==============================] - 2s 4ms/step - loss: 0.0027 - accuracy: 0.8491 - val_loss: 0.0113 - val_accuracy: 0.8311\n",
      "Epoch 32/100\n",
      "421/421 [==============================] - 2s 4ms/step - loss: 0.0025 - accuracy: 0.8541 - val_loss: 0.0116 - val_accuracy: 0.7970\n",
      "Epoch 33/100\n",
      "421/421 [==============================] - 2s 4ms/step - loss: 0.0023 - accuracy: 0.8379 - val_loss: 0.0116 - val_accuracy: 0.8435\n",
      "Epoch 34/100\n",
      "421/421 [==============================] - 2s 4ms/step - loss: 0.0021 - accuracy: 0.8421 - val_loss: 0.0120 - val_accuracy: 0.8505\n",
      "Epoch 35/100\n",
      "421/421 [==============================] - 2s 4ms/step - loss: 0.0019 - accuracy: 0.8399 - val_loss: 0.0122 - val_accuracy: 0.8251\n",
      "Epoch 36/100\n",
      "421/421 [==============================] - 2s 4ms/step - loss: 0.0017 - accuracy: 0.8258 - val_loss: 0.0125 - val_accuracy: 0.7936\n",
      "Epoch 37/100\n",
      "421/421 [==============================] - 2s 4ms/step - loss: 0.0015 - accuracy: 0.8220 - val_loss: 0.0127 - val_accuracy: 0.8304\n",
      "Epoch 38/100\n",
      "421/421 [==============================] - 2s 4ms/step - loss: 0.0014 - accuracy: 0.8119 - val_loss: 0.0131 - val_accuracy: 0.7739\n",
      "Epoch 39/100\n",
      "421/421 [==============================] - 2s 4ms/step - loss: 0.0012 - accuracy: 0.8048 - val_loss: 0.0134 - val_accuracy: 0.8017\n",
      "Epoch 40/100\n",
      "421/421 [==============================] - 2s 4ms/step - loss: 0.0011 - accuracy: 0.7959 - val_loss: 0.0137 - val_accuracy: 0.7793\n",
      "Epoch 41/100\n",
      "421/421 [==============================] - 2s 4ms/step - loss: 9.5686e-04 - accuracy: 0.8083 - val_loss: 0.0142 - val_accuracy: 0.7773\n",
      "Epoch 42/100\n",
      "421/421 [==============================] - 2s 4ms/step - loss: 8.5499e-04 - accuracy: 0.7876 - val_loss: 0.0144 - val_accuracy: 0.7612\n",
      "Epoch 43/100\n",
      "421/421 [==============================] - 2s 4ms/step - loss: 7.4257e-04 - accuracy: 0.7840 - val_loss: 0.0146 - val_accuracy: 0.7846\n",
      "Epoch 44/100\n",
      "421/421 [==============================] - 2s 4ms/step - loss: 6.4903e-04 - accuracy: 0.7781 - val_loss: 0.0151 - val_accuracy: 0.7816\n",
      "Epoch 45/100\n",
      "421/421 [==============================] - 2s 4ms/step - loss: 5.6720e-04 - accuracy: 0.7672 - val_loss: 0.0153 - val_accuracy: 0.7609\n",
      "Epoch 46/100\n",
      "421/421 [==============================] - 2s 4ms/step - loss: 4.9785e-04 - accuracy: 0.7585 - val_loss: 0.0157 - val_accuracy: 0.7599\n",
      "Epoch 47/100\n",
      "421/421 [==============================] - 2s 4ms/step - loss: 4.2623e-04 - accuracy: 0.7508 - val_loss: 0.0162 - val_accuracy: 0.7619\n",
      "Epoch 48/100\n",
      "421/421 [==============================] - 2s 4ms/step - loss: 3.6194e-04 - accuracy: 0.7501 - val_loss: 0.0166 - val_accuracy: 0.7555\n",
      "Epoch 49/100\n",
      "421/421 [==============================] - 2s 4ms/step - loss: 3.1446e-04 - accuracy: 0.7450 - val_loss: 0.0171 - val_accuracy: 0.7258\n",
      "Epoch 50/100\n",
      "421/421 [==============================] - 2s 4ms/step - loss: 2.7626e-04 - accuracy: 0.7374 - val_loss: 0.0174 - val_accuracy: 0.7124\n",
      "Epoch 51/100\n",
      "421/421 [==============================] - 2s 4ms/step - loss: 2.3240e-04 - accuracy: 0.7317 - val_loss: 0.0178 - val_accuracy: 0.7381\n",
      "Epoch 52/100\n",
      "421/421 [==============================] - 2s 4ms/step - loss: 2.0589e-04 - accuracy: 0.7320 - val_loss: 0.0182 - val_accuracy: 0.7047\n",
      "Epoch 53/100\n",
      "421/421 [==============================] - 2s 4ms/step - loss: 1.7850e-04 - accuracy: 0.7180 - val_loss: 0.0185 - val_accuracy: 0.6930\n",
      "Epoch 54/100\n",
      "421/421 [==============================] - 2s 4ms/step - loss: 1.5814e-04 - accuracy: 0.7157 - val_loss: 0.0190 - val_accuracy: 0.6900\n",
      "Epoch 55/100\n",
      "421/421 [==============================] - 2s 4ms/step - loss: 1.2659e-04 - accuracy: 0.7069 - val_loss: 0.0194 - val_accuracy: 0.6736\n",
      "Epoch 56/100\n",
      "421/421 [==============================] - 2s 4ms/step - loss: 1.2541e-04 - accuracy: 0.6970 - val_loss: 0.0196 - val_accuracy: 0.6799\n",
      "Epoch 57/100\n",
      "421/421 [==============================] - 2s 4ms/step - loss: 1.0811e-04 - accuracy: 0.7019 - val_loss: 0.0200 - val_accuracy: 0.6625\n",
      "Epoch 58/100\n",
      "421/421 [==============================] - 2s 4ms/step - loss: 8.6345e-05 - accuracy: 0.6841 - val_loss: 0.0203 - val_accuracy: 0.6602\n",
      "Epoch 59/100\n",
      "421/421 [==============================] - 2s 4ms/step - loss: 8.4948e-05 - accuracy: 0.6845 - val_loss: 0.0208 - val_accuracy: 0.6585\n",
      "Epoch 60/100\n",
      "421/421 [==============================] - 2s 4ms/step - loss: 7.1545e-05 - accuracy: 0.6800 - val_loss: 0.0212 - val_accuracy: 0.6712\n",
      "Epoch 61/100\n",
      "421/421 [==============================] - 2s 4ms/step - loss: 6.5388e-05 - accuracy: 0.6715 - val_loss: 0.0216 - val_accuracy: 0.6863\n",
      "Epoch 62/100\n",
      "421/421 [==============================] - 2s 4ms/step - loss: 5.2444e-05 - accuracy: 0.6799 - val_loss: 0.0217 - val_accuracy: 0.6609\n",
      "Epoch 63/100\n",
      "421/421 [==============================] - 2s 4ms/step - loss: 5.4838e-05 - accuracy: 0.6689 - val_loss: 0.0222 - val_accuracy: 0.6498\n",
      "Epoch 64/100\n",
      "421/421 [==============================] - 2s 4ms/step - loss: 5.2125e-05 - accuracy: 0.6568 - val_loss: 0.0226 - val_accuracy: 0.6522\n",
      "Epoch 65/100\n",
      "421/421 [==============================] - 2s 4ms/step - loss: 5.0116e-05 - accuracy: 0.6628 - val_loss: 0.0228 - val_accuracy: 0.6318\n",
      "Epoch 66/100\n",
      "421/421 [==============================] - 2s 4ms/step - loss: 4.7800e-05 - accuracy: 0.6458 - val_loss: 0.0232 - val_accuracy: 0.6314\n",
      "Epoch 67/100\n",
      "421/421 [==============================] - 2s 4ms/step - loss: 3.1303e-05 - accuracy: 0.6451 - val_loss: 0.0233 - val_accuracy: 0.6184\n",
      "Epoch 68/100\n",
      "421/421 [==============================] - 2s 4ms/step - loss: 3.3983e-05 - accuracy: 0.6444 - val_loss: 0.0238 - val_accuracy: 0.6324\n",
      "Epoch 69/100\n",
      "421/421 [==============================] - 2s 4ms/step - loss: 2.9318e-05 - accuracy: 0.6446 - val_loss: 0.0243 - val_accuracy: 0.6181\n",
      "Epoch 70/100\n",
      "421/421 [==============================] - 2s 4ms/step - loss: 4.0876e-05 - accuracy: 0.6281 - val_loss: 0.0241 - val_accuracy: 0.6067\n",
      "Epoch 71/100\n",
      "421/421 [==============================] - 2s 4ms/step - loss: 3.3418e-05 - accuracy: 0.6157 - val_loss: 0.0243 - val_accuracy: 0.6224\n",
      "Epoch 72/100\n",
      "421/421 [==============================] - 2s 4ms/step - loss: 2.5995e-05 - accuracy: 0.6291 - val_loss: 0.0247 - val_accuracy: 0.6100\n",
      "Epoch 73/100\n",
      "421/421 [==============================] - 2s 4ms/step - loss: 2.4883e-05 - accuracy: 0.6223 - val_loss: 0.0250 - val_accuracy: 0.6181\n",
      "Epoch 74/100\n",
      "421/421 [==============================] - 2s 4ms/step - loss: 2.6497e-05 - accuracy: 0.6217 - val_loss: 0.0253 - val_accuracy: 0.5990\n",
      "Epoch 75/100\n",
      "421/421 [==============================] - 2s 4ms/step - loss: 2.2699e-05 - accuracy: 0.6096 - val_loss: 0.0254 - val_accuracy: 0.6080\n",
      "Epoch 76/100\n",
      "421/421 [==============================] - 2s 4ms/step - loss: 2.4304e-05 - accuracy: 0.6158 - val_loss: 0.0257 - val_accuracy: 0.5983\n",
      "Epoch 77/100\n",
      "421/421 [==============================] - 2s 4ms/step - loss: 2.7746e-05 - accuracy: 0.6069 - val_loss: 0.0260 - val_accuracy: 0.5916\n",
      "Epoch 78/100\n",
      "421/421 [==============================] - 2s 4ms/step - loss: 2.4144e-05 - accuracy: 0.6020 - val_loss: 0.0263 - val_accuracy: 0.5903\n",
      "Epoch 79/100\n",
      "421/421 [==============================] - 2s 4ms/step - loss: 1.8820e-05 - accuracy: 0.6014 - val_loss: 0.0264 - val_accuracy: 0.5880\n",
      "Epoch 80/100\n",
      "421/421 [==============================] - 2s 4ms/step - loss: 2.3953e-05 - accuracy: 0.5970 - val_loss: 0.0264 - val_accuracy: 0.5843\n",
      "Epoch 81/100\n",
      "421/421 [==============================] - 2s 4ms/step - loss: 1.9963e-05 - accuracy: 0.5907 - val_loss: 0.0267 - val_accuracy: 0.5763\n",
      "Epoch 82/100\n",
      "421/421 [==============================] - 2s 4ms/step - loss: 1.6492e-05 - accuracy: 0.5890 - val_loss: 0.0269 - val_accuracy: 0.5833\n",
      "Epoch 83/100\n",
      "421/421 [==============================] - 2s 4ms/step - loss: 1.6059e-05 - accuracy: 0.5901 - val_loss: 0.0270 - val_accuracy: 0.5749\n",
      "Epoch 84/100\n",
      "421/421 [==============================] - 2s 4ms/step - loss: 1.6868e-05 - accuracy: 0.5851 - val_loss: 0.0272 - val_accuracy: 0.5575\n",
      "Epoch 85/100\n",
      "421/421 [==============================] - 2s 4ms/step - loss: 1.4454e-05 - accuracy: 0.5810 - val_loss: 0.0274 - val_accuracy: 0.5602\n",
      "Epoch 86/100\n",
      "421/421 [==============================] - 2s 4ms/step - loss: 1.6483e-05 - accuracy: 0.5738 - val_loss: 0.0275 - val_accuracy: 0.5548\n",
      "Epoch 87/100\n",
      "421/421 [==============================] - 2s 4ms/step - loss: 1.4504e-05 - accuracy: 0.5736 - val_loss: 0.0277 - val_accuracy: 0.5565\n",
      "Epoch 88/100\n",
      "421/421 [==============================] - 2s 4ms/step - loss: 9.8324e-06 - accuracy: 0.5683 - val_loss: 0.0278 - val_accuracy: 0.5662\n",
      "Epoch 89/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "421/421 [==============================] - 2s 4ms/step - loss: 1.4086e-05 - accuracy: 0.5733 - val_loss: 0.0281 - val_accuracy: 0.5532\n",
      "Epoch 90/100\n",
      "421/421 [==============================] - 2s 4ms/step - loss: 1.1648e-05 - accuracy: 0.5667 - val_loss: 0.0282 - val_accuracy: 0.5532\n",
      "Epoch 91/100\n",
      "421/421 [==============================] - 2s 4ms/step - loss: 1.2523e-05 - accuracy: 0.5635 - val_loss: 0.0283 - val_accuracy: 0.5455\n",
      "Epoch 92/100\n",
      "421/421 [==============================] - 2s 4ms/step - loss: 1.3196e-05 - accuracy: 0.5616 - val_loss: 0.0287 - val_accuracy: 0.5615\n",
      "Epoch 93/100\n",
      "421/421 [==============================] - 2s 4ms/step - loss: 1.2553e-05 - accuracy: 0.5570 - val_loss: 0.0286 - val_accuracy: 0.5488\n",
      "Epoch 94/100\n",
      "421/421 [==============================] - 2s 4ms/step - loss: 1.1328e-05 - accuracy: 0.5577 - val_loss: 0.0285 - val_accuracy: 0.5344\n",
      "Epoch 95/100\n",
      "421/421 [==============================] - 2s 4ms/step - loss: 9.2740e-06 - accuracy: 0.5526 - val_loss: 0.0288 - val_accuracy: 0.5495\n",
      "Epoch 96/100\n",
      "421/421 [==============================] - 2s 4ms/step - loss: 1.0090e-05 - accuracy: 0.5503 - val_loss: 0.0289 - val_accuracy: 0.5452\n",
      "Epoch 97/100\n",
      "421/421 [==============================] - 2s 4ms/step - loss: 1.2650e-05 - accuracy: 0.5491 - val_loss: 0.0290 - val_accuracy: 0.5388\n",
      "Epoch 98/100\n",
      "421/421 [==============================] - 2s 4ms/step - loss: 1.2343e-05 - accuracy: 0.5426 - val_loss: 0.0292 - val_accuracy: 0.5338\n",
      "Epoch 99/100\n",
      "421/421 [==============================] - 2s 4ms/step - loss: 9.0100e-06 - accuracy: 0.5429 - val_loss: 0.0292 - val_accuracy: 0.5271\n",
      "Epoch 100/100\n",
      "421/421 [==============================] - 2s 4ms/step - loss: 8.8979e-06 - accuracy: 0.5427 - val_loss: 0.0296 - val_accuracy: 0.5415\n",
      "Score for fold 4 : loss of 0.029565371572971344 ; F1-Macro: 0.6488101120309002 F1-Micro: 0.9383881595122191\n",
      "Training...\n",
      "Epoch 1/100\n",
      "421/421 [==============================] - 2s 4ms/step - loss: 0.0587 - accuracy: 0.6181 - val_loss: 0.0203 - val_accuracy: 0.9796\n",
      "Epoch 2/100\n",
      "421/421 [==============================] - 2s 4ms/step - loss: 0.0165 - accuracy: 0.9807 - val_loss: 0.0136 - val_accuracy: 0.9411\n",
      "Epoch 3/100\n",
      "421/421 [==============================] - 2s 4ms/step - loss: 0.0125 - accuracy: 0.9199 - val_loss: 0.0113 - val_accuracy: 0.9338\n",
      "Epoch 4/100\n",
      "421/421 [==============================] - 2s 4ms/step - loss: 0.0107 - accuracy: 0.7383 - val_loss: 0.0102 - val_accuracy: 0.9532\n",
      "Epoch 5/100\n",
      "421/421 [==============================] - 2s 4ms/step - loss: 0.0097 - accuracy: 0.6712 - val_loss: 0.0094 - val_accuracy: 0.2823\n",
      "Epoch 6/100\n",
      "421/421 [==============================] - 2s 4ms/step - loss: 0.0090 - accuracy: 0.5063 - val_loss: 0.0090 - val_accuracy: 0.6308\n",
      "Epoch 7/100\n",
      "421/421 [==============================] - 2s 4ms/step - loss: 0.0084 - accuracy: 0.6169 - val_loss: 0.0088 - val_accuracy: 0.7518\n",
      "Epoch 8/100\n",
      "421/421 [==============================] - 2s 4ms/step - loss: 0.0080 - accuracy: 0.6176 - val_loss: 0.0086 - val_accuracy: 0.2926\n",
      "Epoch 9/100\n",
      "421/421 [==============================] - 2s 4ms/step - loss: 0.0076 - accuracy: 0.5286 - val_loss: 0.0083 - val_accuracy: 0.5395\n",
      "Epoch 10/100\n",
      "421/421 [==============================] - 2s 4ms/step - loss: 0.0073 - accuracy: 0.5920 - val_loss: 0.0083 - val_accuracy: 0.5709\n",
      "Epoch 11/100\n",
      "421/421 [==============================] - 2s 4ms/step - loss: 0.0070 - accuracy: 0.5933 - val_loss: 0.0082 - val_accuracy: 0.7164\n",
      "Epoch 12/100\n",
      "421/421 [==============================] - 2s 4ms/step - loss: 0.0068 - accuracy: 0.7070 - val_loss: 0.0081 - val_accuracy: 0.6569\n",
      "Epoch 13/100\n",
      "421/421 [==============================] - 2s 4ms/step - loss: 0.0065 - accuracy: 0.6706 - val_loss: 0.0079 - val_accuracy: 0.6241\n",
      "Epoch 14/100\n",
      "421/421 [==============================] - 2s 4ms/step - loss: 0.0063 - accuracy: 0.6941 - val_loss: 0.0080 - val_accuracy: 0.5328\n",
      "Epoch 15/100\n",
      "421/421 [==============================] - 2s 5ms/step - loss: 0.0061 - accuracy: 0.6592 - val_loss: 0.0080 - val_accuracy: 0.6094\n",
      "Epoch 16/100\n",
      "421/421 [==============================] - 2s 5ms/step - loss: 0.0059 - accuracy: 0.6683 - val_loss: 0.0079 - val_accuracy: 0.9308\n",
      "Epoch 17/100\n",
      "421/421 [==============================] - 2s 5ms/step - loss: 0.0057 - accuracy: 0.8522 - val_loss: 0.0081 - val_accuracy: 0.7090\n",
      "Epoch 18/100\n",
      "421/421 [==============================] - 2s 5ms/step - loss: 0.0055 - accuracy: 0.7458 - val_loss: 0.0079 - val_accuracy: 0.7237\n",
      "Epoch 19/100\n",
      "421/421 [==============================] - 2s 5ms/step - loss: 0.0053 - accuracy: 0.8270 - val_loss: 0.0081 - val_accuracy: 0.7659\n",
      "Epoch 20/100\n",
      "421/421 [==============================] - 2s 4ms/step - loss: 0.0051 - accuracy: 0.7615 - val_loss: 0.0080 - val_accuracy: 0.7987\n",
      "Epoch 21/100\n",
      "421/421 [==============================] - 2s 4ms/step - loss: 0.0049 - accuracy: 0.8151 - val_loss: 0.0082 - val_accuracy: 0.8679\n",
      "Epoch 22/100\n",
      "421/421 [==============================] - 2s 5ms/step - loss: 0.0047 - accuracy: 0.8380 - val_loss: 0.0081 - val_accuracy: 0.9368\n",
      "Epoch 23/100\n",
      "421/421 [==============================] - 2s 5ms/step - loss: 0.0045 - accuracy: 0.8546 - val_loss: 0.0083 - val_accuracy: 0.7492\n",
      "Epoch 24/100\n",
      "421/421 [==============================] - 2s 5ms/step - loss: 0.0042 - accuracy: 0.8341 - val_loss: 0.0083 - val_accuracy: 0.8816\n",
      "Epoch 25/100\n",
      "421/421 [==============================] - 2s 5ms/step - loss: 0.0040 - accuracy: 0.8625 - val_loss: 0.0083 - val_accuracy: 0.9040\n",
      "Epoch 26/100\n",
      "421/421 [==============================] - 2s 5ms/step - loss: 0.0038 - accuracy: 0.8694 - val_loss: 0.0084 - val_accuracy: 0.7987\n",
      "Epoch 27/100\n",
      "421/421 [==============================] - 2s 5ms/step - loss: 0.0036 - accuracy: 0.8828 - val_loss: 0.0085 - val_accuracy: 0.9408\n",
      "Epoch 28/100\n",
      "421/421 [==============================] - 2s 5ms/step - loss: 0.0034 - accuracy: 0.8767 - val_loss: 0.0087 - val_accuracy: 0.9134\n",
      "Epoch 29/100\n",
      "421/421 [==============================] - 2s 5ms/step - loss: 0.0032 - accuracy: 0.8839 - val_loss: 0.0087 - val_accuracy: 0.8602\n",
      "Epoch 30/100\n",
      "421/421 [==============================] - 2s 5ms/step - loss: 0.0030 - accuracy: 0.8759 - val_loss: 0.0089 - val_accuracy: 0.8763\n",
      "Epoch 31/100\n",
      "421/421 [==============================] - 2s 5ms/step - loss: 0.0028 - accuracy: 0.8762 - val_loss: 0.0091 - val_accuracy: 0.8883\n",
      "Epoch 32/100\n",
      "421/421 [==============================] - 2s 5ms/step - loss: 0.0025 - accuracy: 0.8723 - val_loss: 0.0092 - val_accuracy: 0.8866\n",
      "Epoch 33/100\n",
      "421/421 [==============================] - 2s 5ms/step - loss: 0.0024 - accuracy: 0.8709 - val_loss: 0.0094 - val_accuracy: 0.8525\n",
      "Epoch 34/100\n",
      "421/421 [==============================] - 2s 5ms/step - loss: 0.0022 - accuracy: 0.8710 - val_loss: 0.0096 - val_accuracy: 0.8559\n",
      "Epoch 35/100\n",
      "421/421 [==============================] - 2s 5ms/step - loss: 0.0020 - accuracy: 0.8620 - val_loss: 0.0098 - val_accuracy: 0.8401\n",
      "Epoch 36/100\n",
      "421/421 [==============================] - 2s 5ms/step - loss: 0.0018 - accuracy: 0.8559 - val_loss: 0.0100 - val_accuracy: 0.8669\n",
      "Epoch 37/100\n",
      "421/421 [==============================] - 2s 5ms/step - loss: 0.0016 - accuracy: 0.8529 - val_loss: 0.0100 - val_accuracy: 0.8676\n",
      "Epoch 38/100\n",
      "421/421 [==============================] - 2s 5ms/step - loss: 0.0014 - accuracy: 0.8454 - val_loss: 0.0104 - val_accuracy: 0.8565\n",
      "Epoch 39/100\n",
      "421/421 [==============================] - 2s 5ms/step - loss: 0.0013 - accuracy: 0.8440 - val_loss: 0.0105 - val_accuracy: 0.8274\n",
      "Epoch 40/100\n",
      "421/421 [==============================] - 2s 5ms/step - loss: 0.0011 - accuracy: 0.8345 - val_loss: 0.0108 - val_accuracy: 0.8338\n",
      "Epoch 41/100\n",
      "421/421 [==============================] - 2s 5ms/step - loss: 0.0010 - accuracy: 0.8332 - val_loss: 0.0112 - val_accuracy: 0.7960\n",
      "Epoch 42/100\n",
      "421/421 [==============================] - 2s 5ms/step - loss: 9.1200e-04 - accuracy: 0.8194 - val_loss: 0.0113 - val_accuracy: 0.8321\n",
      "Epoch 43/100\n",
      "421/421 [==============================] - 2s 5ms/step - loss: 7.9552e-04 - accuracy: 0.8169 - val_loss: 0.0116 - val_accuracy: 0.7712\n",
      "Epoch 44/100\n",
      "421/421 [==============================] - 2s 5ms/step - loss: 6.9499e-04 - accuracy: 0.8096 - val_loss: 0.0120 - val_accuracy: 0.7833\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 45/100\n",
      "421/421 [==============================] - 2s 5ms/step - loss: 6.0576e-04 - accuracy: 0.7961 - val_loss: 0.0123 - val_accuracy: 0.7729\n",
      "Epoch 46/100\n",
      "421/421 [==============================] - 2s 5ms/step - loss: 5.2606e-04 - accuracy: 0.7926 - val_loss: 0.0125 - val_accuracy: 0.7870\n",
      "Epoch 47/100\n",
      "421/421 [==============================] - 2s 5ms/step - loss: 4.5704e-04 - accuracy: 0.7886 - val_loss: 0.0129 - val_accuracy: 0.7746\n",
      "Epoch 48/100\n",
      "421/421 [==============================] - 2s 5ms/step - loss: 3.9778e-04 - accuracy: 0.7867 - val_loss: 0.0131 - val_accuracy: 0.7635\n",
      "Epoch 49/100\n",
      "421/421 [==============================] - 2s 5ms/step - loss: 3.5980e-04 - accuracy: 0.7673 - val_loss: 0.0135 - val_accuracy: 0.7559\n",
      "Epoch 50/100\n",
      "421/421 [==============================] - 2s 5ms/step - loss: 3.0098e-04 - accuracy: 0.7671 - val_loss: 0.0136 - val_accuracy: 0.7609\n",
      "Epoch 51/100\n",
      "421/421 [==============================] - 2s 5ms/step - loss: 2.7440e-04 - accuracy: 0.7503 - val_loss: 0.0140 - val_accuracy: 0.7676\n",
      "Epoch 52/100\n",
      "421/421 [==============================] - 2s 5ms/step - loss: 2.3481e-04 - accuracy: 0.7512 - val_loss: 0.0144 - val_accuracy: 0.7555\n",
      "Epoch 53/100\n",
      "421/421 [==============================] - 2s 5ms/step - loss: 2.0549e-04 - accuracy: 0.7414 - val_loss: 0.0145 - val_accuracy: 0.7512\n",
      "Epoch 54/100\n",
      "421/421 [==============================] - 2s 5ms/step - loss: 1.9437e-04 - accuracy: 0.7370 - val_loss: 0.0148 - val_accuracy: 0.7217\n",
      "Epoch 55/100\n",
      "421/421 [==============================] - 2s 5ms/step - loss: 1.6949e-04 - accuracy: 0.7300 - val_loss: 0.0154 - val_accuracy: 0.7114\n",
      "Epoch 56/100\n",
      "421/421 [==============================] - 2s 5ms/step - loss: 1.3221e-04 - accuracy: 0.7106 - val_loss: 0.0156 - val_accuracy: 0.7177\n",
      "Epoch 57/100\n",
      "421/421 [==============================] - 2s 5ms/step - loss: 1.5203e-04 - accuracy: 0.7146 - val_loss: 0.0158 - val_accuracy: 0.6960\n",
      "Epoch 58/100\n",
      "421/421 [==============================] - 2s 5ms/step - loss: 1.1580e-04 - accuracy: 0.6928 - val_loss: 0.0162 - val_accuracy: 0.6625\n",
      "Epoch 59/100\n",
      "421/421 [==============================] - 2s 5ms/step - loss: 1.0395e-04 - accuracy: 0.6924 - val_loss: 0.0163 - val_accuracy: 0.6973\n",
      "Epoch 60/100\n",
      "421/421 [==============================] - 2s 5ms/step - loss: 9.2283e-05 - accuracy: 0.6942 - val_loss: 0.0166 - val_accuracy: 0.6642\n",
      "Epoch 61/100\n",
      "421/421 [==============================] - 2s 5ms/step - loss: 9.8682e-05 - accuracy: 0.6761 - val_loss: 0.0168 - val_accuracy: 0.6575\n",
      "Epoch 62/100\n",
      "421/421 [==============================] - 2s 5ms/step - loss: 6.8849e-05 - accuracy: 0.6685 - val_loss: 0.0173 - val_accuracy: 0.6502\n",
      "Epoch 63/100\n",
      "421/421 [==============================] - 2s 5ms/step - loss: 7.0771e-05 - accuracy: 0.6602 - val_loss: 0.0175 - val_accuracy: 0.6542\n",
      "Epoch 64/100\n",
      "421/421 [==============================] - 2s 5ms/step - loss: 7.6110e-05 - accuracy: 0.6505 - val_loss: 0.0178 - val_accuracy: 0.6602\n",
      "Epoch 65/100\n",
      "421/421 [==============================] - 2s 5ms/step - loss: 7.4054e-05 - accuracy: 0.6553 - val_loss: 0.0180 - val_accuracy: 0.6371\n",
      "Epoch 66/100\n",
      "421/421 [==============================] - 2s 5ms/step - loss: 7.1112e-05 - accuracy: 0.6451 - val_loss: 0.0182 - val_accuracy: 0.6134\n",
      "Epoch 67/100\n",
      "421/421 [==============================] - 2s 5ms/step - loss: 5.0115e-05 - accuracy: 0.6302 - val_loss: 0.0184 - val_accuracy: 0.6197\n",
      "Epoch 68/100\n",
      "421/421 [==============================] - 2s 5ms/step - loss: 5.3622e-05 - accuracy: 0.6285 - val_loss: 0.0187 - val_accuracy: 0.6130\n",
      "Epoch 69/100\n",
      "421/421 [==============================] - 2s 5ms/step - loss: 4.5600e-05 - accuracy: 0.6231 - val_loss: 0.0189 - val_accuracy: 0.6054\n",
      "Epoch 70/100\n",
      "421/421 [==============================] - 2s 5ms/step - loss: 4.6289e-05 - accuracy: 0.6142 - val_loss: 0.0190 - val_accuracy: 0.6151\n",
      "Epoch 71/100\n",
      "421/421 [==============================] - 2s 5ms/step - loss: 4.3145e-05 - accuracy: 0.6174 - val_loss: 0.0203 - val_accuracy: 0.5967\n",
      "Epoch 72/100\n",
      "421/421 [==============================] - 2s 5ms/step - loss: 1.1177e-04 - accuracy: 0.5875 - val_loss: 0.0194 - val_accuracy: 0.5967\n",
      "Epoch 73/100\n",
      "421/421 [==============================] - 2s 5ms/step - loss: 4.0450e-05 - accuracy: 0.5968 - val_loss: 0.0197 - val_accuracy: 0.5930\n",
      "Epoch 74/100\n",
      "421/421 [==============================] - 2s 5ms/step - loss: 4.3235e-05 - accuracy: 0.5975 - val_loss: 0.0199 - val_accuracy: 0.5873\n",
      "Epoch 75/100\n",
      "421/421 [==============================] - 2s 5ms/step - loss: 4.3810e-05 - accuracy: 0.5876 - val_loss: 0.0198 - val_accuracy: 0.5799\n",
      "Epoch 76/100\n",
      "421/421 [==============================] - 2s 5ms/step - loss: 4.2226e-05 - accuracy: 0.5913 - val_loss: 0.0201 - val_accuracy: 0.5692\n",
      "Epoch 77/100\n",
      "421/421 [==============================] - 2s 5ms/step - loss: 4.1282e-05 - accuracy: 0.5788 - val_loss: 0.0203 - val_accuracy: 0.5605\n",
      "Epoch 78/100\n",
      "421/421 [==============================] - 2s 5ms/step - loss: 3.8776e-05 - accuracy: 0.5767 - val_loss: 0.0205 - val_accuracy: 0.5592\n",
      "Epoch 79/100\n",
      "421/421 [==============================] - 2s 5ms/step - loss: 3.1003e-05 - accuracy: 0.5718 - val_loss: 0.0204 - val_accuracy: 0.5719\n",
      "Epoch 80/100\n",
      "421/421 [==============================] - 2s 5ms/step - loss: 3.3278e-05 - accuracy: 0.5742 - val_loss: 0.0208 - val_accuracy: 0.5676\n",
      "Epoch 81/100\n",
      "421/421 [==============================] - 2s 5ms/step - loss: 3.9949e-05 - accuracy: 0.5711 - val_loss: 0.0207 - val_accuracy: 0.5522\n",
      "Epoch 82/100\n",
      "421/421 [==============================] - 2s 5ms/step - loss: 3.2182e-05 - accuracy: 0.5656 - val_loss: 0.0210 - val_accuracy: 0.5702\n",
      "Epoch 83/100\n",
      "421/421 [==============================] - 2s 5ms/step - loss: 2.8687e-05 - accuracy: 0.5625 - val_loss: 0.0211 - val_accuracy: 0.5251\n",
      "Epoch 84/100\n",
      "421/421 [==============================] - 2s 5ms/step - loss: 2.4589e-05 - accuracy: 0.5526 - val_loss: 0.0214 - val_accuracy: 0.5525\n",
      "Epoch 85/100\n",
      "421/421 [==============================] - 2s 5ms/step - loss: 2.4656e-05 - accuracy: 0.5637 - val_loss: 0.0215 - val_accuracy: 0.5482\n",
      "Epoch 86/100\n",
      "421/421 [==============================] - 2s 6ms/step - loss: 3.0093e-05 - accuracy: 0.5492 - val_loss: 0.0216 - val_accuracy: 0.5542\n",
      "Epoch 87/100\n",
      "421/421 [==============================] - 2s 5ms/step - loss: 2.7890e-05 - accuracy: 0.5477 - val_loss: 0.0219 - val_accuracy: 0.5318\n",
      "Epoch 88/100\n",
      "421/421 [==============================] - 2s 5ms/step - loss: 2.2821e-05 - accuracy: 0.5466 - val_loss: 0.0218 - val_accuracy: 0.5528\n",
      "Epoch 89/100\n",
      "421/421 [==============================] - 2s 5ms/step - loss: 2.8632e-05 - accuracy: 0.5501 - val_loss: 0.0220 - val_accuracy: 0.5207\n",
      "Epoch 90/100\n",
      "421/421 [==============================] - 2s 5ms/step - loss: 2.1517e-05 - accuracy: 0.5386 - val_loss: 0.0221 - val_accuracy: 0.5344\n",
      "Epoch 91/100\n",
      "421/421 [==============================] - 2s 5ms/step - loss: 3.1230e-05 - accuracy: 0.5397 - val_loss: 0.0221 - val_accuracy: 0.5207\n",
      "Epoch 92/100\n",
      "421/421 [==============================] - 2s 5ms/step - loss: 2.4985e-05 - accuracy: 0.5362 - val_loss: 0.0222 - val_accuracy: 0.5271\n",
      "Epoch 93/100\n",
      "421/421 [==============================] - 2s 5ms/step - loss: 1.7847e-05 - accuracy: 0.5365 - val_loss: 0.0225 - val_accuracy: 0.5147\n",
      "Epoch 94/100\n",
      "421/421 [==============================] - 2s 5ms/step - loss: 2.6184e-05 - accuracy: 0.5234 - val_loss: 0.0227 - val_accuracy: 0.5234\n",
      "Epoch 95/100\n",
      "421/421 [==============================] - 2s 5ms/step - loss: 2.2758e-05 - accuracy: 0.5313 - val_loss: 0.0228 - val_accuracy: 0.5308\n",
      "Epoch 96/100\n",
      "421/421 [==============================] - 2s 5ms/step - loss: 2.0970e-05 - accuracy: 0.5334 - val_loss: 0.0226 - val_accuracy: 0.5077\n",
      "Epoch 97/100\n",
      "421/421 [==============================] - 2s 5ms/step - loss: 1.8318e-05 - accuracy: 0.5217 - val_loss: 0.0228 - val_accuracy: 0.5177\n",
      "Epoch 98/100\n",
      "421/421 [==============================] - 2s 5ms/step - loss: 2.1067e-05 - accuracy: 0.5225 - val_loss: 0.0229 - val_accuracy: 0.5171\n",
      "Epoch 99/100\n",
      "421/421 [==============================] - 2s 5ms/step - loss: 2.4018e-05 - accuracy: 0.5207 - val_loss: 0.0229 - val_accuracy: 0.5037\n",
      "Epoch 100/100\n",
      "421/421 [==============================] - 2s 5ms/step - loss: 1.9342e-05 - accuracy: 0.5159 - val_loss: 0.0231 - val_accuracy: 0.5064\n",
      "Score for fold 5 : loss of 0.023142701014876366 ; F1-Macro: 0.7529009094387104 F1-Micro: 0.9405389428050643\n",
      "Training...\n",
      "Epoch 1/100\n",
      "421/421 [==============================] - 3s 5ms/step - loss: 0.0590 - accuracy: 0.5867 - val_loss: 0.0210 - val_accuracy: 0.9967\n",
      "Epoch 2/100\n",
      "421/421 [==============================] - 2s 5ms/step - loss: 0.0168 - accuracy: 0.9930 - val_loss: 0.0145 - val_accuracy: 0.9926\n",
      "Epoch 3/100\n",
      "421/421 [==============================] - 2s 5ms/step - loss: 0.0125 - accuracy: 0.8034 - val_loss: 0.0121 - val_accuracy: 0.3368\n",
      "Epoch 4/100\n",
      "421/421 [==============================] - 2s 5ms/step - loss: 0.0107 - accuracy: 0.7192 - val_loss: 0.0109 - val_accuracy: 0.9769\n",
      "Epoch 5/100\n",
      "421/421 [==============================] - 2s 5ms/step - loss: 0.0096 - accuracy: 0.6594 - val_loss: 0.0102 - val_accuracy: 0.2689\n",
      "Epoch 6/100\n",
      "421/421 [==============================] - 2s 5ms/step - loss: 0.0089 - accuracy: 0.4875 - val_loss: 0.0099 - val_accuracy: 0.4294\n",
      "Epoch 7/100\n",
      "421/421 [==============================] - 2s 5ms/step - loss: 0.0083 - accuracy: 0.4962 - val_loss: 0.0096 - val_accuracy: 0.6528\n",
      "Epoch 8/100\n",
      "421/421 [==============================] - 2s 5ms/step - loss: 0.0079 - accuracy: 0.5137 - val_loss: 0.0093 - val_accuracy: 0.2007\n",
      "Epoch 9/100\n",
      "421/421 [==============================] - 2s 5ms/step - loss: 0.0075 - accuracy: 0.3544 - val_loss: 0.0092 - val_accuracy: 0.7221\n",
      "Epoch 10/100\n",
      "421/421 [==============================] - 2s 5ms/step - loss: 0.0072 - accuracy: 0.6018 - val_loss: 0.0091 - val_accuracy: 0.4070\n",
      "Epoch 11/100\n",
      "421/421 [==============================] - 2s 5ms/step - loss: 0.0069 - accuracy: 0.5773 - val_loss: 0.0089 - val_accuracy: 0.7629\n",
      "Epoch 12/100\n",
      "421/421 [==============================] - 2s 5ms/step - loss: 0.0067 - accuracy: 0.7098 - val_loss: 0.0087 - val_accuracy: 0.5666\n",
      "Epoch 13/100\n",
      "421/421 [==============================] - 2s 5ms/step - loss: 0.0065 - accuracy: 0.6760 - val_loss: 0.0088 - val_accuracy: 0.4719\n",
      "Epoch 14/100\n",
      "421/421 [==============================] - 2s 5ms/step - loss: 0.0062 - accuracy: 0.6894 - val_loss: 0.0088 - val_accuracy: 0.5973\n",
      "Epoch 15/100\n",
      "421/421 [==============================] - 2s 5ms/step - loss: 0.0060 - accuracy: 0.7408 - val_loss: 0.0088 - val_accuracy: 0.6676\n",
      "Epoch 16/100\n",
      "421/421 [==============================] - 2s 5ms/step - loss: 0.0058 - accuracy: 0.7561 - val_loss: 0.0089 - val_accuracy: 0.8803\n",
      "Epoch 17/100\n",
      "421/421 [==============================] - 2s 5ms/step - loss: 0.0056 - accuracy: 0.8314 - val_loss: 0.0087 - val_accuracy: 0.9067\n",
      "Epoch 18/100\n",
      "421/421 [==============================] - 2s 5ms/step - loss: 0.0054 - accuracy: 0.8212 - val_loss: 0.0088 - val_accuracy: 0.9241\n",
      "Epoch 19/100\n",
      "421/421 [==============================] - 2s 5ms/step - loss: 0.0052 - accuracy: 0.8629 - val_loss: 0.0089 - val_accuracy: 0.9334\n",
      "Epoch 20/100\n",
      "421/421 [==============================] - 2s 5ms/step - loss: 0.0050 - accuracy: 0.8365 - val_loss: 0.0090 - val_accuracy: 0.8625\n",
      "Epoch 21/100\n",
      "421/421 [==============================] - 2s 5ms/step - loss: 0.0048 - accuracy: 0.8771 - val_loss: 0.0089 - val_accuracy: 0.8378\n",
      "Epoch 22/100\n",
      "421/421 [==============================] - 2s 5ms/step - loss: 0.0046 - accuracy: 0.8720 - val_loss: 0.0090 - val_accuracy: 0.8171\n",
      "Epoch 23/100\n",
      "421/421 [==============================] - 2s 5ms/step - loss: 0.0044 - accuracy: 0.8820 - val_loss: 0.0092 - val_accuracy: 0.8776\n",
      "Epoch 24/100\n",
      "421/421 [==============================] - 2s 5ms/step - loss: 0.0042 - accuracy: 0.9132 - val_loss: 0.0091 - val_accuracy: 0.8987\n",
      "Epoch 25/100\n",
      "421/421 [==============================] - 2s 5ms/step - loss: 0.0040 - accuracy: 0.9165 - val_loss: 0.0093 - val_accuracy: 0.9127\n",
      "Epoch 26/100\n",
      "421/421 [==============================] - 2s 5ms/step - loss: 0.0037 - accuracy: 0.9162 - val_loss: 0.0096 - val_accuracy: 0.9421\n",
      "Epoch 27/100\n",
      "421/421 [==============================] - 2s 5ms/step - loss: 0.0035 - accuracy: 0.9351 - val_loss: 0.0097 - val_accuracy: 0.9344\n",
      "Epoch 28/100\n",
      "421/421 [==============================] - 2s 5ms/step - loss: 0.0033 - accuracy: 0.9259 - val_loss: 0.0097 - val_accuracy: 0.8980\n",
      "Epoch 29/100\n",
      "421/421 [==============================] - 2s 5ms/step - loss: 0.0031 - accuracy: 0.9281 - val_loss: 0.0098 - val_accuracy: 0.8983\n",
      "Epoch 30/100\n",
      "421/421 [==============================] - 2s 5ms/step - loss: 0.0029 - accuracy: 0.9229 - val_loss: 0.0099 - val_accuracy: 0.9458\n",
      "Epoch 31/100\n",
      "421/421 [==============================] - 2s 5ms/step - loss: 0.0027 - accuracy: 0.9269 - val_loss: 0.0103 - val_accuracy: 0.9010\n",
      "Epoch 32/100\n",
      "421/421 [==============================] - 2s 5ms/step - loss: 0.0025 - accuracy: 0.9067 - val_loss: 0.0104 - val_accuracy: 0.9528\n",
      "Epoch 33/100\n",
      "421/421 [==============================] - 2s 5ms/step - loss: 0.0023 - accuracy: 0.9114 - val_loss: 0.0105 - val_accuracy: 0.8890\n",
      "Epoch 34/100\n",
      "421/421 [==============================] - 2s 5ms/step - loss: 0.0021 - accuracy: 0.9036 - val_loss: 0.0108 - val_accuracy: 0.8639\n",
      "Epoch 35/100\n",
      "421/421 [==============================] - 2s 5ms/step - loss: 0.0019 - accuracy: 0.8913 - val_loss: 0.0110 - val_accuracy: 0.8823\n",
      "Epoch 36/100\n",
      "421/421 [==============================] - 2s 5ms/step - loss: 0.0017 - accuracy: 0.8815 - val_loss: 0.0113 - val_accuracy: 0.8896\n",
      "Epoch 37/100\n",
      "421/421 [==============================] - 2s 5ms/step - loss: 0.0016 - accuracy: 0.8779 - val_loss: 0.0117 - val_accuracy: 0.8488\n",
      "Epoch 38/100\n",
      "421/421 [==============================] - 2s 5ms/step - loss: 0.0014 - accuracy: 0.8625 - val_loss: 0.0118 - val_accuracy: 0.8579\n",
      "Epoch 39/100\n",
      "421/421 [==============================] - 2s 5ms/step - loss: 0.0013 - accuracy: 0.8647 - val_loss: 0.0120 - val_accuracy: 0.8428\n",
      "Epoch 40/100\n",
      "421/421 [==============================] - 2s 5ms/step - loss: 0.0011 - accuracy: 0.8528 - val_loss: 0.0123 - val_accuracy: 0.8334\n",
      "Epoch 41/100\n",
      "421/421 [==============================] - 2s 5ms/step - loss: 0.0010 - accuracy: 0.8491 - val_loss: 0.0126 - val_accuracy: 0.8080\n",
      "Epoch 42/100\n",
      "421/421 [==============================] - 2s 5ms/step - loss: 8.7280e-04 - accuracy: 0.8265 - val_loss: 0.0130 - val_accuracy: 0.8411\n",
      "Epoch 43/100\n",
      "421/421 [==============================] - 2s 5ms/step - loss: 7.6511e-04 - accuracy: 0.8127 - val_loss: 0.0133 - val_accuracy: 0.8171\n",
      "Epoch 44/100\n",
      "421/421 [==============================] - 2s 5ms/step - loss: 6.6479e-04 - accuracy: 0.8112 - val_loss: 0.0135 - val_accuracy: 0.7739\n",
      "Epoch 45/100\n",
      "421/421 [==============================] - 2s 5ms/step - loss: 5.8879e-04 - accuracy: 0.7951 - val_loss: 0.0139 - val_accuracy: 0.7880\n",
      "Epoch 46/100\n",
      "421/421 [==============================] - 2s 5ms/step - loss: 5.0839e-04 - accuracy: 0.7819 - val_loss: 0.0143 - val_accuracy: 0.7532\n",
      "Epoch 47/100\n",
      "421/421 [==============================] - 2s 5ms/step - loss: 4.6206e-04 - accuracy: 0.7740 - val_loss: 0.0146 - val_accuracy: 0.7923\n",
      "Epoch 48/100\n",
      "421/421 [==============================] - 2s 5ms/step - loss: 3.9455e-04 - accuracy: 0.7692 - val_loss: 0.0147 - val_accuracy: 0.7411\n",
      "Epoch 49/100\n",
      "421/421 [==============================] - 2s 5ms/step - loss: 3.5149e-04 - accuracy: 0.7400 - val_loss: 0.0151 - val_accuracy: 0.7569\n",
      "Epoch 50/100\n",
      "421/421 [==============================] - 2s 5ms/step - loss: 3.0193e-04 - accuracy: 0.7272 - val_loss: 0.0156 - val_accuracy: 0.7498\n",
      "Epoch 51/100\n",
      "421/421 [==============================] - 2s 5ms/step - loss: 2.5453e-04 - accuracy: 0.7113 - val_loss: 0.0158 - val_accuracy: 0.7064\n",
      "Epoch 52/100\n",
      "421/421 [==============================] - 2s 5ms/step - loss: 2.2710e-04 - accuracy: 0.7077 - val_loss: 0.0163 - val_accuracy: 0.7007\n",
      "Epoch 53/100\n",
      "421/421 [==============================] - 2s 5ms/step - loss: 1.9485e-04 - accuracy: 0.6974 - val_loss: 0.0166 - val_accuracy: 0.7107\n",
      "Epoch 54/100\n",
      "421/421 [==============================] - 2s 5ms/step - loss: 1.7679e-04 - accuracy: 0.6867 - val_loss: 0.0169 - val_accuracy: 0.6816\n",
      "Epoch 55/100\n",
      "421/421 [==============================] - 2s 5ms/step - loss: 1.5359e-04 - accuracy: 0.6793 - val_loss: 0.0175 - val_accuracy: 0.6789\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 56/100\n",
      "421/421 [==============================] - 2s 5ms/step - loss: 1.5542e-04 - accuracy: 0.6596 - val_loss: 0.0176 - val_accuracy: 0.6609\n",
      "Epoch 57/100\n",
      "421/421 [==============================] - 2s 5ms/step - loss: 1.2664e-04 - accuracy: 0.6525 - val_loss: 0.0180 - val_accuracy: 0.6742\n",
      "Epoch 58/100\n",
      "421/421 [==============================] - 2s 5ms/step - loss: 1.1569e-04 - accuracy: 0.6463 - val_loss: 0.0185 - val_accuracy: 0.6498\n",
      "Epoch 59/100\n",
      "421/421 [==============================] - 2s 5ms/step - loss: 1.0698e-04 - accuracy: 0.6369 - val_loss: 0.0184 - val_accuracy: 0.6261\n",
      "Epoch 60/100\n",
      "421/421 [==============================] - 2s 5ms/step - loss: 8.6069e-05 - accuracy: 0.6226 - val_loss: 0.0192 - val_accuracy: 0.6281\n",
      "Epoch 61/100\n",
      "421/421 [==============================] - 2s 5ms/step - loss: 9.3397e-05 - accuracy: 0.6186 - val_loss: 0.0192 - val_accuracy: 0.6060\n",
      "Epoch 62/100\n",
      "421/421 [==============================] - 2s 5ms/step - loss: 8.7428e-05 - accuracy: 0.5988 - val_loss: 0.0194 - val_accuracy: 0.6134\n",
      "Epoch 63/100\n",
      "421/421 [==============================] - 2s 5ms/step - loss: 7.7231e-05 - accuracy: 0.5996 - val_loss: 0.0197 - val_accuracy: 0.5933\n",
      "Epoch 64/100\n",
      "421/421 [==============================] - 2s 5ms/step - loss: 7.6106e-05 - accuracy: 0.5872 - val_loss: 0.0199 - val_accuracy: 0.5886\n",
      "Epoch 65/100\n",
      "421/421 [==============================] - 2s 5ms/step - loss: 4.8738e-05 - accuracy: 0.5785 - val_loss: 0.0203 - val_accuracy: 0.5977\n",
      "Epoch 66/100\n",
      "421/421 [==============================] - 2s 5ms/step - loss: 5.3817e-05 - accuracy: 0.5691 - val_loss: 0.0208 - val_accuracy: 0.5943\n",
      "Epoch 67/100\n",
      "421/421 [==============================] - 2s 5ms/step - loss: 6.1743e-05 - accuracy: 0.5691 - val_loss: 0.0209 - val_accuracy: 0.5679\n",
      "Epoch 68/100\n",
      "421/421 [==============================] - 2s 5ms/step - loss: 5.6289e-05 - accuracy: 0.5589 - val_loss: 0.0211 - val_accuracy: 0.5649\n",
      "Epoch 69/100\n",
      "421/421 [==============================] - 2s 5ms/step - loss: 5.6224e-05 - accuracy: 0.5524 - val_loss: 0.0213 - val_accuracy: 0.5582\n",
      "Epoch 70/100\n",
      "421/421 [==============================] - 2s 5ms/step - loss: 5.1249e-05 - accuracy: 0.5387 - val_loss: 0.0217 - val_accuracy: 0.5508\n",
      "Epoch 71/100\n",
      "421/421 [==============================] - 2s 5ms/step - loss: 9.2004e-05 - accuracy: 0.5241 - val_loss: 0.0214 - val_accuracy: 0.5294\n",
      "Epoch 72/100\n",
      "421/421 [==============================] - 2s 5ms/step - loss: 4.2892e-05 - accuracy: 0.5172 - val_loss: 0.0216 - val_accuracy: 0.5258\n",
      "Epoch 73/100\n",
      "421/421 [==============================] - 2s 5ms/step - loss: 4.2101e-05 - accuracy: 0.5127 - val_loss: 0.0219 - val_accuracy: 0.5244\n",
      "Epoch 74/100\n",
      "421/421 [==============================] - 2s 5ms/step - loss: 4.1078e-05 - accuracy: 0.5057 - val_loss: 0.0221 - val_accuracy: 0.5074\n",
      "Epoch 75/100\n",
      "421/421 [==============================] - 2s 5ms/step - loss: 3.9495e-05 - accuracy: 0.5134 - val_loss: 0.0223 - val_accuracy: 0.5070\n",
      "Epoch 76/100\n",
      "421/421 [==============================] - 2s 5ms/step - loss: 2.2775e-05 - accuracy: 0.4982 - val_loss: 0.0224 - val_accuracy: 0.5197\n",
      "Epoch 77/100\n",
      "421/421 [==============================] - 2s 5ms/step - loss: 3.4365e-05 - accuracy: 0.4989 - val_loss: 0.0228 - val_accuracy: 0.5154\n",
      "Epoch 78/100\n",
      "421/421 [==============================] - 2s 5ms/step - loss: 3.9291e-05 - accuracy: 0.4884 - val_loss: 0.0229 - val_accuracy: 0.5080\n",
      "Epoch 79/100\n",
      "421/421 [==============================] - 2s 5ms/step - loss: 3.1198e-05 - accuracy: 0.4921 - val_loss: 0.0231 - val_accuracy: 0.4913\n",
      "Epoch 80/100\n",
      "421/421 [==============================] - 2s 5ms/step - loss: 2.3954e-05 - accuracy: 0.4770 - val_loss: 0.0231 - val_accuracy: 0.5043\n",
      "Epoch 81/100\n",
      "421/421 [==============================] - 2s 5ms/step - loss: 2.2795e-05 - accuracy: 0.4829 - val_loss: 0.0237 - val_accuracy: 0.4870\n",
      "Epoch 82/100\n",
      "421/421 [==============================] - 2s 5ms/step - loss: 2.8571e-05 - accuracy: 0.4765 - val_loss: 0.0234 - val_accuracy: 0.4753\n",
      "Epoch 83/100\n",
      "421/421 [==============================] - 2s 5ms/step - loss: 2.4496e-05 - accuracy: 0.4760 - val_loss: 0.0238 - val_accuracy: 0.4759\n",
      "Epoch 84/100\n",
      "421/421 [==============================] - 2s 5ms/step - loss: 2.4320e-05 - accuracy: 0.4695 - val_loss: 0.0239 - val_accuracy: 0.4823\n",
      "Epoch 85/100\n",
      "421/421 [==============================] - 2s 5ms/step - loss: 1.9466e-05 - accuracy: 0.4621 - val_loss: 0.0243 - val_accuracy: 0.4773\n",
      "Epoch 86/100\n",
      "421/421 [==============================] - 2s 5ms/step - loss: 2.8806e-05 - accuracy: 0.4626 - val_loss: 0.0243 - val_accuracy: 0.4829\n",
      "Epoch 87/100\n",
      "421/421 [==============================] - 2s 5ms/step - loss: 1.9734e-05 - accuracy: 0.4582 - val_loss: 0.0244 - val_accuracy: 0.4676\n",
      "Epoch 88/100\n",
      "421/421 [==============================] - 2s 5ms/step - loss: 2.0403e-05 - accuracy: 0.4591 - val_loss: 0.0247 - val_accuracy: 0.4829\n",
      "Epoch 89/100\n",
      "421/421 [==============================] - 2s 5ms/step - loss: 2.1470e-05 - accuracy: 0.4551 - val_loss: 0.0247 - val_accuracy: 0.4579\n",
      "Epoch 90/100\n",
      "421/421 [==============================] - 2s 5ms/step - loss: 1.8897e-05 - accuracy: 0.4478 - val_loss: 0.0249 - val_accuracy: 0.4696\n",
      "Epoch 91/100\n",
      "421/421 [==============================] - 2s 5ms/step - loss: 1.9369e-05 - accuracy: 0.4545 - val_loss: 0.0249 - val_accuracy: 0.4505\n",
      "Epoch 92/100\n",
      "421/421 [==============================] - 2s 5ms/step - loss: 1.4871e-05 - accuracy: 0.4527 - val_loss: 0.0253 - val_accuracy: 0.4538\n",
      "Epoch 93/100\n",
      "421/421 [==============================] - 2s 5ms/step - loss: 1.8198e-05 - accuracy: 0.4398 - val_loss: 0.0254 - val_accuracy: 0.4572\n",
      "Epoch 94/100\n",
      "421/421 [==============================] - 2s 5ms/step - loss: 2.0812e-05 - accuracy: 0.4384 - val_loss: 0.0253 - val_accuracy: 0.4548\n",
      "Epoch 95/100\n",
      "421/421 [==============================] - 2s 5ms/step - loss: 1.7263e-05 - accuracy: 0.4344 - val_loss: 0.0254 - val_accuracy: 0.4462\n",
      "Epoch 96/100\n",
      "421/421 [==============================] - 2s 5ms/step - loss: 1.6384e-05 - accuracy: 0.4358 - val_loss: 0.0256 - val_accuracy: 0.4398\n",
      "Epoch 97/100\n",
      "421/421 [==============================] - 2s 5ms/step - loss: 1.8922e-05 - accuracy: 0.4307 - val_loss: 0.0256 - val_accuracy: 0.4401\n",
      "Epoch 98/100\n",
      "421/421 [==============================] - 2s 5ms/step - loss: 1.4135e-05 - accuracy: 0.4289 - val_loss: 0.0258 - val_accuracy: 0.4401\n",
      "Epoch 99/100\n",
      "421/421 [==============================] - 2s 5ms/step - loss: 1.2721e-05 - accuracy: 0.4294 - val_loss: 0.0259 - val_accuracy: 0.4515\n",
      "Epoch 100/100\n",
      "421/421 [==============================] - 2s 5ms/step - loss: 1.2899e-05 - accuracy: 0.4339 - val_loss: 0.0259 - val_accuracy: 0.4344\n",
      "Score for fold 6 : loss of 0.02592935413122177 ; F1-Macro: 0.7121186862735349 F1-Micro: 0.9395953183892085\n",
      "Training...\n",
      "Epoch 1/100\n",
      "421/421 [==============================] - 2s 5ms/step - loss: 0.0590 - accuracy: 0.7970 - val_loss: 0.0207 - val_accuracy: 0.9880\n",
      "Epoch 2/100\n",
      "421/421 [==============================] - 2s 5ms/step - loss: 0.0166 - accuracy: 0.9851 - val_loss: 0.0142 - val_accuracy: 0.9468\n",
      "Epoch 3/100\n",
      "421/421 [==============================] - 2s 5ms/step - loss: 0.0125 - accuracy: 0.9108 - val_loss: 0.0118 - val_accuracy: 0.9505\n",
      "Epoch 4/100\n",
      "421/421 [==============================] - 2s 4ms/step - loss: 0.0107 - accuracy: 0.7377 - val_loss: 0.0105 - val_accuracy: 0.7278\n",
      "Epoch 5/100\n",
      "421/421 [==============================] - 2s 5ms/step - loss: 0.0097 - accuracy: 0.7152 - val_loss: 0.0099 - val_accuracy: 0.3545\n",
      "Epoch 6/100\n",
      "421/421 [==============================] - 2s 5ms/step - loss: 0.0089 - accuracy: 0.6472 - val_loss: 0.0094 - val_accuracy: 0.5435\n",
      "Epoch 7/100\n",
      "421/421 [==============================] - 2s 4ms/step - loss: 0.0084 - accuracy: 0.5508 - val_loss: 0.0090 - val_accuracy: 0.5602\n",
      "Epoch 8/100\n",
      "421/421 [==============================] - 2s 4ms/step - loss: 0.0079 - accuracy: 0.5899 - val_loss: 0.0088 - val_accuracy: 0.4482\n",
      "Epoch 9/100\n",
      "421/421 [==============================] - 2s 4ms/step - loss: 0.0076 - accuracy: 0.6146 - val_loss: 0.0086 - val_accuracy: 0.8796\n",
      "Epoch 10/100\n",
      "421/421 [==============================] - 2s 5ms/step - loss: 0.0073 - accuracy: 0.6240 - val_loss: 0.0085 - val_accuracy: 0.8010\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/100\n",
      "421/421 [==============================] - 2s 5ms/step - loss: 0.0070 - accuracy: 0.6275 - val_loss: 0.0084 - val_accuracy: 0.6191\n",
      "Epoch 12/100\n",
      "421/421 [==============================] - 2s 5ms/step - loss: 0.0067 - accuracy: 0.6949 - val_loss: 0.0084 - val_accuracy: 0.4555\n",
      "Epoch 13/100\n",
      "421/421 [==============================] - 2s 5ms/step - loss: 0.0065 - accuracy: 0.7281 - val_loss: 0.0083 - val_accuracy: 0.5247\n",
      "Epoch 14/100\n",
      "421/421 [==============================] - 2s 5ms/step - loss: 0.0062 - accuracy: 0.7230 - val_loss: 0.0084 - val_accuracy: 0.7411\n",
      "Epoch 15/100\n",
      "421/421 [==============================] - 2s 5ms/step - loss: 0.0060 - accuracy: 0.7073 - val_loss: 0.0084 - val_accuracy: 0.8809\n",
      "Epoch 16/100\n",
      "421/421 [==============================] - 2s 5ms/step - loss: 0.0058 - accuracy: 0.8186 - val_loss: 0.0083 - val_accuracy: 0.5990\n",
      "Epoch 17/100\n",
      "421/421 [==============================] - 2s 5ms/step - loss: 0.0056 - accuracy: 0.7509 - val_loss: 0.0083 - val_accuracy: 0.7712\n",
      "Epoch 18/100\n",
      "421/421 [==============================] - 2s 5ms/step - loss: 0.0054 - accuracy: 0.7731 - val_loss: 0.0084 - val_accuracy: 0.8532\n",
      "Epoch 19/100\n",
      "421/421 [==============================] - 2s 5ms/step - loss: 0.0052 - accuracy: 0.8607 - val_loss: 0.0084 - val_accuracy: 0.7666\n",
      "Epoch 20/100\n",
      "421/421 [==============================] - 2s 5ms/step - loss: 0.0050 - accuracy: 0.8137 - val_loss: 0.0086 - val_accuracy: 0.7288\n",
      "Epoch 21/100\n",
      "421/421 [==============================] - 2s 5ms/step - loss: 0.0048 - accuracy: 0.8190 - val_loss: 0.0087 - val_accuracy: 0.8194\n",
      "Epoch 22/100\n",
      "421/421 [==============================] - 2s 5ms/step - loss: 0.0046 - accuracy: 0.8674 - val_loss: 0.0090 - val_accuracy: 0.8870\n",
      "Epoch 23/100\n",
      "421/421 [==============================] - 2s 5ms/step - loss: 0.0044 - accuracy: 0.8962 - val_loss: 0.0088 - val_accuracy: 0.8565\n",
      "Epoch 24/100\n",
      "421/421 [==============================] - 2s 5ms/step - loss: 0.0042 - accuracy: 0.8774 - val_loss: 0.0090 - val_accuracy: 0.8806\n",
      "Epoch 25/100\n",
      "421/421 [==============================] - 2s 5ms/step - loss: 0.0040 - accuracy: 0.8901 - val_loss: 0.0091 - val_accuracy: 0.9247\n",
      "Epoch 26/100\n",
      "421/421 [==============================] - 2s 5ms/step - loss: 0.0038 - accuracy: 0.9045 - val_loss: 0.0093 - val_accuracy: 0.9120\n",
      "Epoch 27/100\n",
      "421/421 [==============================] - 2s 5ms/step - loss: 0.0036 - accuracy: 0.9189 - val_loss: 0.0092 - val_accuracy: 0.8910\n",
      "Epoch 28/100\n",
      "421/421 [==============================] - 2s 5ms/step - loss: 0.0034 - accuracy: 0.9163 - val_loss: 0.0095 - val_accuracy: 0.9405\n",
      "Epoch 29/100\n",
      "421/421 [==============================] - 2s 5ms/step - loss: 0.0032 - accuracy: 0.9259 - val_loss: 0.0096 - val_accuracy: 0.9438\n",
      "Epoch 30/100\n",
      "421/421 [==============================] - 2s 5ms/step - loss: 0.0029 - accuracy: 0.9206 - val_loss: 0.0098 - val_accuracy: 0.8950\n",
      "Epoch 31/100\n",
      "421/421 [==============================] - 2s 5ms/step - loss: 0.0027 - accuracy: 0.9161 - val_loss: 0.0099 - val_accuracy: 0.8983\n",
      "Epoch 32/100\n",
      "421/421 [==============================] - 2s 5ms/step - loss: 0.0025 - accuracy: 0.9133 - val_loss: 0.0101 - val_accuracy: 0.8967\n",
      "Epoch 33/100\n",
      "421/421 [==============================] - 2s 5ms/step - loss: 0.0023 - accuracy: 0.9156 - val_loss: 0.0103 - val_accuracy: 0.9157\n",
      "Epoch 34/100\n",
      "421/421 [==============================] - 2s 5ms/step - loss: 0.0021 - accuracy: 0.9114 - val_loss: 0.0105 - val_accuracy: 0.8555\n",
      "Epoch 35/100\n",
      "421/421 [==============================] - 2s 5ms/step - loss: 0.0019 - accuracy: 0.8861 - val_loss: 0.0108 - val_accuracy: 0.9067\n",
      "Epoch 36/100\n",
      "421/421 [==============================] - 2s 5ms/step - loss: 0.0018 - accuracy: 0.8945 - val_loss: 0.0110 - val_accuracy: 0.8736\n",
      "Epoch 37/100\n",
      "421/421 [==============================] - 2s 5ms/step - loss: 0.0016 - accuracy: 0.8780 - val_loss: 0.0112 - val_accuracy: 0.8749\n",
      "Epoch 38/100\n",
      "421/421 [==============================] - 2s 5ms/step - loss: 0.0014 - accuracy: 0.8788 - val_loss: 0.0115 - val_accuracy: 0.8873\n",
      "Epoch 39/100\n",
      "421/421 [==============================] - 2s 5ms/step - loss: 0.0013 - accuracy: 0.8723 - val_loss: 0.0119 - val_accuracy: 0.8659\n",
      "Epoch 40/100\n",
      "421/421 [==============================] - 2s 5ms/step - loss: 0.0011 - accuracy: 0.8696 - val_loss: 0.0120 - val_accuracy: 0.8321\n",
      "Epoch 41/100\n",
      "421/421 [==============================] - 2s 5ms/step - loss: 0.0010 - accuracy: 0.8537 - val_loss: 0.0125 - val_accuracy: 0.8401\n",
      "Epoch 42/100\n",
      "421/421 [==============================] - 2s 5ms/step - loss: 8.8893e-04 - accuracy: 0.8510 - val_loss: 0.0127 - val_accuracy: 0.8485\n",
      "Epoch 43/100\n",
      "421/421 [==============================] - 2s 5ms/step - loss: 7.7659e-04 - accuracy: 0.8438 - val_loss: 0.0131 - val_accuracy: 0.8472\n",
      "Epoch 44/100\n",
      "421/421 [==============================] - 2s 5ms/step - loss: 6.8352e-04 - accuracy: 0.8346 - val_loss: 0.0134 - val_accuracy: 0.8214\n",
      "Epoch 45/100\n",
      "421/421 [==============================] - 2s 4ms/step - loss: 6.0210e-04 - accuracy: 0.8305 - val_loss: 0.0138 - val_accuracy: 0.7829\n",
      "Epoch 46/100\n",
      "421/421 [==============================] - 2s 4ms/step - loss: 5.3156e-04 - accuracy: 0.8129 - val_loss: 0.0140 - val_accuracy: 0.8157\n",
      "Epoch 47/100\n",
      "421/421 [==============================] - 2s 4ms/step - loss: 4.5996e-04 - accuracy: 0.8124 - val_loss: 0.0142 - val_accuracy: 0.7833\n",
      "Epoch 48/100\n",
      "421/421 [==============================] - 2s 4ms/step - loss: 3.9184e-04 - accuracy: 0.8057 - val_loss: 0.0146 - val_accuracy: 0.8003\n",
      "Epoch 49/100\n",
      "421/421 [==============================] - 2s 4ms/step - loss: 3.4452e-04 - accuracy: 0.7937 - val_loss: 0.0150 - val_accuracy: 0.8033\n",
      "Epoch 50/100\n",
      "421/421 [==============================] - 2s 4ms/step - loss: 2.9612e-04 - accuracy: 0.7934 - val_loss: 0.0155 - val_accuracy: 0.7866\n",
      "Epoch 51/100\n",
      "421/421 [==============================] - 2s 4ms/step - loss: 2.6770e-04 - accuracy: 0.7947 - val_loss: 0.0156 - val_accuracy: 0.7709\n",
      "Epoch 52/100\n",
      "421/421 [==============================] - 2s 4ms/step - loss: 2.3331e-04 - accuracy: 0.7689 - val_loss: 0.0160 - val_accuracy: 0.7709\n",
      "Epoch 53/100\n",
      "421/421 [==============================] - 2s 4ms/step - loss: 2.0896e-04 - accuracy: 0.7570 - val_loss: 0.0167 - val_accuracy: 0.7686\n",
      "Epoch 54/100\n",
      "421/421 [==============================] - 2s 4ms/step - loss: 1.7709e-04 - accuracy: 0.7724 - val_loss: 0.0166 - val_accuracy: 0.7398\n",
      "Epoch 55/100\n",
      "421/421 [==============================] - 2s 4ms/step - loss: 1.6718e-04 - accuracy: 0.7410 - val_loss: 0.0170 - val_accuracy: 0.7809\n",
      "Epoch 56/100\n",
      "421/421 [==============================] - 2s 4ms/step - loss: 1.3676e-04 - accuracy: 0.7475 - val_loss: 0.0177 - val_accuracy: 0.7431\n",
      "Epoch 57/100\n",
      "421/421 [==============================] - 2s 4ms/step - loss: 1.4911e-04 - accuracy: 0.7344 - val_loss: 0.0179 - val_accuracy: 0.7000\n",
      "Epoch 58/100\n",
      "421/421 [==============================] - 2s 4ms/step - loss: 1.2266e-04 - accuracy: 0.7150 - val_loss: 0.0180 - val_accuracy: 0.7328\n",
      "Epoch 59/100\n",
      "421/421 [==============================] - 2s 5ms/step - loss: 9.6938e-05 - accuracy: 0.7187 - val_loss: 0.0185 - val_accuracy: 0.6926\n",
      "Epoch 60/100\n",
      "421/421 [==============================] - 2s 5ms/step - loss: 1.0143e-04 - accuracy: 0.7077 - val_loss: 0.0187 - val_accuracy: 0.6990\n",
      "Epoch 61/100\n",
      "421/421 [==============================] - 2s 5ms/step - loss: 9.0905e-05 - accuracy: 0.7010 - val_loss: 0.0190 - val_accuracy: 0.6849\n",
      "Epoch 62/100\n",
      "421/421 [==============================] - 2s 5ms/step - loss: 7.7972e-05 - accuracy: 0.6915 - val_loss: 0.0192 - val_accuracy: 0.6846\n",
      "Epoch 63/100\n",
      "421/421 [==============================] - 2s 5ms/step - loss: 8.2023e-05 - accuracy: 0.6879 - val_loss: 0.0196 - val_accuracy: 0.6719\n",
      "Epoch 64/100\n",
      "421/421 [==============================] - 2s 4ms/step - loss: 7.5355e-05 - accuracy: 0.6723 - val_loss: 0.0197 - val_accuracy: 0.6860\n",
      "Epoch 65/100\n",
      "421/421 [==============================] - 2s 4ms/step - loss: 6.0402e-05 - accuracy: 0.6779 - val_loss: 0.0199 - val_accuracy: 0.6722\n",
      "Epoch 66/100\n",
      "421/421 [==============================] - 2s 4ms/step - loss: 6.8689e-05 - accuracy: 0.6718 - val_loss: 0.0203 - val_accuracy: 0.6659\n",
      "Epoch 67/100\n",
      "421/421 [==============================] - 2s 5ms/step - loss: 4.9753e-05 - accuracy: 0.6554 - val_loss: 0.0206 - val_accuracy: 0.6833\n",
      "Epoch 68/100\n",
      "421/421 [==============================] - 2s 5ms/step - loss: 7.2463e-05 - accuracy: 0.6552 - val_loss: 0.0209 - val_accuracy: 0.6351\n",
      "Epoch 69/100\n",
      "421/421 [==============================] - 2s 5ms/step - loss: 5.1573e-05 - accuracy: 0.6489 - val_loss: 0.0211 - val_accuracy: 0.6666\n",
      "Epoch 70/100\n",
      "421/421 [==============================] - 2s 5ms/step - loss: 5.2436e-05 - accuracy: 0.6457 - val_loss: 0.0214 - val_accuracy: 0.6448\n",
      "Epoch 71/100\n",
      "421/421 [==============================] - 2s 5ms/step - loss: 4.7844e-05 - accuracy: 0.6368 - val_loss: 0.0216 - val_accuracy: 0.6388\n",
      "Epoch 72/100\n",
      "421/421 [==============================] - 2s 5ms/step - loss: 4.9801e-05 - accuracy: 0.6252 - val_loss: 0.0219 - val_accuracy: 0.6057\n",
      "Epoch 73/100\n",
      "421/421 [==============================] - 2s 5ms/step - loss: 4.4518e-05 - accuracy: 0.6260 - val_loss: 0.0223 - val_accuracy: 0.6207\n",
      "Epoch 74/100\n",
      "421/421 [==============================] - 2s 5ms/step - loss: 3.5621e-05 - accuracy: 0.6154 - val_loss: 0.0220 - val_accuracy: 0.6314\n",
      "Epoch 75/100\n",
      "421/421 [==============================] - 2s 5ms/step - loss: 4.9107e-05 - accuracy: 0.6097 - val_loss: 0.0222 - val_accuracy: 0.5886\n",
      "Epoch 76/100\n",
      "421/421 [==============================] - 2s 4ms/step - loss: 3.2270e-05 - accuracy: 0.5995 - val_loss: 0.0225 - val_accuracy: 0.6120\n",
      "Epoch 77/100\n",
      "421/421 [==============================] - 2s 4ms/step - loss: 4.8336e-05 - accuracy: 0.6004 - val_loss: 0.0229 - val_accuracy: 0.6070\n",
      "Epoch 78/100\n",
      "421/421 [==============================] - 2s 4ms/step - loss: 4.2342e-05 - accuracy: 0.5951 - val_loss: 0.0229 - val_accuracy: 0.5769\n",
      "Epoch 79/100\n",
      "421/421 [==============================] - 2s 4ms/step - loss: 3.1860e-05 - accuracy: 0.5805 - val_loss: 0.0230 - val_accuracy: 0.5930\n",
      "Epoch 80/100\n",
      "421/421 [==============================] - 2s 4ms/step - loss: 3.8755e-05 - accuracy: 0.5823 - val_loss: 0.0232 - val_accuracy: 0.5716\n",
      "Epoch 81/100\n",
      "421/421 [==============================] - 2s 4ms/step - loss: 2.7280e-05 - accuracy: 0.5736 - val_loss: 0.0236 - val_accuracy: 0.5452\n",
      "Epoch 82/100\n",
      "421/421 [==============================] - 2s 5ms/step - loss: 3.2143e-05 - accuracy: 0.5718 - val_loss: 0.0238 - val_accuracy: 0.5696\n",
      "Epoch 83/100\n",
      "421/421 [==============================] - 2s 4ms/step - loss: 2.9218e-05 - accuracy: 0.5637 - val_loss: 0.0238 - val_accuracy: 0.5642\n",
      "Epoch 84/100\n",
      "421/421 [==============================] - 2s 4ms/step - loss: 3.3946e-05 - accuracy: 0.5562 - val_loss: 0.0237 - val_accuracy: 0.5716\n",
      "Epoch 85/100\n",
      "421/421 [==============================] - 2s 4ms/step - loss: 2.8630e-05 - accuracy: 0.5550 - val_loss: 0.0240 - val_accuracy: 0.5599\n",
      "Epoch 86/100\n",
      "421/421 [==============================] - 2s 4ms/step - loss: 2.2345e-05 - accuracy: 0.5522 - val_loss: 0.0244 - val_accuracy: 0.5401\n",
      "Epoch 87/100\n",
      "421/421 [==============================] - 2s 4ms/step - loss: 2.3143e-05 - accuracy: 0.5445 - val_loss: 0.0245 - val_accuracy: 0.5548\n",
      "Epoch 88/100\n",
      "421/421 [==============================] - 2s 5ms/step - loss: 2.8072e-05 - accuracy: 0.5402 - val_loss: 0.0246 - val_accuracy: 0.5207\n",
      "Epoch 89/100\n",
      "421/421 [==============================] - 2s 5ms/step - loss: 1.8010e-05 - accuracy: 0.5392 - val_loss: 0.0247 - val_accuracy: 0.5204\n",
      "Epoch 90/100\n",
      "421/421 [==============================] - 2s 5ms/step - loss: 2.4060e-05 - accuracy: 0.5303 - val_loss: 0.0246 - val_accuracy: 0.5294\n",
      "Epoch 91/100\n",
      "421/421 [==============================] - 2s 5ms/step - loss: 1.9073e-05 - accuracy: 0.5328 - val_loss: 0.0251 - val_accuracy: 0.5251\n",
      "Epoch 92/100\n",
      "421/421 [==============================] - 2s 5ms/step - loss: 2.4767e-05 - accuracy: 0.5235 - val_loss: 0.0252 - val_accuracy: 0.5254\n",
      "Epoch 93/100\n",
      "421/421 [==============================] - 2s 5ms/step - loss: 1.9824e-05 - accuracy: 0.5299 - val_loss: 0.0254 - val_accuracy: 0.5365\n",
      "Epoch 94/100\n",
      "421/421 [==============================] - 2s 5ms/step - loss: 2.1203e-05 - accuracy: 0.5212 - val_loss: 0.0254 - val_accuracy: 0.5308\n",
      "Epoch 95/100\n",
      "421/421 [==============================] - 2s 5ms/step - loss: 2.2475e-05 - accuracy: 0.5264 - val_loss: 0.0256 - val_accuracy: 0.5117\n",
      "Epoch 96/100\n",
      "421/421 [==============================] - 2s 5ms/step - loss: 2.0178e-05 - accuracy: 0.5127 - val_loss: 0.0256 - val_accuracy: 0.5107\n",
      "Epoch 97/100\n",
      "421/421 [==============================] - 2s 5ms/step - loss: 2.0112e-05 - accuracy: 0.5143 - val_loss: 0.0258 - val_accuracy: 0.5003\n",
      "Epoch 98/100\n",
      "421/421 [==============================] - 2s 5ms/step - loss: 1.5587e-05 - accuracy: 0.5143 - val_loss: 0.0258 - val_accuracy: 0.5264\n",
      "Epoch 99/100\n",
      "421/421 [==============================] - 2s 5ms/step - loss: 1.5533e-05 - accuracy: 0.5087 - val_loss: 0.0261 - val_accuracy: 0.5054\n",
      "Epoch 100/100\n",
      "421/421 [==============================] - 2s 5ms/step - loss: 2.2579e-05 - accuracy: 0.5149 - val_loss: 0.0260 - val_accuracy: 0.4963\n",
      "Score for fold 7 : loss of 0.02602919563651085 ; F1-Macro: 0.664264728990239 F1-Micro: 0.9414748147779821\n",
      "Training...\n",
      "Epoch 1/100\n",
      "421/421 [==============================] - 3s 5ms/step - loss: 0.0593 - accuracy: 0.9533 - val_loss: 0.0203 - val_accuracy: 0.9983\n",
      "Epoch 2/100\n",
      "421/421 [==============================] - 2s 5ms/step - loss: 0.0167 - accuracy: 0.9911 - val_loss: 0.0137 - val_accuracy: 0.9732\n",
      "Epoch 3/100\n",
      "421/421 [==============================] - 2s 5ms/step - loss: 0.0125 - accuracy: 0.9401 - val_loss: 0.0113 - val_accuracy: 0.8053\n",
      "Epoch 4/100\n",
      "421/421 [==============================] - 2s 5ms/step - loss: 0.0107 - accuracy: 0.7575 - val_loss: 0.0102 - val_accuracy: 0.3081\n",
      "Epoch 5/100\n",
      "421/421 [==============================] - 2s 5ms/step - loss: 0.0097 - accuracy: 0.6321 - val_loss: 0.0096 - val_accuracy: 0.9160\n",
      "Epoch 6/100\n",
      "421/421 [==============================] - 2s 5ms/step - loss: 0.0090 - accuracy: 0.5912 - val_loss: 0.0091 - val_accuracy: 0.9823\n",
      "Epoch 7/100\n",
      "421/421 [==============================] - 2s 5ms/step - loss: 0.0084 - accuracy: 0.6514 - val_loss: 0.0087 - val_accuracy: 0.5259\n",
      "Epoch 8/100\n",
      "421/421 [==============================] - 2s 5ms/step - loss: 0.0080 - accuracy: 0.5860 - val_loss: 0.0086 - val_accuracy: 0.3884\n",
      "Epoch 9/100\n",
      "421/421 [==============================] - 2s 5ms/step - loss: 0.0076 - accuracy: 0.6159 - val_loss: 0.0084 - val_accuracy: 0.9090\n",
      "Epoch 10/100\n",
      "421/421 [==============================] - 2s 5ms/step - loss: 0.0073 - accuracy: 0.7009 - val_loss: 0.0083 - val_accuracy: 0.9231\n",
      "Epoch 11/100\n",
      "421/421 [==============================] - 2s 5ms/step - loss: 0.0070 - accuracy: 0.7382 - val_loss: 0.0082 - val_accuracy: 0.5099\n",
      "Epoch 12/100\n",
      "421/421 [==============================] - 2s 5ms/step - loss: 0.0068 - accuracy: 0.6876 - val_loss: 0.0082 - val_accuracy: 0.7317\n",
      "Epoch 13/100\n",
      "421/421 [==============================] - 2s 5ms/step - loss: 0.0066 - accuracy: 0.8042 - val_loss: 0.0082 - val_accuracy: 0.6126\n",
      "Epoch 14/100\n",
      "421/421 [==============================] - 2s 5ms/step - loss: 0.0063 - accuracy: 0.7260 - val_loss: 0.0081 - val_accuracy: 0.8210\n",
      "Epoch 15/100\n",
      "421/421 [==============================] - 2s 5ms/step - loss: 0.0061 - accuracy: 0.7952 - val_loss: 0.0080 - val_accuracy: 0.7481\n",
      "Epoch 16/100\n",
      "421/421 [==============================] - 2s 5ms/step - loss: 0.0059 - accuracy: 0.7918 - val_loss: 0.0081 - val_accuracy: 0.6976\n",
      "Epoch 17/100\n",
      "421/421 [==============================] - 2s 5ms/step - loss: 0.0057 - accuracy: 0.8049 - val_loss: 0.0080 - val_accuracy: 0.6996\n",
      "Epoch 18/100\n",
      "421/421 [==============================] - 2s 5ms/step - loss: 0.0055 - accuracy: 0.8286 - val_loss: 0.0080 - val_accuracy: 0.7063\n",
      "Epoch 19/100\n",
      "421/421 [==============================] - 2s 5ms/step - loss: 0.0053 - accuracy: 0.8268 - val_loss: 0.0081 - val_accuracy: 0.5985\n",
      "Epoch 20/100\n",
      "421/421 [==============================] - 2s 5ms/step - loss: 0.0051 - accuracy: 0.8178 - val_loss: 0.0082 - val_accuracy: 0.7946\n",
      "Epoch 21/100\n",
      "421/421 [==============================] - 2s 5ms/step - loss: 0.0049 - accuracy: 0.8594 - val_loss: 0.0082 - val_accuracy: 0.9505\n",
      "Epoch 22/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "421/421 [==============================] - 2s 5ms/step - loss: 0.0047 - accuracy: 0.8782 - val_loss: 0.0083 - val_accuracy: 0.9568\n",
      "Epoch 23/100\n",
      "421/421 [==============================] - 2s 5ms/step - loss: 0.0045 - accuracy: 0.9093 - val_loss: 0.0083 - val_accuracy: 0.9334\n",
      "Epoch 24/100\n",
      "421/421 [==============================] - 2s 5ms/step - loss: 0.0043 - accuracy: 0.9183 - val_loss: 0.0084 - val_accuracy: 0.9197\n",
      "Epoch 25/100\n",
      "421/421 [==============================] - 2s 5ms/step - loss: 0.0041 - accuracy: 0.9040 - val_loss: 0.0085 - val_accuracy: 0.9401\n",
      "Epoch 26/100\n",
      "421/421 [==============================] - 2s 5ms/step - loss: 0.0039 - accuracy: 0.9265 - val_loss: 0.0085 - val_accuracy: 0.9334\n",
      "Epoch 27/100\n",
      "421/421 [==============================] - 2s 5ms/step - loss: 0.0037 - accuracy: 0.9338 - val_loss: 0.0087 - val_accuracy: 0.9113\n",
      "Epoch 28/100\n",
      "421/421 [==============================] - 2s 5ms/step - loss: 0.0034 - accuracy: 0.9293 - val_loss: 0.0087 - val_accuracy: 0.9428\n",
      "Epoch 29/100\n",
      "421/421 [==============================] - 2s 5ms/step - loss: 0.0032 - accuracy: 0.9303 - val_loss: 0.0088 - val_accuracy: 0.9057\n",
      "Epoch 30/100\n",
      "421/421 [==============================] - 2s 5ms/step - loss: 0.0030 - accuracy: 0.9206 - val_loss: 0.0091 - val_accuracy: 0.9542\n",
      "Epoch 31/100\n",
      "421/421 [==============================] - 2s 5ms/step - loss: 0.0028 - accuracy: 0.9332 - val_loss: 0.0093 - val_accuracy: 0.9214\n",
      "Epoch 32/100\n",
      "421/421 [==============================] - 2s 5ms/step - loss: 0.0026 - accuracy: 0.9218 - val_loss: 0.0094 - val_accuracy: 0.9224\n",
      "Epoch 33/100\n",
      "421/421 [==============================] - 2s 5ms/step - loss: 0.0024 - accuracy: 0.9135 - val_loss: 0.0095 - val_accuracy: 0.8772\n",
      "Epoch 34/100\n",
      "421/421 [==============================] - 2s 5ms/step - loss: 0.0022 - accuracy: 0.9079 - val_loss: 0.0097 - val_accuracy: 0.9271\n",
      "Epoch 35/100\n",
      "421/421 [==============================] - 2s 5ms/step - loss: 0.0020 - accuracy: 0.9075 - val_loss: 0.0099 - val_accuracy: 0.9371\n",
      "Epoch 36/100\n",
      "421/421 [==============================] - 2s 5ms/step - loss: 0.0018 - accuracy: 0.9109 - val_loss: 0.0103 - val_accuracy: 0.9154\n",
      "Epoch 37/100\n",
      "421/421 [==============================] - 2s 5ms/step - loss: 0.0016 - accuracy: 0.9034 - val_loss: 0.0104 - val_accuracy: 0.9227\n",
      "Epoch 38/100\n",
      "421/421 [==============================] - 2s 5ms/step - loss: 0.0015 - accuracy: 0.9040 - val_loss: 0.0105 - val_accuracy: 0.8973\n",
      "Epoch 39/100\n",
      "421/421 [==============================] - 2s 5ms/step - loss: 0.0013 - accuracy: 0.8942 - val_loss: 0.0107 - val_accuracy: 0.8949\n",
      "Epoch 40/100\n",
      "421/421 [==============================] - 2s 5ms/step - loss: 0.0012 - accuracy: 0.8894 - val_loss: 0.0110 - val_accuracy: 0.8655\n",
      "Epoch 41/100\n",
      "421/421 [==============================] - 2s 5ms/step - loss: 0.0010 - accuracy: 0.8822 - val_loss: 0.0113 - val_accuracy: 0.9174\n",
      "Epoch 42/100\n",
      "421/421 [==============================] - 2s 5ms/step - loss: 9.2731e-04 - accuracy: 0.8848 - val_loss: 0.0116 - val_accuracy: 0.9057\n",
      "Epoch 43/100\n",
      "421/421 [==============================] - 2s 5ms/step - loss: 8.1624e-04 - accuracy: 0.8755 - val_loss: 0.0119 - val_accuracy: 0.8531\n",
      "Epoch 44/100\n",
      "421/421 [==============================] - 2s 5ms/step - loss: 7.1220e-04 - accuracy: 0.8638 - val_loss: 0.0123 - val_accuracy: 0.8699\n",
      "Epoch 45/100\n",
      "421/421 [==============================] - 2s 5ms/step - loss: 6.2747e-04 - accuracy: 0.8629 - val_loss: 0.0124 - val_accuracy: 0.8551\n",
      "Epoch 46/100\n",
      "421/421 [==============================] - 2s 5ms/step - loss: 5.5067e-04 - accuracy: 0.8590 - val_loss: 0.0127 - val_accuracy: 0.8270\n",
      "Epoch 47/100\n",
      "421/421 [==============================] - 2s 5ms/step - loss: 4.6656e-04 - accuracy: 0.8438 - val_loss: 0.0130 - val_accuracy: 0.8565\n",
      "Epoch 48/100\n",
      "421/421 [==============================] - 2s 5ms/step - loss: 4.0984e-04 - accuracy: 0.8357 - val_loss: 0.0133 - val_accuracy: 0.8561\n",
      "Epoch 49/100\n",
      "421/421 [==============================] - 2s 5ms/step - loss: 3.5727e-04 - accuracy: 0.8288 - val_loss: 0.0136 - val_accuracy: 0.8521\n",
      "Epoch 50/100\n",
      "421/421 [==============================] - 2s 5ms/step - loss: 3.1269e-04 - accuracy: 0.8306 - val_loss: 0.0139 - val_accuracy: 0.8106\n",
      "Epoch 51/100\n",
      "421/421 [==============================] - 2s 5ms/step - loss: 2.6868e-04 - accuracy: 0.8175 - val_loss: 0.0143 - val_accuracy: 0.8294\n",
      "Epoch 52/100\n",
      "421/421 [==============================] - 2s 5ms/step - loss: 2.4449e-04 - accuracy: 0.8114 - val_loss: 0.0146 - val_accuracy: 0.8096\n",
      "Epoch 53/100\n",
      "421/421 [==============================] - 2s 5ms/step - loss: 2.0985e-04 - accuracy: 0.7976 - val_loss: 0.0148 - val_accuracy: 0.8039\n",
      "Epoch 54/100\n",
      "421/421 [==============================] - 2s 5ms/step - loss: 1.9490e-04 - accuracy: 0.7840 - val_loss: 0.0152 - val_accuracy: 0.7926\n",
      "Epoch 55/100\n",
      "421/421 [==============================] - 2s 5ms/step - loss: 1.6197e-04 - accuracy: 0.7860 - val_loss: 0.0155 - val_accuracy: 0.7899\n",
      "Epoch 56/100\n",
      "421/421 [==============================] - 2s 5ms/step - loss: 1.4895e-04 - accuracy: 0.7739 - val_loss: 0.0158 - val_accuracy: 0.7832\n",
      "Epoch 57/100\n",
      "421/421 [==============================] - 2s 5ms/step - loss: 1.2954e-04 - accuracy: 0.7570 - val_loss: 0.0162 - val_accuracy: 0.7692\n",
      "Epoch 58/100\n",
      "421/421 [==============================] - 2s 5ms/step - loss: 1.0944e-04 - accuracy: 0.7535 - val_loss: 0.0163 - val_accuracy: 0.7591\n",
      "Epoch 59/100\n",
      "421/421 [==============================] - 2s 5ms/step - loss: 1.0292e-04 - accuracy: 0.7380 - val_loss: 0.0168 - val_accuracy: 0.7327\n",
      "Epoch 60/100\n",
      "421/421 [==============================] - 2s 5ms/step - loss: 1.1093e-04 - accuracy: 0.7291 - val_loss: 0.0170 - val_accuracy: 0.7541\n",
      "Epoch 61/100\n",
      "421/421 [==============================] - 2s 4ms/step - loss: 8.5040e-05 - accuracy: 0.7284 - val_loss: 0.0173 - val_accuracy: 0.7357\n",
      "Epoch 62/100\n",
      "421/421 [==============================] - 2s 5ms/step - loss: 8.4509e-05 - accuracy: 0.7163 - val_loss: 0.0175 - val_accuracy: 0.7303\n",
      "Epoch 63/100\n",
      "421/421 [==============================] - 2s 5ms/step - loss: 1.0434e-04 - accuracy: 0.7099 - val_loss: 0.0179 - val_accuracy: 0.7140\n",
      "Epoch 64/100\n",
      "421/421 [==============================] - 2s 4ms/step - loss: 6.8672e-05 - accuracy: 0.6880 - val_loss: 0.0179 - val_accuracy: 0.7039\n",
      "Epoch 65/100\n",
      "421/421 [==============================] - 2s 4ms/step - loss: 6.5346e-05 - accuracy: 0.6882 - val_loss: 0.0183 - val_accuracy: 0.6945\n",
      "Epoch 66/100\n",
      "421/421 [==============================] - 2s 5ms/step - loss: 5.5860e-05 - accuracy: 0.6697 - val_loss: 0.0187 - val_accuracy: 0.6598\n",
      "Epoch 67/100\n",
      "421/421 [==============================] - 2s 5ms/step - loss: 6.3344e-05 - accuracy: 0.6624 - val_loss: 0.0186 - val_accuracy: 0.7016\n",
      "Epoch 68/100\n",
      "421/421 [==============================] - 2s 5ms/step - loss: 5.3659e-05 - accuracy: 0.6683 - val_loss: 0.0190 - val_accuracy: 0.6745\n",
      "Epoch 69/100\n",
      "421/421 [==============================] - 2s 5ms/step - loss: 6.2098e-05 - accuracy: 0.6595 - val_loss: 0.0193 - val_accuracy: 0.6855\n",
      "Epoch 70/100\n",
      "421/421 [==============================] - 2s 5ms/step - loss: 5.0024e-05 - accuracy: 0.6405 - val_loss: 0.0192 - val_accuracy: 0.6427\n",
      "Epoch 71/100\n",
      "421/421 [==============================] - 2s 5ms/step - loss: 4.6509e-05 - accuracy: 0.6474 - val_loss: 0.0194 - val_accuracy: 0.6561\n",
      "Epoch 72/100\n",
      "421/421 [==============================] - 2s 5ms/step - loss: 4.8511e-05 - accuracy: 0.6491 - val_loss: 0.0198 - val_accuracy: 0.6320\n",
      "Epoch 73/100\n",
      "421/421 [==============================] - 2s 5ms/step - loss: 4.7864e-05 - accuracy: 0.6218 - val_loss: 0.0199 - val_accuracy: 0.6290\n",
      "Epoch 74/100\n",
      "421/421 [==============================] - 2s 5ms/step - loss: 4.0043e-05 - accuracy: 0.6248 - val_loss: 0.0204 - val_accuracy: 0.6360\n",
      "Epoch 75/100\n",
      "421/421 [==============================] - 2s 5ms/step - loss: 4.4345e-05 - accuracy: 0.6178 - val_loss: 0.0202 - val_accuracy: 0.6286\n",
      "Epoch 76/100\n",
      "421/421 [==============================] - 2s 5ms/step - loss: 4.0611e-05 - accuracy: 0.6146 - val_loss: 0.0204 - val_accuracy: 0.6233\n",
      "Epoch 77/100\n",
      "421/421 [==============================] - 2s 5ms/step - loss: 3.7365e-05 - accuracy: 0.6101 - val_loss: 0.0208 - val_accuracy: 0.6109\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 78/100\n",
      "421/421 [==============================] - 2s 5ms/step - loss: 4.1869e-05 - accuracy: 0.6022 - val_loss: 0.0209 - val_accuracy: 0.6193\n",
      "Epoch 79/100\n",
      "421/421 [==============================] - 2s 5ms/step - loss: 3.2158e-05 - accuracy: 0.5812 - val_loss: 0.0209 - val_accuracy: 0.6005\n",
      "Epoch 80/100\n",
      "421/421 [==============================] - 2s 5ms/step - loss: 3.9311e-05 - accuracy: 0.5898 - val_loss: 0.0210 - val_accuracy: 0.5948\n",
      "Epoch 81/100\n",
      "421/421 [==============================] - 2s 5ms/step - loss: 2.9941e-05 - accuracy: 0.5738 - val_loss: 0.0210 - val_accuracy: 0.5905\n",
      "Epoch 82/100\n",
      "421/421 [==============================] - 2s 5ms/step - loss: 3.1128e-05 - accuracy: 0.5773 - val_loss: 0.0213 - val_accuracy: 0.5841\n",
      "Epoch 83/100\n",
      "421/421 [==============================] - 2s 5ms/step - loss: 2.7285e-05 - accuracy: 0.5735 - val_loss: 0.0216 - val_accuracy: 0.5868\n",
      "Epoch 84/100\n",
      "421/421 [==============================] - 2s 5ms/step - loss: 2.4305e-05 - accuracy: 0.5654 - val_loss: 0.0217 - val_accuracy: 0.5721\n",
      "Epoch 85/100\n",
      "421/421 [==============================] - 2s 5ms/step - loss: 3.1122e-05 - accuracy: 0.5541 - val_loss: 0.0219 - val_accuracy: 0.5841\n",
      "Epoch 86/100\n",
      "421/421 [==============================] - 2s 5ms/step - loss: 2.7057e-05 - accuracy: 0.5586 - val_loss: 0.0218 - val_accuracy: 0.5691\n",
      "Epoch 87/100\n",
      "421/421 [==============================] - 2s 5ms/step - loss: 2.5469e-05 - accuracy: 0.5592 - val_loss: 0.0221 - val_accuracy: 0.5527\n",
      "Epoch 88/100\n",
      "421/421 [==============================] - 2s 5ms/step - loss: 3.2729e-05 - accuracy: 0.5443 - val_loss: 0.0223 - val_accuracy: 0.5524\n",
      "Epoch 89/100\n",
      "421/421 [==============================] - 2s 5ms/step - loss: 2.3817e-05 - accuracy: 0.5447 - val_loss: 0.0224 - val_accuracy: 0.5624\n",
      "Epoch 90/100\n",
      "421/421 [==============================] - 2s 5ms/step - loss: 2.2828e-05 - accuracy: 0.5426 - val_loss: 0.0223 - val_accuracy: 0.5728\n",
      "Epoch 91/100\n",
      "421/421 [==============================] - 2s 5ms/step - loss: 2.7605e-05 - accuracy: 0.5452 - val_loss: 0.0225 - val_accuracy: 0.5437\n",
      "Epoch 92/100\n",
      "421/421 [==============================] - 2s 5ms/step - loss: 1.8631e-05 - accuracy: 0.5351 - val_loss: 0.0228 - val_accuracy: 0.5483\n",
      "Epoch 93/100\n",
      "421/421 [==============================] - 2s 5ms/step - loss: 2.0077e-05 - accuracy: 0.5346 - val_loss: 0.0230 - val_accuracy: 0.5233\n",
      "Epoch 94/100\n",
      "421/421 [==============================] - 2s 5ms/step - loss: 1.8703e-05 - accuracy: 0.5259 - val_loss: 0.0230 - val_accuracy: 0.5380\n",
      "Epoch 95/100\n",
      "421/421 [==============================] - 2s 5ms/step - loss: 2.1416e-05 - accuracy: 0.5338 - val_loss: 0.0229 - val_accuracy: 0.5554\n",
      "Epoch 96/100\n",
      "421/421 [==============================] - 2s 5ms/step - loss: 1.6922e-05 - accuracy: 0.5207 - val_loss: 0.0232 - val_accuracy: 0.5229\n",
      "Epoch 97/100\n",
      "421/421 [==============================] - 2s 5ms/step - loss: 1.7469e-05 - accuracy: 0.5208 - val_loss: 0.0236 - val_accuracy: 0.5189\n",
      "Epoch 98/100\n",
      "421/421 [==============================] - 2s 5ms/step - loss: 2.1081e-05 - accuracy: 0.5178 - val_loss: 0.0235 - val_accuracy: 0.5139\n",
      "Epoch 99/100\n",
      "421/421 [==============================] - 2s 5ms/step - loss: 1.5065e-05 - accuracy: 0.5182 - val_loss: 0.0235 - val_accuracy: 0.5320\n",
      "Epoch 100/100\n",
      "421/421 [==============================] - 2s 5ms/step - loss: 1.6633e-05 - accuracy: 0.5153 - val_loss: 0.0236 - val_accuracy: 0.5179\n",
      "Score for fold 8 : loss of 0.02357669547200203 ; F1-Macro: 0.6795988840609262 F1-Micro: 0.9434983758243922\n",
      "Training...\n",
      "Epoch 1/100\n",
      "421/421 [==============================] - 3s 5ms/step - loss: 0.0591 - accuracy: 0.9903 - val_loss: 0.0202 - val_accuracy: 0.9977\n",
      "Epoch 2/100\n",
      "421/421 [==============================] - 2s 5ms/step - loss: 0.0168 - accuracy: 0.9807 - val_loss: 0.0137 - val_accuracy: 0.9358\n",
      "Epoch 3/100\n",
      "421/421 [==============================] - 2s 5ms/step - loss: 0.0126 - accuracy: 0.8330 - val_loss: 0.0110 - val_accuracy: 0.8163\n",
      "Epoch 4/100\n",
      "421/421 [==============================] - 2s 5ms/step - loss: 0.0107 - accuracy: 0.8578 - val_loss: 0.0100 - val_accuracy: 0.5353\n",
      "Epoch 5/100\n",
      "421/421 [==============================] - 2s 5ms/step - loss: 0.0097 - accuracy: 0.6167 - val_loss: 0.0093 - val_accuracy: 0.5664\n",
      "Epoch 6/100\n",
      "421/421 [==============================] - 2s 5ms/step - loss: 0.0090 - accuracy: 0.5958 - val_loss: 0.0088 - val_accuracy: 0.9301\n",
      "Epoch 7/100\n",
      "421/421 [==============================] - 2s 5ms/step - loss: 0.0084 - accuracy: 0.6005 - val_loss: 0.0086 - val_accuracy: 0.5393\n",
      "Epoch 8/100\n",
      "421/421 [==============================] - 2s 5ms/step - loss: 0.0080 - accuracy: 0.6941 - val_loss: 0.0083 - val_accuracy: 0.5681\n",
      "Epoch 9/100\n",
      "421/421 [==============================] - 2s 5ms/step - loss: 0.0076 - accuracy: 0.6099 - val_loss: 0.0082 - val_accuracy: 0.9120\n",
      "Epoch 10/100\n",
      "421/421 [==============================] - 2s 5ms/step - loss: 0.0073 - accuracy: 0.6776 - val_loss: 0.0081 - val_accuracy: 0.9562\n",
      "Epoch 11/100\n",
      "421/421 [==============================] - 2s 5ms/step - loss: 0.0070 - accuracy: 0.6503 - val_loss: 0.0079 - val_accuracy: 0.6367\n",
      "Epoch 12/100\n",
      "421/421 [==============================] - 2s 5ms/step - loss: 0.0068 - accuracy: 0.7356 - val_loss: 0.0078 - val_accuracy: 0.7451\n",
      "Epoch 13/100\n",
      "421/421 [==============================] - 2s 5ms/step - loss: 0.0065 - accuracy: 0.7012 - val_loss: 0.0077 - val_accuracy: 0.8448\n",
      "Epoch 14/100\n",
      "421/421 [==============================] - 2s 5ms/step - loss: 0.0063 - accuracy: 0.8200 - val_loss: 0.0079 - val_accuracy: 0.5256\n",
      "Epoch 15/100\n",
      "421/421 [==============================] - 2s 5ms/step - loss: 0.0061 - accuracy: 0.7304 - val_loss: 0.0078 - val_accuracy: 0.6674\n",
      "Epoch 16/100\n",
      "421/421 [==============================] - 2s 5ms/step - loss: 0.0059 - accuracy: 0.8227 - val_loss: 0.0080 - val_accuracy: 0.6591\n",
      "Epoch 17/100\n",
      "421/421 [==============================] - 2s 5ms/step - loss: 0.0057 - accuracy: 0.7043 - val_loss: 0.0078 - val_accuracy: 0.7253\n",
      "Epoch 18/100\n",
      "421/421 [==============================] - 2s 5ms/step - loss: 0.0055 - accuracy: 0.7752 - val_loss: 0.0078 - val_accuracy: 0.7926\n",
      "Epoch 19/100\n",
      "421/421 [==============================] - 2s 5ms/step - loss: 0.0052 - accuracy: 0.7349 - val_loss: 0.0078 - val_accuracy: 0.6698\n",
      "Epoch 20/100\n",
      "421/421 [==============================] - 2s 5ms/step - loss: 0.0051 - accuracy: 0.7716 - val_loss: 0.0079 - val_accuracy: 0.9150\n",
      "Epoch 21/100\n",
      "421/421 [==============================] - 2s 5ms/step - loss: 0.0049 - accuracy: 0.7850 - val_loss: 0.0079 - val_accuracy: 0.9378\n",
      "Epoch 22/100\n",
      "421/421 [==============================] - 2s 5ms/step - loss: 0.0047 - accuracy: 0.8002 - val_loss: 0.0079 - val_accuracy: 0.8458\n",
      "Epoch 23/100\n",
      "421/421 [==============================] - 2s 5ms/step - loss: 0.0044 - accuracy: 0.8366 - val_loss: 0.0080 - val_accuracy: 0.9154\n",
      "Epoch 24/100\n",
      "421/421 [==============================] - 2s 5ms/step - loss: 0.0042 - accuracy: 0.8506 - val_loss: 0.0081 - val_accuracy: 0.8602\n",
      "Epoch 25/100\n",
      "421/421 [==============================] - 2s 5ms/step - loss: 0.0040 - accuracy: 0.8502 - val_loss: 0.0081 - val_accuracy: 0.8675\n",
      "Epoch 26/100\n",
      "421/421 [==============================] - 2s 5ms/step - loss: 0.0038 - accuracy: 0.8646 - val_loss: 0.0083 - val_accuracy: 0.9384\n",
      "Epoch 27/100\n",
      "421/421 [==============================] - 2s 5ms/step - loss: 0.0036 - accuracy: 0.8670 - val_loss: 0.0083 - val_accuracy: 0.8294\n",
      "Epoch 28/100\n",
      "421/421 [==============================] - 2s 4ms/step - loss: 0.0034 - accuracy: 0.8714 - val_loss: 0.0084 - val_accuracy: 0.8297\n",
      "Epoch 29/100\n",
      "421/421 [==============================] - 2s 4ms/step - loss: 0.0032 - accuracy: 0.8736 - val_loss: 0.0086 - val_accuracy: 0.9180\n",
      "Epoch 30/100\n",
      "421/421 [==============================] - 2s 4ms/step - loss: 0.0030 - accuracy: 0.8811 - val_loss: 0.0087 - val_accuracy: 0.8193\n",
      "Epoch 31/100\n",
      "421/421 [==============================] - 2s 4ms/step - loss: 0.0028 - accuracy: 0.8573 - val_loss: 0.0087 - val_accuracy: 0.8334\n",
      "Epoch 32/100\n",
      "421/421 [==============================] - 2s 5ms/step - loss: 0.0026 - accuracy: 0.8631 - val_loss: 0.0090 - val_accuracy: 0.8558\n",
      "Epoch 33/100\n",
      "421/421 [==============================] - 2s 5ms/step - loss: 0.0024 - accuracy: 0.8403 - val_loss: 0.0091 - val_accuracy: 0.8003\n",
      "Epoch 34/100\n",
      "421/421 [==============================] - 2s 5ms/step - loss: 0.0021 - accuracy: 0.8383 - val_loss: 0.0094 - val_accuracy: 0.8270\n",
      "Epoch 35/100\n",
      "421/421 [==============================] - 2s 5ms/step - loss: 0.0020 - accuracy: 0.8269 - val_loss: 0.0096 - val_accuracy: 0.8719\n",
      "Epoch 36/100\n",
      "421/421 [==============================] - 2s 5ms/step - loss: 0.0018 - accuracy: 0.8331 - val_loss: 0.0098 - val_accuracy: 0.7922\n",
      "Epoch 37/100\n",
      "421/421 [==============================] - 2s 5ms/step - loss: 0.0016 - accuracy: 0.8259 - val_loss: 0.0100 - val_accuracy: 0.7999\n",
      "Epoch 38/100\n",
      "421/421 [==============================] - 2s 5ms/step - loss: 0.0014 - accuracy: 0.8163 - val_loss: 0.0102 - val_accuracy: 0.8444\n",
      "Epoch 39/100\n",
      "421/421 [==============================] - 2s 4ms/step - loss: 0.0013 - accuracy: 0.8088 - val_loss: 0.0105 - val_accuracy: 0.7765\n",
      "Epoch 40/100\n",
      "421/421 [==============================] - 2s 5ms/step - loss: 0.0012 - accuracy: 0.8012 - val_loss: 0.0106 - val_accuracy: 0.7916\n",
      "Epoch 41/100\n",
      "421/421 [==============================] - 2s 5ms/step - loss: 0.0010 - accuracy: 0.8049 - val_loss: 0.0108 - val_accuracy: 0.8076\n",
      "Epoch 42/100\n",
      "421/421 [==============================] - 2s 5ms/step - loss: 8.9939e-04 - accuracy: 0.7846 - val_loss: 0.0115 - val_accuracy: 0.7842\n",
      "Epoch 43/100\n",
      "421/421 [==============================] - 2s 5ms/step - loss: 8.0032e-04 - accuracy: 0.7879 - val_loss: 0.0115 - val_accuracy: 0.7581\n",
      "Epoch 44/100\n",
      "421/421 [==============================] - 2s 5ms/step - loss: 6.9454e-04 - accuracy: 0.7750 - val_loss: 0.0117 - val_accuracy: 0.7394\n",
      "Epoch 45/100\n",
      "421/421 [==============================] - 2s 5ms/step - loss: 6.0740e-04 - accuracy: 0.7736 - val_loss: 0.0123 - val_accuracy: 0.7692\n",
      "Epoch 46/100\n",
      "421/421 [==============================] - 2s 5ms/step - loss: 5.3296e-04 - accuracy: 0.7605 - val_loss: 0.0125 - val_accuracy: 0.7457\n",
      "Epoch 47/100\n",
      "421/421 [==============================] - 2s 5ms/step - loss: 4.6152e-04 - accuracy: 0.7497 - val_loss: 0.0127 - val_accuracy: 0.7571\n",
      "Epoch 48/100\n",
      "421/421 [==============================] - 2s 5ms/step - loss: 3.9919e-04 - accuracy: 0.7563 - val_loss: 0.0128 - val_accuracy: 0.7384\n",
      "Epoch 49/100\n",
      "421/421 [==============================] - 2s 5ms/step - loss: 3.4874e-04 - accuracy: 0.7504 - val_loss: 0.0132 - val_accuracy: 0.7116\n",
      "Epoch 50/100\n",
      "421/421 [==============================] - 2s 5ms/step - loss: 2.9169e-04 - accuracy: 0.7310 - val_loss: 0.0137 - val_accuracy: 0.6905\n",
      "Epoch 51/100\n",
      "421/421 [==============================] - 2s 5ms/step - loss: 2.6632e-04 - accuracy: 0.7065 - val_loss: 0.0140 - val_accuracy: 0.6869\n",
      "Epoch 52/100\n",
      "421/421 [==============================] - 2s 5ms/step - loss: 2.3552e-04 - accuracy: 0.7171 - val_loss: 0.0142 - val_accuracy: 0.6999\n",
      "Epoch 53/100\n",
      "421/421 [==============================] - 2s 5ms/step - loss: 2.0376e-04 - accuracy: 0.7056 - val_loss: 0.0147 - val_accuracy: 0.6818\n",
      "Epoch 54/100\n",
      "421/421 [==============================] - 2s 5ms/step - loss: 1.6881e-04 - accuracy: 0.7044 - val_loss: 0.0149 - val_accuracy: 0.6869\n",
      "Epoch 55/100\n",
      "421/421 [==============================] - 2s 5ms/step - loss: 1.6080e-04 - accuracy: 0.6874 - val_loss: 0.0150 - val_accuracy: 0.6450\n",
      "Epoch 56/100\n",
      "421/421 [==============================] - 2s 5ms/step - loss: 1.3553e-04 - accuracy: 0.6805 - val_loss: 0.0156 - val_accuracy: 0.6531\n",
      "Epoch 57/100\n",
      "421/421 [==============================] - 2s 5ms/step - loss: 1.3926e-04 - accuracy: 0.6726 - val_loss: 0.0157 - val_accuracy: 0.6621\n",
      "Epoch 58/100\n",
      "421/421 [==============================] - 2s 5ms/step - loss: 1.1795e-04 - accuracy: 0.6623 - val_loss: 0.0161 - val_accuracy: 0.6424\n",
      "Epoch 59/100\n",
      "421/421 [==============================] - 2s 5ms/step - loss: 8.9536e-05 - accuracy: 0.6601 - val_loss: 0.0163 - val_accuracy: 0.6333\n",
      "Epoch 60/100\n",
      "421/421 [==============================] - 2s 5ms/step - loss: 9.1022e-05 - accuracy: 0.6482 - val_loss: 0.0167 - val_accuracy: 0.6343\n",
      "Epoch 61/100\n",
      "421/421 [==============================] - 2s 5ms/step - loss: 9.1473e-05 - accuracy: 0.6514 - val_loss: 0.0168 - val_accuracy: 0.6373\n",
      "Epoch 62/100\n",
      "421/421 [==============================] - 2s 5ms/step - loss: 6.6762e-05 - accuracy: 0.6395 - val_loss: 0.0172 - val_accuracy: 0.6236\n",
      "Epoch 63/100\n",
      "421/421 [==============================] - 2s 5ms/step - loss: 7.0687e-05 - accuracy: 0.6327 - val_loss: 0.0176 - val_accuracy: 0.6119\n",
      "Epoch 64/100\n",
      "421/421 [==============================] - 2s 5ms/step - loss: 7.2840e-05 - accuracy: 0.6168 - val_loss: 0.0177 - val_accuracy: 0.6109\n",
      "Epoch 65/100\n",
      "421/421 [==============================] - 2s 5ms/step - loss: 5.0305e-05 - accuracy: 0.6268 - val_loss: 0.0178 - val_accuracy: 0.5935\n",
      "Epoch 66/100\n",
      "421/421 [==============================] - 2s 5ms/step - loss: 4.8916e-05 - accuracy: 0.6057 - val_loss: 0.0181 - val_accuracy: 0.6213\n",
      "Epoch 67/100\n",
      "421/421 [==============================] - 2s 5ms/step - loss: 5.9154e-05 - accuracy: 0.6202 - val_loss: 0.0184 - val_accuracy: 0.6066\n",
      "Epoch 68/100\n",
      "421/421 [==============================] - 2s 5ms/step - loss: 6.0123e-05 - accuracy: 0.6006 - val_loss: 0.0185 - val_accuracy: 0.6086\n",
      "Epoch 69/100\n",
      "421/421 [==============================] - 2s 5ms/step - loss: 5.2659e-05 - accuracy: 0.6018 - val_loss: 0.0191 - val_accuracy: 0.5831\n",
      "Epoch 70/100\n",
      "421/421 [==============================] - 2s 5ms/step - loss: 4.6374e-05 - accuracy: 0.5850 - val_loss: 0.0190 - val_accuracy: 0.5845\n",
      "Epoch 71/100\n",
      "421/421 [==============================] - 2s 5ms/step - loss: 3.4279e-05 - accuracy: 0.5868 - val_loss: 0.0193 - val_accuracy: 0.5912\n",
      "Epoch 72/100\n",
      "421/421 [==============================] - 2s 5ms/step - loss: 4.1685e-05 - accuracy: 0.5907 - val_loss: 0.0196 - val_accuracy: 0.5674\n",
      "Epoch 73/100\n",
      "421/421 [==============================] - 2s 5ms/step - loss: 3.0161e-05 - accuracy: 0.5783 - val_loss: 0.0198 - val_accuracy: 0.5882\n",
      "Epoch 74/100\n",
      "421/421 [==============================] - 2s 5ms/step - loss: 3.6624e-05 - accuracy: 0.5780 - val_loss: 0.0199 - val_accuracy: 0.5644\n",
      "Epoch 75/100\n",
      "421/421 [==============================] - 2s 5ms/step - loss: 3.2354e-05 - accuracy: 0.5603 - val_loss: 0.0202 - val_accuracy: 0.5684\n",
      "Epoch 76/100\n",
      "421/421 [==============================] - 2s 5ms/step - loss: 2.6421e-05 - accuracy: 0.5620 - val_loss: 0.0206 - val_accuracy: 0.5594\n",
      "Epoch 77/100\n",
      "421/421 [==============================] - 2s 5ms/step - loss: 4.1647e-05 - accuracy: 0.5632 - val_loss: 0.0202 - val_accuracy: 0.5504\n",
      "Epoch 78/100\n",
      "421/421 [==============================] - 2s 5ms/step - loss: 3.3095e-05 - accuracy: 0.5531 - val_loss: 0.0206 - val_accuracy: 0.5420\n",
      "Epoch 79/100\n",
      "421/421 [==============================] - 2s 5ms/step - loss: 2.2415e-05 - accuracy: 0.5398 - val_loss: 0.0206 - val_accuracy: 0.5570\n",
      "Epoch 80/100\n",
      "421/421 [==============================] - 2s 5ms/step - loss: 3.0255e-05 - accuracy: 0.5514 - val_loss: 0.0208 - val_accuracy: 0.5684\n",
      "Epoch 81/100\n",
      "421/421 [==============================] - 2s 5ms/step - loss: 2.3299e-05 - accuracy: 0.5510 - val_loss: 0.0210 - val_accuracy: 0.5316\n",
      "Epoch 82/100\n",
      "421/421 [==============================] - 2s 5ms/step - loss: 3.2602e-05 - accuracy: 0.5431 - val_loss: 0.0212 - val_accuracy: 0.5437\n",
      "Epoch 83/100\n",
      "421/421 [==============================] - 2s 5ms/step - loss: 2.2713e-05 - accuracy: 0.5449 - val_loss: 0.0212 - val_accuracy: 0.5423\n",
      "Epoch 84/100\n",
      "421/421 [==============================] - 2s 5ms/step - loss: 2.1762e-05 - accuracy: 0.5370 - val_loss: 0.0214 - val_accuracy: 0.5417\n",
      "Epoch 85/100\n",
      "421/421 [==============================] - 2s 5ms/step - loss: 2.2348e-05 - accuracy: 0.5375 - val_loss: 0.0217 - val_accuracy: 0.5423\n",
      "Epoch 86/100\n",
      "421/421 [==============================] - 2s 5ms/step - loss: 2.9242e-05 - accuracy: 0.5262 - val_loss: 0.0217 - val_accuracy: 0.5433\n",
      "Epoch 87/100\n",
      "421/421 [==============================] - 2s 5ms/step - loss: 1.9580e-05 - accuracy: 0.5337 - val_loss: 0.0218 - val_accuracy: 0.5243\n",
      "Epoch 88/100\n",
      "421/421 [==============================] - 2s 5ms/step - loss: 2.0638e-05 - accuracy: 0.5300 - val_loss: 0.0220 - val_accuracy: 0.5219\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 89/100\n",
      "421/421 [==============================] - 2s 5ms/step - loss: 1.4125e-05 - accuracy: 0.5307 - val_loss: 0.0221 - val_accuracy: 0.5323\n",
      "Epoch 90/100\n",
      "421/421 [==============================] - 2s 5ms/step - loss: 1.9498e-05 - accuracy: 0.5300 - val_loss: 0.0221 - val_accuracy: 0.5166\n",
      "Epoch 91/100\n",
      "421/421 [==============================] - 2s 5ms/step - loss: 1.4911e-05 - accuracy: 0.5220 - val_loss: 0.0223 - val_accuracy: 0.5376\n",
      "Epoch 92/100\n",
      "421/421 [==============================] - 2s 5ms/step - loss: 1.8420e-05 - accuracy: 0.5239 - val_loss: 0.0225 - val_accuracy: 0.5166\n",
      "Epoch 93/100\n",
      "421/421 [==============================] - 2s 5ms/step - loss: 1.5488e-05 - accuracy: 0.5212 - val_loss: 0.0224 - val_accuracy: 0.5152\n",
      "Epoch 94/100\n",
      "421/421 [==============================] - 2s 5ms/step - loss: 1.3240e-05 - accuracy: 0.5188 - val_loss: 0.0226 - val_accuracy: 0.5095\n",
      "Epoch 95/100\n",
      "421/421 [==============================] - 2s 4ms/step - loss: 1.9156e-05 - accuracy: 0.5153 - val_loss: 0.0226 - val_accuracy: 0.5162\n",
      "Epoch 96/100\n",
      "421/421 [==============================] - 2s 5ms/step - loss: 1.6969e-05 - accuracy: 0.5149 - val_loss: 0.0228 - val_accuracy: 0.5199\n",
      "Epoch 97/100\n",
      "421/421 [==============================] - 2s 5ms/step - loss: 1.4197e-05 - accuracy: 0.5211 - val_loss: 0.0232 - val_accuracy: 0.5132\n",
      "Epoch 98/100\n",
      "421/421 [==============================] - 2s 5ms/step - loss: 1.2869e-05 - accuracy: 0.5235 - val_loss: 0.0231 - val_accuracy: 0.5015\n",
      "Epoch 99/100\n",
      "421/421 [==============================] - 2s 5ms/step - loss: 1.1745e-05 - accuracy: 0.5090 - val_loss: 0.0231 - val_accuracy: 0.5159\n",
      "Epoch 100/100\n",
      "421/421 [==============================] - 2s 5ms/step - loss: 1.5515e-05 - accuracy: 0.5134 - val_loss: 0.0232 - val_accuracy: 0.5069\n",
      "Score for fold 9 : loss of 0.02316310815513134 ; F1-Macro: 0.7338677836237489 F1-Micro: 0.9449406222396702\n",
      "Training...\n",
      "Epoch 1/100\n",
      "421/421 [==============================] - 3s 5ms/step - loss: 0.0588 - accuracy: 0.8873 - val_loss: 0.0207 - val_accuracy: 0.9926\n",
      "Epoch 2/100\n",
      "421/421 [==============================] - 2s 5ms/step - loss: 0.0165 - accuracy: 0.9638 - val_loss: 0.0142 - val_accuracy: 0.9448\n",
      "Epoch 3/100\n",
      "421/421 [==============================] - 2s 5ms/step - loss: 0.0123 - accuracy: 0.8417 - val_loss: 0.0120 - val_accuracy: 0.9023\n",
      "Epoch 4/100\n",
      "421/421 [==============================] - 2s 5ms/step - loss: 0.0106 - accuracy: 0.8094 - val_loss: 0.0110 - val_accuracy: 0.8796\n",
      "Epoch 5/100\n",
      "421/421 [==============================] - 2s 5ms/step - loss: 0.0096 - accuracy: 0.6688 - val_loss: 0.0103 - val_accuracy: 0.3787\n",
      "Epoch 6/100\n",
      "421/421 [==============================] - 2s 5ms/step - loss: 0.0089 - accuracy: 0.5828 - val_loss: 0.0097 - val_accuracy: 0.5119\n",
      "Epoch 7/100\n",
      "421/421 [==============================] - 2s 5ms/step - loss: 0.0083 - accuracy: 0.5779 - val_loss: 0.0095 - val_accuracy: 0.6276\n",
      "Epoch 8/100\n",
      "421/421 [==============================] - 2s 5ms/step - loss: 0.0079 - accuracy: 0.5604 - val_loss: 0.0092 - val_accuracy: 0.8501\n",
      "Epoch 9/100\n",
      "421/421 [==============================] - 2s 5ms/step - loss: 0.0075 - accuracy: 0.6542 - val_loss: 0.0092 - val_accuracy: 0.7795\n",
      "Epoch 10/100\n",
      "421/421 [==============================] - 2s 5ms/step - loss: 0.0072 - accuracy: 0.6575 - val_loss: 0.0089 - val_accuracy: 0.9388\n",
      "Epoch 11/100\n",
      "421/421 [==============================] - 2s 5ms/step - loss: 0.0069 - accuracy: 0.6972 - val_loss: 0.0089 - val_accuracy: 0.9197\n",
      "Epoch 12/100\n",
      "421/421 [==============================] - 2s 5ms/step - loss: 0.0067 - accuracy: 0.7661 - val_loss: 0.0088 - val_accuracy: 0.9291\n",
      "Epoch 13/100\n",
      "421/421 [==============================] - 2s 5ms/step - loss: 0.0064 - accuracy: 0.7774 - val_loss: 0.0088 - val_accuracy: 0.7491\n",
      "Epoch 14/100\n",
      "421/421 [==============================] - 2s 5ms/step - loss: 0.0062 - accuracy: 0.8196 - val_loss: 0.0089 - val_accuracy: 0.6986\n",
      "Epoch 15/100\n",
      "421/421 [==============================] - 2s 5ms/step - loss: 0.0060 - accuracy: 0.7682 - val_loss: 0.0088 - val_accuracy: 0.7518\n",
      "Epoch 16/100\n",
      "421/421 [==============================] - 2s 5ms/step - loss: 0.0058 - accuracy: 0.8087 - val_loss: 0.0089 - val_accuracy: 0.9147\n",
      "Epoch 17/100\n",
      "421/421 [==============================] - 2s 5ms/step - loss: 0.0056 - accuracy: 0.8002 - val_loss: 0.0088 - val_accuracy: 0.7993\n",
      "Epoch 18/100\n",
      "421/421 [==============================] - 2s 5ms/step - loss: 0.0054 - accuracy: 0.8527 - val_loss: 0.0088 - val_accuracy: 0.9026\n",
      "Epoch 19/100\n",
      "421/421 [==============================] - 2s 5ms/step - loss: 0.0052 - accuracy: 0.8142 - val_loss: 0.0089 - val_accuracy: 0.8491\n",
      "Epoch 20/100\n",
      "421/421 [==============================] - 2s 5ms/step - loss: 0.0050 - accuracy: 0.8542 - val_loss: 0.0091 - val_accuracy: 0.7216\n",
      "Epoch 21/100\n",
      "421/421 [==============================] - 2s 5ms/step - loss: 0.0048 - accuracy: 0.8422 - val_loss: 0.0091 - val_accuracy: 0.8933\n",
      "Epoch 22/100\n",
      "421/421 [==============================] - 2s 5ms/step - loss: 0.0046 - accuracy: 0.8473 - val_loss: 0.0094 - val_accuracy: 0.9194\n",
      "Epoch 23/100\n",
      "421/421 [==============================] - 2s 5ms/step - loss: 0.0044 - accuracy: 0.8648 - val_loss: 0.0093 - val_accuracy: 0.8551\n",
      "Epoch 24/100\n",
      "421/421 [==============================] - 2s 5ms/step - loss: 0.0041 - accuracy: 0.8788 - val_loss: 0.0094 - val_accuracy: 0.8782\n",
      "Epoch 25/100\n",
      "421/421 [==============================] - 2s 5ms/step - loss: 0.0039 - accuracy: 0.8941 - val_loss: 0.0096 - val_accuracy: 0.8916\n",
      "Epoch 26/100\n",
      "421/421 [==============================] - 2s 5ms/step - loss: 0.0037 - accuracy: 0.8977 - val_loss: 0.0097 - val_accuracy: 0.8923\n",
      "Epoch 27/100\n",
      "421/421 [==============================] - 2s 5ms/step - loss: 0.0035 - accuracy: 0.9077 - val_loss: 0.0098 - val_accuracy: 0.9495\n",
      "Epoch 28/100\n",
      "421/421 [==============================] - 2s 5ms/step - loss: 0.0033 - accuracy: 0.9228 - val_loss: 0.0100 - val_accuracy: 0.9448\n",
      "Epoch 29/100\n",
      "421/421 [==============================] - 2s 5ms/step - loss: 0.0031 - accuracy: 0.9109 - val_loss: 0.0101 - val_accuracy: 0.9033\n",
      "Epoch 30/100\n",
      "421/421 [==============================] - 2s 5ms/step - loss: 0.0029 - accuracy: 0.9159 - val_loss: 0.0104 - val_accuracy: 0.8956\n",
      "Epoch 31/100\n",
      "421/421 [==============================] - 2s 5ms/step - loss: 0.0027 - accuracy: 0.9191 - val_loss: 0.0107 - val_accuracy: 0.8732\n",
      "Epoch 32/100\n",
      "421/421 [==============================] - 2s 5ms/step - loss: 0.0024 - accuracy: 0.8971 - val_loss: 0.0107 - val_accuracy: 0.9147\n",
      "Epoch 33/100\n",
      "421/421 [==============================] - 2s 5ms/step - loss: 0.0023 - accuracy: 0.9036 - val_loss: 0.0109 - val_accuracy: 0.9006\n",
      "Epoch 34/100\n",
      "421/421 [==============================] - 2s 5ms/step - loss: 0.0021 - accuracy: 0.8965 - val_loss: 0.0111 - val_accuracy: 0.8963\n",
      "Epoch 35/100\n",
      "421/421 [==============================] - 2s 5ms/step - loss: 0.0019 - accuracy: 0.9021 - val_loss: 0.0114 - val_accuracy: 0.8953\n",
      "Epoch 36/100\n",
      "421/421 [==============================] - 2s 5ms/step - loss: 0.0017 - accuracy: 0.8860 - val_loss: 0.0116 - val_accuracy: 0.8622\n",
      "Epoch 37/100\n",
      "421/421 [==============================] - 2s 5ms/step - loss: 0.0016 - accuracy: 0.8884 - val_loss: 0.0120 - val_accuracy: 0.8765\n",
      "Epoch 38/100\n",
      "421/421 [==============================] - 2s 5ms/step - loss: 0.0014 - accuracy: 0.8783 - val_loss: 0.0123 - val_accuracy: 0.8712\n",
      "Epoch 39/100\n",
      "421/421 [==============================] - 2s 5ms/step - loss: 0.0013 - accuracy: 0.8806 - val_loss: 0.0123 - val_accuracy: 0.8511\n",
      "Epoch 40/100\n",
      "421/421 [==============================] - 2s 5ms/step - loss: 0.0011 - accuracy: 0.8648 - val_loss: 0.0131 - val_accuracy: 0.8468\n",
      "Epoch 41/100\n",
      "421/421 [==============================] - 2s 5ms/step - loss: 9.9340e-04 - accuracy: 0.8724 - val_loss: 0.0132 - val_accuracy: 0.8578\n",
      "Epoch 42/100\n",
      "421/421 [==============================] - 2s 5ms/step - loss: 8.7558e-04 - accuracy: 0.8656 - val_loss: 0.0134 - val_accuracy: 0.8581\n",
      "Epoch 43/100\n",
      "421/421 [==============================] - 2s 5ms/step - loss: 7.6894e-04 - accuracy: 0.8566 - val_loss: 0.0139 - val_accuracy: 0.8314\n",
      "Epoch 44/100\n",
      "421/421 [==============================] - 2s 5ms/step - loss: 6.7248e-04 - accuracy: 0.8540 - val_loss: 0.0143 - val_accuracy: 0.8699\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 45/100\n",
      "421/421 [==============================] - 2s 5ms/step - loss: 5.8704e-04 - accuracy: 0.8544 - val_loss: 0.0147 - val_accuracy: 0.8234\n",
      "Epoch 46/100\n",
      "421/421 [==============================] - 2s 5ms/step - loss: 5.2791e-04 - accuracy: 0.8389 - val_loss: 0.0148 - val_accuracy: 0.8264\n",
      "Epoch 47/100\n",
      "421/421 [==============================] - 2s 5ms/step - loss: 4.5091e-04 - accuracy: 0.8377 - val_loss: 0.0152 - val_accuracy: 0.8150\n",
      "Epoch 48/100\n",
      "421/421 [==============================] - 2s 5ms/step - loss: 3.8818e-04 - accuracy: 0.8262 - val_loss: 0.0155 - val_accuracy: 0.8394\n",
      "Epoch 49/100\n",
      "421/421 [==============================] - 2s 5ms/step - loss: 3.3520e-04 - accuracy: 0.8244 - val_loss: 0.0162 - val_accuracy: 0.8043\n",
      "Epoch 50/100\n",
      "421/421 [==============================] - 2s 5ms/step - loss: 2.9833e-04 - accuracy: 0.8196 - val_loss: 0.0164 - val_accuracy: 0.8361\n",
      "Epoch 51/100\n",
      "421/421 [==============================] - 2s 5ms/step - loss: 2.6014e-04 - accuracy: 0.8154 - val_loss: 0.0167 - val_accuracy: 0.8143\n",
      "Epoch 52/100\n",
      "421/421 [==============================] - 2s 4ms/step - loss: 2.3128e-04 - accuracy: 0.8079 - val_loss: 0.0172 - val_accuracy: 0.8227\n",
      "Epoch 53/100\n",
      "421/421 [==============================] - 2s 5ms/step - loss: 1.9700e-04 - accuracy: 0.8015 - val_loss: 0.0173 - val_accuracy: 0.7886\n",
      "Epoch 54/100\n",
      "421/421 [==============================] - 2s 5ms/step - loss: 1.7091e-04 - accuracy: 0.7893 - val_loss: 0.0177 - val_accuracy: 0.7889\n",
      "Epoch 55/100\n",
      "421/421 [==============================] - 2s 5ms/step - loss: 1.4986e-04 - accuracy: 0.7917 - val_loss: 0.0179 - val_accuracy: 0.7745\n",
      "Epoch 56/100\n",
      "421/421 [==============================] - 2s 5ms/step - loss: 1.3490e-04 - accuracy: 0.7777 - val_loss: 0.0186 - val_accuracy: 0.7568\n",
      "Epoch 57/100\n",
      "421/421 [==============================] - 2s 5ms/step - loss: 1.0975e-04 - accuracy: 0.7731 - val_loss: 0.0189 - val_accuracy: 0.7548\n",
      "Epoch 58/100\n",
      "421/421 [==============================] - 2s 4ms/step - loss: 1.2244e-04 - accuracy: 0.7552 - val_loss: 0.0193 - val_accuracy: 0.7708\n",
      "Epoch 59/100\n",
      "421/421 [==============================] - 2s 4ms/step - loss: 1.0300e-04 - accuracy: 0.7596 - val_loss: 0.0196 - val_accuracy: 0.7621\n",
      "Epoch 60/100\n",
      "421/421 [==============================] - 2s 4ms/step - loss: 9.1682e-05 - accuracy: 0.7539 - val_loss: 0.0199 - val_accuracy: 0.7611\n",
      "Epoch 61/100\n",
      "421/421 [==============================] - 2s 4ms/step - loss: 8.4147e-05 - accuracy: 0.7374 - val_loss: 0.0202 - val_accuracy: 0.7076\n",
      "Epoch 62/100\n",
      "421/421 [==============================] - 2s 4ms/step - loss: 6.6169e-05 - accuracy: 0.7313 - val_loss: 0.0206 - val_accuracy: 0.7220\n",
      "Epoch 63/100\n",
      "421/421 [==============================] - 2s 4ms/step - loss: 6.1288e-05 - accuracy: 0.7270 - val_loss: 0.0207 - val_accuracy: 0.7367\n",
      "Epoch 64/100\n",
      "421/421 [==============================] - 2s 4ms/step - loss: 7.1545e-05 - accuracy: 0.7233 - val_loss: 0.0213 - val_accuracy: 0.7213\n",
      "Epoch 65/100\n",
      "421/421 [==============================] - 2s 5ms/step - loss: 4.9763e-05 - accuracy: 0.7142 - val_loss: 0.0219 - val_accuracy: 0.7126\n",
      "Epoch 66/100\n",
      "421/421 [==============================] - 2s 5ms/step - loss: 6.9006e-05 - accuracy: 0.7060 - val_loss: 0.0218 - val_accuracy: 0.7200\n",
      "Epoch 67/100\n",
      "421/421 [==============================] - 2s 5ms/step - loss: 6.0893e-05 - accuracy: 0.7027 - val_loss: 0.0221 - val_accuracy: 0.6848\n",
      "Epoch 68/100\n",
      "421/421 [==============================] - 2s 5ms/step - loss: 3.7639e-05 - accuracy: 0.6934 - val_loss: 0.0224 - val_accuracy: 0.6862\n",
      "Epoch 69/100\n",
      "421/421 [==============================] - 2s 5ms/step - loss: 4.8535e-05 - accuracy: 0.6899 - val_loss: 0.0225 - val_accuracy: 0.7039\n",
      "Epoch 70/100\n",
      "421/421 [==============================] - 2s 5ms/step - loss: 3.7387e-05 - accuracy: 0.6872 - val_loss: 0.0227 - val_accuracy: 0.6705\n",
      "Epoch 71/100\n",
      "421/421 [==============================] - 2s 5ms/step - loss: 4.1883e-05 - accuracy: 0.6811 - val_loss: 0.0231 - val_accuracy: 0.6671\n",
      "Epoch 72/100\n",
      "421/421 [==============================] - 2s 5ms/step - loss: 4.3089e-05 - accuracy: 0.6755 - val_loss: 0.0234 - val_accuracy: 0.6725\n",
      "Epoch 73/100\n",
      "421/421 [==============================] - 2s 5ms/step - loss: 3.6412e-05 - accuracy: 0.6618 - val_loss: 0.0238 - val_accuracy: 0.6715\n",
      "Epoch 74/100\n",
      "421/421 [==============================] - 2s 5ms/step - loss: 3.8403e-05 - accuracy: 0.6602 - val_loss: 0.0236 - val_accuracy: 0.6470\n",
      "Epoch 75/100\n",
      "421/421 [==============================] - 2s 5ms/step - loss: 3.3479e-05 - accuracy: 0.6547 - val_loss: 0.0239 - val_accuracy: 0.6487\n",
      "Epoch 76/100\n",
      "421/421 [==============================] - 2s 5ms/step - loss: 2.3526e-05 - accuracy: 0.6426 - val_loss: 0.0242 - val_accuracy: 0.6668\n",
      "Epoch 77/100\n",
      "421/421 [==============================] - 2s 5ms/step - loss: 4.1392e-05 - accuracy: 0.6480 - val_loss: 0.0244 - val_accuracy: 0.6547\n",
      "Epoch 78/100\n",
      "421/421 [==============================] - 2s 5ms/step - loss: 3.0257e-05 - accuracy: 0.6402 - val_loss: 0.0249 - val_accuracy: 0.6383\n",
      "Epoch 79/100\n",
      "421/421 [==============================] - 2s 5ms/step - loss: 2.6522e-05 - accuracy: 0.6414 - val_loss: 0.0244 - val_accuracy: 0.6323\n",
      "Epoch 80/100\n",
      "421/421 [==============================] - 2s 5ms/step - loss: 3.3442e-05 - accuracy: 0.6293 - val_loss: 0.0249 - val_accuracy: 0.6337\n",
      "Epoch 81/100\n",
      "421/421 [==============================] - 2s 5ms/step - loss: 2.8028e-05 - accuracy: 0.6338 - val_loss: 0.0250 - val_accuracy: 0.6203\n",
      "Epoch 82/100\n",
      "421/421 [==============================] - 2s 5ms/step - loss: 2.9086e-05 - accuracy: 0.6228 - val_loss: 0.0251 - val_accuracy: 0.6320\n",
      "Epoch 83/100\n",
      "421/421 [==============================] - 2s 5ms/step - loss: 2.8198e-05 - accuracy: 0.6228 - val_loss: 0.0253 - val_accuracy: 0.6092\n",
      "Epoch 84/100\n",
      "421/421 [==============================] - 2s 5ms/step - loss: 2.1502e-05 - accuracy: 0.6076 - val_loss: 0.0254 - val_accuracy: 0.6035\n",
      "Epoch 85/100\n",
      "421/421 [==============================] - 2s 5ms/step - loss: 1.7266e-05 - accuracy: 0.6059 - val_loss: 0.0259 - val_accuracy: 0.6363\n",
      "Epoch 86/100\n",
      "421/421 [==============================] - 2s 5ms/step - loss: 2.1500e-05 - accuracy: 0.6143 - val_loss: 0.0258 - val_accuracy: 0.6032\n",
      "Epoch 87/100\n",
      "421/421 [==============================] - 2s 5ms/step - loss: 1.9931e-05 - accuracy: 0.6026 - val_loss: 0.0258 - val_accuracy: 0.5948\n",
      "Epoch 88/100\n",
      "421/421 [==============================] - 2s 5ms/step - loss: 2.6187e-05 - accuracy: 0.5957 - val_loss: 0.0261 - val_accuracy: 0.5818\n",
      "Epoch 89/100\n",
      "421/421 [==============================] - 2s 5ms/step - loss: 2.0057e-05 - accuracy: 0.5918 - val_loss: 0.0264 - val_accuracy: 0.6039\n",
      "Epoch 90/100\n",
      "421/421 [==============================] - 2s 5ms/step - loss: 1.8816e-05 - accuracy: 0.5979 - val_loss: 0.0262 - val_accuracy: 0.5811\n",
      "Epoch 91/100\n",
      "421/421 [==============================] - 2s 5ms/step - loss: 1.8401e-05 - accuracy: 0.5804 - val_loss: 0.0267 - val_accuracy: 0.5952\n",
      "Epoch 92/100\n",
      "421/421 [==============================] - 2s 5ms/step - loss: 2.2573e-05 - accuracy: 0.5893 - val_loss: 0.0267 - val_accuracy: 0.5738\n",
      "Epoch 93/100\n",
      "421/421 [==============================] - 2s 5ms/step - loss: 1.6400e-05 - accuracy: 0.5776 - val_loss: 0.0269 - val_accuracy: 0.5764\n",
      "Epoch 94/100\n",
      "421/421 [==============================] - 2s 5ms/step - loss: 1.5259e-05 - accuracy: 0.5728 - val_loss: 0.0269 - val_accuracy: 0.5848\n",
      "Epoch 95/100\n",
      "421/421 [==============================] - 2s 5ms/step - loss: 2.0159e-05 - accuracy: 0.5779 - val_loss: 0.0270 - val_accuracy: 0.5580\n",
      "Epoch 96/100\n",
      "421/421 [==============================] - 2s 5ms/step - loss: 1.6772e-05 - accuracy: 0.5707 - val_loss: 0.0271 - val_accuracy: 0.5534\n",
      "Epoch 97/100\n",
      "421/421 [==============================] - 2s 5ms/step - loss: 1.4168e-05 - accuracy: 0.5698 - val_loss: 0.0271 - val_accuracy: 0.5467\n",
      "Epoch 98/100\n",
      "421/421 [==============================] - 2s 5ms/step - loss: 1.1678e-05 - accuracy: 0.5520 - val_loss: 0.0276 - val_accuracy: 0.5671\n",
      "Epoch 99/100\n",
      "421/421 [==============================] - 2s 5ms/step - loss: 1.5503e-05 - accuracy: 0.5640 - val_loss: 0.0276 - val_accuracy: 0.5647\n",
      "Epoch 100/100\n",
      "421/421 [==============================] - 2s 5ms/step - loss: 1.5450e-05 - accuracy: 0.5660 - val_loss: 0.0277 - val_accuracy: 0.5534\n",
      "Score for fold 10 : loss of 0.027690699324011803 ; F1-Macro: 0.691264384446635 F1-Micro: 0.9362371564819821\n",
      "------------------------------------------------------------------------\n",
      "Score per fold\n",
      "------------------------------------------------------------------------\n",
      "> Fold 1  - Loss: 0.02735821343958378 - F1-Macro: 0.6494053422253019 %\n",
      "------------------------------------------------------------------------\n",
      "> Fold 2  - Loss: 0.02847907319664955 - F1-Macro: 0.7240974102951583 %\n",
      "------------------------------------------------------------------------\n",
      "> Fold 3  - Loss: 0.024841681122779846 - F1-Macro: 0.7192175068252838 %\n",
      "------------------------------------------------------------------------\n",
      "> Fold 4  - Loss: 0.029565371572971344 - F1-Macro: 0.6488101120309002 %\n",
      "------------------------------------------------------------------------\n",
      "> Fold 5  - Loss: 0.023142701014876366 - F1-Macro: 0.7529009094387104 %\n",
      "------------------------------------------------------------------------\n",
      "> Fold 6  - Loss: 0.02592935413122177 - F1-Macro: 0.7121186862735349 %\n",
      "------------------------------------------------------------------------\n",
      "> Fold 7  - Loss: 0.02602919563651085 - F1-Macro: 0.664264728990239 %\n",
      "------------------------------------------------------------------------\n",
      "> Fold 8  - Loss: 0.02357669547200203 - F1-Macro: 0.6795988840609262 %\n",
      "------------------------------------------------------------------------\n",
      "> Fold 9  - Loss: 0.02316310815513134 - F1-Macro: 0.7338677836237489 %\n",
      "------------------------------------------------------------------------\n",
      "> Fold 10  - Loss: 0.027690699324011803 - F1-Macro: 0.691264384446635 %\n",
      "------------------------------------------------------------------------\n",
      "Average scores for all folds:\n",
      "> F1-Macro: 0.6975545748210438 (+- 0.03454322275483713 )\n",
      "> F1-Micro: 0.9408191436292233 (+- 0.0025180401105800404 )\n",
      "> Loss: 0.02597760930657387\n",
      "------------------------------------------------------------------------\n",
      "   F1-Macro  F1-Macro_std  F1-Micro  F1-Micro_std  F1-Weighted  \\\n",
      "0  0.697555      0.034543  0.940819      0.002518     0.937474   \n",
      "\n",
      "   F1-Weighted_std         Dataset           method  \n",
      "0         0.002565  Person_DBpedia  Only Embeddings  \n",
      "Model: \"sequential_59\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_118 (Dense)           (None, 768)               590592    \n",
      "                                                                 \n",
      " Gelu (Activation)           (None, 768)               0         \n",
      "                                                                 \n",
      " dense_119 (Dense)           (None, 125)               96125     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 686,717\n",
      "Trainable params: 686,717\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "K_FOLD = 10\n",
    "mlb = MultiLabelBinarizer()\n",
    "fold_no = 1\n",
    "loss_per_fold, f1_macro, f1_micro, f1_weighted = [], [], [], []\n",
    "kfold = KFold(n_splits=K_FOLD, shuffle=True, random_state=42)\n",
    "targets = mlb.fit_transform(input_new['Class'])\n",
    "#emb_array = r.drop(['S', 'Class'], axis=1).values\n",
    "for train, test_new in kfold.split(emb_array, targets):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(emb_array[train].shape[1], input_dim=emb_array[train].shape[1]))\n",
    "    model.add(Activation(gelu, name='Gelu'))\n",
    "    model.add(Dense(targets[train].shape[1], activation='sigmoid'))\n",
    "    # Compile model\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    print('Training...')\n",
    "    history = model.fit(emb_array[train], targets[train], batch_size=64, validation_data=(emb_array[test_new], targets[test_new]), epochs=100)\n",
    "    y_pred = model.predict(emb_array[test_new])\n",
    "    y_pred[y_pred>=0.5]=1\n",
    "    y_pred[y_pred<0.5]=0\n",
    "    \n",
    "    # Generate F1 scores\n",
    "    scores = model.evaluate(emb_array[test_new], targets[test_new], verbose=0)\n",
    "    f1_macro.append(f1_score(targets[test_new], y_pred, average='macro', zero_division=1))\n",
    "    f1_micro.append(f1_score(targets[test_new], y_pred, average='micro', zero_division=1))\n",
    "    f1_weighted.append(f1_score(targets[test_new], y_pred, average='weighted', zero_division=1))\n",
    "\n",
    "    print('Score for fold', fold_no, ':', model.metrics_names[0], 'of', scores[0], ';', 'F1-Macro:', f1_macro[-1], 'F1-Micro:', f1_micro[-1])\n",
    "    loss_per_fold.append(scores[0])\n",
    "\n",
    "    fold_no += 1\n",
    "    \n",
    "# Provide average scores\n",
    "print('------------------------------------------------------------------------')\n",
    "print('Score per fold')\n",
    "for i in range(0, len(loss_per_fold)):\n",
    "    print('------------------------------------------------------------------------')\n",
    "    print('> Fold', i+1, ' - Loss:', loss_per_fold[i], '- F1-Macro:', f1_macro[i], '%')\n",
    "print('------------------------------------------------------------------------')\n",
    "print('Average scores for all folds:')\n",
    "print('> F1-Macro:', np.mean(f1_macro), '(+-', np.std(f1_macro), ')')\n",
    "print('> F1-Micro:', np.mean(f1_micro), '(+-', np.std(f1_micro), ')')\n",
    "print('> Loss:', np.mean(loss_per_fold))\n",
    "print('------------------------------------------------------------------------')\n",
    "\n",
    "# Save results to file\n",
    "result = {}\n",
    "f1_macro = np.array(f1_macro)\n",
    "f1_micro = np.array(f1_micro)\n",
    "f1_weighted = np.array(f1_weighted)\n",
    "result['F1-Macro'] = np.mean(f1_macro)\n",
    "result['F1-Macro_std'] = np.std(f1_macro)\n",
    "result['F1-Micro'] = np.mean(f1_micro)\n",
    "result['F1-Micro_std'] = np.std(f1_micro)\n",
    "result['F1-Weighted'] = np.mean(f1_weighted)\n",
    "result['F1-Weighted_std'] = np.std(f1_weighted)\n",
    "result['Dataset'] = parser.dataset\n",
    "result['method'] = 'Only Embeddings'\n",
    "df_result = pd.DataFrame([result])\n",
    "print(df_result)\n",
    "\n",
    "if os.path.isfile('./evaluation_instance_type.csv'):\n",
    "    df_result.to_csv('./evaluation_instance_type.csv', mode='a', header=False, index=False)\n",
    "# else:\n",
    "    df_result.to_csv('./evaluation_instance_type.csv', index=False)\n",
    "\n",
    "    \n",
    "model.summary()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
