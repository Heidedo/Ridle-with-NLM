{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "825214be",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import wget\n",
    "import argparse\n",
    "import os\n",
    "import re\n",
    "import wikipediaapi as wikiapi\n",
    "import pickle\n",
    "import nltk\n",
    "import string"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b823729e",
   "metadata": {},
   "source": [
    "# Data selection and creation\n",
    "To successfully add natural language knowledge to the program, we have to first focus on where and how we get the information. Here, this is done by checking every single subject and replacing the link with a wikipedia link, so the WikipediaAPI can extract the summary or the content from the wikipedia page. There are two sections in this notebook. The first one focusses on just extracting the summary/the first paragraph/the abstract of the subjects wikipedia page. The second one extracts everything EXCEPT the abstract. At the end of each data cleaning step a pickle file is created to store the data along with the subject and class and i saved in the \"dataset\" folder of the specific dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f9a16726",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading files on Universities_Dbpedia\n",
      "Create mapping...\n"
     ]
    }
   ],
   "source": [
    "parser = argparse.ArgumentParser(\n",
    "    description='Ridle, learning a representation for entities using a target distributions over the usage of relations.',\n",
    ")\n",
    "#parser.add_argument('--dataset', nargs='?', default='DBp_2016-04', type=str)\n",
    "parser.add_argument('--dataset', nargs='?', default='Universities_Dbpedia', type=str)\n",
    "parser, unknown = parser.parse_known_args()\n",
    "\n",
    "# https://www.dropbox.com/sh/szvuv79ubfqgmn5/AACHxl_eC0frcGrZpVy0VDQPa?dl=0\n",
    "\n",
    "\n",
    "links = {}\n",
    "links['dblp'] = 'https://www.dropbox.com/s/78srst5bjt2tta1/dataset.pkl?dl=1'\n",
    "links['dbp_type_mapping'] = 'https://www.dropbox.com/s/2ec6dyr90pmjfm9/dbp_type_mapping.json?dl=1'\n",
    "links['umls'] = 'https://www.dropbox.com/s/madbrirjc3yjtru/dataset.pkl?dl=1'\n",
    "links['Person_DBpedia'] = 'https://www.dropbox.com/s/1omj2btnoj8g4xa/dataset.pkl?dl=1'\n",
    "links['DBp_2016-04'] = 'https://www.dropbox.com/s/z38exis1ah3q5ze/dataset.pkl?dl=1'\n",
    "links['Company_DBpedia'] = 'https://www.dropbox.com/s/bft3hmk2m6ecrkl/dataset.pkl?dl=1'\n",
    "links['Songs_DBpedia'] = 'https://www.dropbox.com/s/u9k6qaydqowckae/dataset.pkl?dl=1'\n",
    "links['Books_DBpedia'] = 'https://www.dropbox.com/s/wdqhov2g4bvwzr9/dataset.pkl?dl=1'\n",
    "links['ChemicalCompounds_DBpedia'] = 'https://www.dropbox.com/s/fyyqgtwwf2pnj3b/dataset.pkl?dl=1'\n",
    "links['Universities_DBpedia'] = 'https://www.dropbox.com/s/0g2moh3puz09uoy/dataset.pkl?dl=1'\n",
    "\n",
    "\n",
    "if not os.path.isfile('./dataset/dbp_type_mapping.json'):\n",
    "    print(\"Downloading dbp_type_mapping data.\")\n",
    "    data_url = links['dbp_type_mapping']\n",
    "    wget.download(data_url, './dataset/dbp_type_mapping.json')\n",
    "\n",
    "\n",
    "if not os.path.isfile('./dataset/{}/dataset.pkl'.format(parser.dataset)):\n",
    "    print(\"Downloading {} data.\".format(parser.dataset))\n",
    "    data_url = links[parser.dataset]\n",
    "    Path('./dataset/{}'.format(parser.dataset)).mkdir(parents=True, exist_ok=True)\n",
    "    wget.download(data_url, './dataset/{}/dataset.pkl'.format(parser.dataset))\n",
    "\n",
    "\n",
    "\n",
    "print('Loading files on', parser.dataset)\n",
    "# Loading Files\n",
    "df = pd.read_pickle('./dataset/{}/dataset.pkl'.format(parser.dataset))[['S', 'P']].drop_duplicates()\n",
    "\n",
    "s = df[\"S\"]\n",
    "\n",
    "#create list from pandas series object\n",
    "link_list = s.tolist()\n",
    "\n",
    "#remove the duplicates from list\n",
    "link_list_cleaned = list(dict.fromkeys(link_list))\n",
    "\n",
    "#replace dbpedia with wikipedia\n",
    "wiki_list = []\n",
    "for link in link_list_cleaned:\n",
    "    temp = re.sub(\"http://dbpedia.org/resource/\", 'https://en.wikipedia.org/wiki/', link)\n",
    "    wiki_list.append(temp)\n",
    "\n",
    "#create list with resource for wikipedia api\n",
    "resource_list = []\n",
    "for res in link_list_cleaned:\n",
    "    temp = re.sub(\"http://dbpedia.org/resource/\", '', res)\n",
    "    resource_list.append(temp)\n",
    "\n",
    "print(\"Create mapping...\")\n",
    "if 'dbp' in parser.dataset.lower():\n",
    "    mapping = pd.read_json('./dataset/dbp_type_mapping.json')\n",
    "elif 'wd' in parser.dataset.lower() or 'wikidata' in parser.dataset.lower():\n",
    "    mapping = pd.read_json('./dataset/wd_mapping_type.json')\n",
    "else:\n",
    "    mapping = pd.read_json('./dataset/{}/type_mapping.json'.format(parser.dataset))\n",
    "    \n",
    "#command for wikipedia article extraction\n",
    "wiki_wiki = wikiapi.Wikipedia(language='en', extract_format=wikiapi.ExtractFormat.WIKI)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a015992c",
   "metadata": {},
   "source": [
    "### Clean the data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "015cca96",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package words to\n",
      "[nltk_data]     C:\\Users\\Dorian\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package words is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('words')\n",
    "words = set(nltk.corpus.words.words())\n",
    "\n",
    "def clean_text(text):\n",
    "    '''\n",
    "    This function removes punctuation, words containing numbers\n",
    "    as well as making the whole text lower-case\n",
    "    '''\n",
    "    text = text.lower()\n",
    "    #text = text.encode(\"ascii\", errors=\"ignore\").decode()\n",
    "    text = re.sub('[%s]' % re.escape(string.punctuation), ' ', text)\n",
    "    text = re.sub('\\w*\\d\\w*', '', text)\n",
    "    text = re.sub('\\n', '', text)\n",
    "    text = re.sub(\"references\", \"\", text)\n",
    "    #text = \" \".join(w for w in nltk.wordpunct_tokenize(text) if w.lower() in words or not w.isalpha())\n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea5b9206",
   "metadata": {},
   "source": [
    "### Create summary dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "022ba4cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Summary</th>\n",
       "      <th>S</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1_Decembrie_1918_University,_Alba_Iulia</th>\n",
       "      <td>decembrie   university  alba iulia is a public higher education and research institution founded in  in alba iulia  romania  it is a state institution  integrated into the national higher educat...</td>\n",
       "      <td>http://dbpedia.org/resource/1_Decembrie_1918_University,_Alba_Iulia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42_(school)</th>\n",
       "      <td>is a private  nonprofit and tuition free computer programming school created and funded by french billionaire xavier niel  founder of the telecommunication company iliad  with several partners in...</td>\n",
       "      <td>http://dbpedia.org/resource/42_(school)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A.T._Still_University</th>\n",
       "      <td>a t  still university  atsu  is a private medical school based in kirksville  missouri  with a second campus in arizona  it was founded in  by dr  andrew taylor still and was the world s first ost...</td>\n",
       "      <td>http://dbpedia.org/resource/A.T._Still_University</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A.T._Still_University_School_of_Osteopathic_Medicine_in_Arizona</th>\n",
       "      <td>a t  still university   school of osteopathic medicine in arizona  atsu soma  is a private medical school in mesa  arizona  it was established in  and is on the arizona campus of a t  still univer...</td>\n",
       "      <td>http://dbpedia.org/resource/A.T._Still_University_School_of_Osteopathic_Medicine_in_Arizona</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A.V.V.M_Sri_Pushpam_College</th>\n",
       "      <td>a  veeriya vandayar memorial sri pushpam college is an arts and sciences autonomous college in thanjavur district  tamil nadu  india  established in   it offers higher education in arts  science a...</td>\n",
       "      <td>http://dbpedia.org/resource/A.V.V.M_Sri_Pushpam_College</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>West_University_of_Timi%C8%99oara</th>\n",
       "      <td></td>\n",
       "      <td>http://dbpedia.org/resource/West_University_of_Timi%C8%99oara</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Wroc%C5%82aw_Medical_University</th>\n",
       "      <td></td>\n",
       "      <td>http://dbpedia.org/resource/Wroc%C5%82aw_Medical_University</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Xavier_University_%E2%80%93_Ateneo_de_Cagayan</th>\n",
       "      <td></td>\n",
       "      <td>http://dbpedia.org/resource/Xavier_University_%E2%80%93_Ateneo_de_Cagayan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Y%C4%B1ld%C4%B1r%C4%B1m_Beyaz%C4%B1t_University</th>\n",
       "      <td></td>\n",
       "      <td>http://dbpedia.org/resource/Y%C4%B1ld%C4%B1r%C4%B1m_Beyaz%C4%B1t_University</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ya%C5%9Far_University</th>\n",
       "      <td></td>\n",
       "      <td>http://dbpedia.org/resource/Ya%C5%9Far_University</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9020 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                                 Summary  \\\n",
       "1_Decembrie_1918_University,_Alba_Iulia                            decembrie   university  alba iulia is a public higher education and research institution founded in  in alba iulia  romania  it is a state institution  integrated into the national higher educat...   \n",
       "42_(school)                                                       is a private  nonprofit and tuition free computer programming school created and funded by french billionaire xavier niel  founder of the telecommunication company iliad  with several partners in...   \n",
       "A.T._Still_University                                            a t  still university  atsu  is a private medical school based in kirksville  missouri  with a second campus in arizona  it was founded in  by dr  andrew taylor still and was the world s first ost...   \n",
       "A.T._Still_University_School_of_Osteopathic_Medicine_in_Arizona  a t  still university   school of osteopathic medicine in arizona  atsu soma  is a private medical school in mesa  arizona  it was established in  and is on the arizona campus of a t  still univer...   \n",
       "A.V.V.M_Sri_Pushpam_College                                      a  veeriya vandayar memorial sri pushpam college is an arts and sciences autonomous college in thanjavur district  tamil nadu  india  established in   it offers higher education in arts  science a...   \n",
       "...                                                                                                                                                                                                                                                                  ...   \n",
       "West_University_of_Timi%C8%99oara                                                                                                                                                                                                                                          \n",
       "Wroc%C5%82aw_Medical_University                                                                                                                                                                                                                                            \n",
       "Xavier_University_%E2%80%93_Ateneo_de_Cagayan                                                                                                                                                                                                                              \n",
       "Y%C4%B1ld%C4%B1r%C4%B1m_Beyaz%C4%B1t_University                                                                                                                                                                                                                            \n",
       "Ya%C5%9Far_University                                                                                                                                                                                                                                                      \n",
       "\n",
       "                                                                                                                                                           S  \n",
       "1_Decembrie_1918_University,_Alba_Iulia                                                  http://dbpedia.org/resource/1_Decembrie_1918_University,_Alba_Iulia  \n",
       "42_(school)                                                                                                          http://dbpedia.org/resource/42_(school)  \n",
       "A.T._Still_University                                                                                      http://dbpedia.org/resource/A.T._Still_University  \n",
       "A.T._Still_University_School_of_Osteopathic_Medicine_in_Arizona  http://dbpedia.org/resource/A.T._Still_University_School_of_Osteopathic_Medicine_in_Arizona  \n",
       "A.V.V.M_Sri_Pushpam_College                                                                          http://dbpedia.org/resource/A.V.V.M_Sri_Pushpam_College  \n",
       "...                                                                                                                                                      ...  \n",
       "West_University_of_Timi%C8%99oara                                                              http://dbpedia.org/resource/West_University_of_Timi%C8%99oara  \n",
       "Wroc%C5%82aw_Medical_University                                                                  http://dbpedia.org/resource/Wroc%C5%82aw_Medical_University  \n",
       "Xavier_University_%E2%80%93_Ateneo_de_Cagayan                                      http://dbpedia.org/resource/Xavier_University_%E2%80%93_Ateneo_de_Cagayan  \n",
       "Y%C4%B1ld%C4%B1r%C4%B1m_Beyaz%C4%B1t_University                                  http://dbpedia.org/resource/Y%C4%B1ld%C4%B1r%C4%B1m_Beyaz%C4%B1t_University  \n",
       "Ya%C5%9Far_University                                                                                      http://dbpedia.org/resource/Ya%C5%9Far_University  \n",
       "\n",
       "[9020 rows x 2 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create dictionary with keys: Objects and values: summary of wikipedia page\n",
    "#[:1000] after resource_list & link_list_cleaned to access a portion of the dataset. Change number dependent on the size you wish\n",
    "my_file = {}\n",
    "for items in resource_list:\n",
    "    my_file[items] = clean_text(wiki_wiki.page(items).summary)\n",
    "pd.set_option('max_colwidth',200)\n",
    "\n",
    "data_clean = pd.DataFrame.from_dict(my_file, orient='index')\n",
    "data_clean.columns = ['Summary']\n",
    "data_clean['S'] = data_clean.index\n",
    "#data_clean = data_clean.sort_index()\n",
    "data_clean['S'] = link_list_cleaned\n",
    "data_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "99c9d373",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_clean['S'] = link_list_cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9445b22b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating input file...\n",
      "Merging summary input data...\n",
      "Input file created successfully\n"
     ]
    }
   ],
   "source": [
    "print('Creating input file...')\n",
    "print('Merging summary input data...')\n",
    "r = pd.merge(data_clean, mapping, on='S')\n",
    "cols = r.columns.tolist()\n",
    "cols = cols[-1:] + cols[:-1]\n",
    "\n",
    "input_data = r[['S', 'Summary', 'Class']]\n",
    "input_data.to_pickle('./dataset/{}/input_data_unclean.pkl'.format(parser.dataset))\n",
    "print('Input file created successfully')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f77a6786",
   "metadata": {},
   "source": [
    "### Create content data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "64801e7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merging contents input data...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Contents</th>\n",
       "      <th>S</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>%C2%A1Ay,_qu%C3%A9_deseo!</th>\n",
       "      <td></td>\n",
       "      <td>http://dbpedia.org/resource/'97_Bonnie_&amp;_Clyde</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>%C2%A1Qu%C3%A9_bueno,_qu%C3%A9_bueno!</th>\n",
       "      <td></td>\n",
       "      <td>http://dbpedia.org/resource/'Cuz_I_Can_(Pink_song)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>%C2%BD_Full</th>\n",
       "      <td></td>\n",
       "      <td>http://dbpedia.org/resource/'Round_Midnight_(song)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>%C2%BFQu%C3%A9_voy_a_hacer_sin_ti%3F</th>\n",
       "      <td></td>\n",
       "      <td>http://dbpedia.org/resource/'S_Wonderful</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>%C2%BFQui%C3%A9n_maneja_mi_barca%3F</th>\n",
       "      <td></td>\n",
       "      <td>http://dbpedia.org/resource/'The_Half_of_It,_Dearie'_Blues</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Zooropa_(song)</th>\n",
       "      <td>background and recordingduring the zoo tv tour in ,  were trying to create a vision of an attractive future for europe, as opposed to a negative, dystopian image that would be found in science fic...</td>\n",
       "      <td>http://dbpedia.org/resource/You_Are_the_Only_One_(Ivan_Mikuli%C4%87_song)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Zor_and_Zam</th>\n",
       "      <td>personnelmicky dolenz - lead vocal, percussionkeith allison and bill chadwick - electric guitarschip douglas, richard dey and max bennett - bassmichael melvoin - pianoeddie hoh - drumshal blaine, ...</td>\n",
       "      <td>http://dbpedia.org/resource/Za_na%C5%A1u_ljubav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Zorbas</th>\n",
       "      <td>== references ==</td>\n",
       "      <td>http://dbpedia.org/resource/Zem_menom_l%C3%A1ska</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Zusammen_geh'n</th>\n",
       "      <td>charts== references ==</td>\n",
       "      <td>http://dbpedia.org/resource/Zemr%C3%ABn_e_lam%C3%AB_peng</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Zwei_kleine_Italiener</th>\n",
       "      <td></td>\n",
       "      <td>http://dbpedia.org/resource/Zjarr_e_ftoht%C3%AB</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6185 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                      Contents  \\\n",
       "%C2%A1Ay,_qu%C3%A9_deseo!                                                                                                                                                                                                                        \n",
       "%C2%A1Qu%C3%A9_bueno,_qu%C3%A9_bueno!                                                                                                                                                                                                            \n",
       "%C2%BD_Full                                                                                                                                                                                                                                      \n",
       "%C2%BFQu%C3%A9_voy_a_hacer_sin_ti%3F                                                                                                                                                                                                             \n",
       "%C2%BFQui%C3%A9n_maneja_mi_barca%3F                                                                                                                                                                                                              \n",
       "...                                                                                                                                                                                                                                        ...   \n",
       "Zooropa_(song)                         background and recordingduring the zoo tv tour in ,  were trying to create a vision of an attractive future for europe, as opposed to a negative, dystopian image that would be found in science fic...   \n",
       "Zor_and_Zam                            personnelmicky dolenz - lead vocal, percussionkeith allison and bill chadwick - electric guitarschip douglas, richard dey and max bennett - bassmichael melvoin - pianoeddie hoh - drumshal blaine, ...   \n",
       "Zorbas                                                                                                                                                                                                                        == references ==   \n",
       "Zusammen_geh'n                                                                                                                                                                                                          charts== references ==   \n",
       "Zwei_kleine_Italiener                                                                                                                                                                                                                            \n",
       "\n",
       "                                                                                                               S  \n",
       "%C2%A1Ay,_qu%C3%A9_deseo!                                         http://dbpedia.org/resource/'97_Bonnie_&_Clyde  \n",
       "%C2%A1Qu%C3%A9_bueno,_qu%C3%A9_bueno!                         http://dbpedia.org/resource/'Cuz_I_Can_(Pink_song)  \n",
       "%C2%BD_Full                                                   http://dbpedia.org/resource/'Round_Midnight_(song)  \n",
       "%C2%BFQu%C3%A9_voy_a_hacer_sin_ti%3F                                    http://dbpedia.org/resource/'S_Wonderful  \n",
       "%C2%BFQui%C3%A9n_maneja_mi_barca%3F                   http://dbpedia.org/resource/'The_Half_of_It,_Dearie'_Blues  \n",
       "...                                                                                                          ...  \n",
       "Zooropa_(song)                         http://dbpedia.org/resource/You_Are_the_Only_One_(Ivan_Mikuli%C4%87_song)  \n",
       "Zor_and_Zam                                                      http://dbpedia.org/resource/Za_na%C5%A1u_ljubav  \n",
       "Zorbas                                                          http://dbpedia.org/resource/Zem_menom_l%C3%A1ska  \n",
       "Zusammen_geh'n                                          http://dbpedia.org/resource/Zemr%C3%ABn_e_lam%C3%AB_peng  \n",
       "Zwei_kleine_Italiener                                            http://dbpedia.org/resource/Zjarr_e_ftoht%C3%AB  \n",
       "\n",
       "[6185 rows x 2 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create dictionary with keys: Objects and values: summary of wikipedia page\n",
    "my_corpus = {}\n",
    "i = 0\n",
    "for items in resource_list:\n",
    "    temp = wiki_wiki.page(items).text\n",
    "    temp = temp.split(\"\\n\\n\", 1)\n",
    "    temp = temp[1:]\n",
    "    temp = ' '.join([str(elem) for elem in temp])\n",
    "    temp = clean_text(temp)\n",
    "    my_corpus[items] = temp\n",
    "    i += 1\n",
    "\n",
    "corpus_new = pd.DataFrame.from_dict(my_corpus, orient='index')\n",
    "corpus_new.columns = ['Contents']\n",
    "corpus_new = corpus_new.sort_index()\n",
    "corpus_new = corpus_new.sort_index()\n",
    "corpus_new['S'] = link_list_cleaned\n",
    "\n",
    "# merge them\n",
    "print('Merging contents input data...')\n",
    "r = pd.merge(data_clean, mapping, on='S')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cd2c80a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating input file...\n",
      "Input file created successfully\n"
     ]
    }
   ],
   "source": [
    "print('Creating input file...')\n",
    "r = pd.merge(corpus_new, mapping, on='S')\n",
    "cols = r.columns.tolist()\n",
    "cols = cols[-1:] + cols[:-1]\n",
    "\n",
    "input_data = r[['S', 'Contents', 'Class']]\n",
    "input_data.to_pickle('./dataset/{}/input_data_contents_full.pkl'.format(parser.dataset))\n",
    "print('Input file created successfully')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13133c26",
   "metadata": {},
   "source": [
    "## Document-Term Matrix for further research"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eac19511",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_pickle('dataset/DBp_2016-04/input_data_summary_full.pkl')\n",
    "data_clean = data['Summary'][:10000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "edbc46ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aa</th>\n",
       "      <th>aaa</th>\n",
       "      <th>aaadonta</th>\n",
       "      <th>aabsal</th>\n",
       "      <th>aacm</th>\n",
       "      <th>aacsb</th>\n",
       "      <th>aaden</th>\n",
       "      <th>aadigere</th>\n",
       "      <th>aadmabaad</th>\n",
       "      <th>aaf</th>\n",
       "      <th>...</th>\n",
       "      <th>zwingen</th>\n",
       "      <th>zx</th>\n",
       "      <th>zygaenidae</th>\n",
       "      <th>zygophyllum</th>\n",
       "      <th>zygoptera</th>\n",
       "      <th>zyl</th>\n",
       "      <th>zymology</th>\n",
       "      <th>zyrat</th>\n",
       "      <th>zz</th>\n",
       "      <th>zzhxin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 53337 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      aa  aaa  aaadonta  aabsal  aacm  aacsb  aaden  aadigere  aadmabaad  aaf  \\\n",
       "0      0    0         0       0     0      0      0         0          0    0   \n",
       "1      0    0         0       0     0      0      0         0          0    0   \n",
       "2      0    0         0       0     0      0      0         0          0    0   \n",
       "3      0    0         0       0     0      0      0         0          0    0   \n",
       "4      0    0         0       0     0      0      0         0          0    0   \n",
       "...   ..  ...       ...     ...   ...    ...    ...       ...        ...  ...   \n",
       "9995   0    0         0       0     0      0      0         0          0    0   \n",
       "9996   0    0         0       0     0      0      0         0          0    0   \n",
       "9997   0    0         0       0     0      0      0         0          0    0   \n",
       "9998   0    0         0       0     0      0      0         0          0    0   \n",
       "9999   0    0         0       0     0      0      0         0          0    0   \n",
       "\n",
       "      ...  zwingen  zx  zygaenidae  zygophyllum  zygoptera  zyl  zymology  \\\n",
       "0     ...        0   0           0            0          0    0         0   \n",
       "1     ...        0   0           0            0          0    0         0   \n",
       "2     ...        0   0           0            0          0    0         0   \n",
       "3     ...        0   0           0            0          0    0         0   \n",
       "4     ...        0   0           0            0          0    0         0   \n",
       "...   ...      ...  ..         ...          ...        ...  ...       ...   \n",
       "9995  ...        0   0           0            0          0    0         0   \n",
       "9996  ...        0   0           0            0          0    0         0   \n",
       "9997  ...        0   0           0            0          0    0         0   \n",
       "9998  ...        0   0           0            0          0    0         0   \n",
       "9999  ...        0   0           0            0          0    0         0   \n",
       "\n",
       "      zyrat  zz  zzhxin  \n",
       "0         0   0       0  \n",
       "1         0   0       0  \n",
       "2         0   0       0  \n",
       "3         0   0       0  \n",
       "4         0   0       0  \n",
       "...     ...  ..     ...  \n",
       "9995      0   0       0  \n",
       "9996      0   0       0  \n",
       "9997      0   0       0  \n",
       "9998      0   0       0  \n",
       "9999      0   0       0  \n",
       "\n",
       "[10000 rows x 53337 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#using CountVectorizer to remove stopwords and tokenize the text to build the document-term matrix \n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "cv = CountVectorizer(stop_words='english')\n",
    "data_cv = cv.fit_transform(data_clean)\n",
    "data_dtm = pd.DataFrame(data_cv.toarray(), columns=cv.get_feature_names())\n",
    "data_dtm.index = data_clean.index\n",
    "data_dtm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "946249a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pickle the document term matrix for later use\n",
    "data_dtm.to_pickle('./dataset/DBp_2016-04/DTM.pkl')\n",
    "#Also pickle the cleaned data and the CountVectorizer object\n",
    "pickle.dump(cv, open(\"./dataset/DBp_2016-04/cv.pkl\", \"wb\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "084b0e48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aa</th>\n",
       "      <th>aaas</th>\n",
       "      <th>aadujeevitham</th>\n",
       "      <th>aai</th>\n",
       "      <th>aair</th>\n",
       "      <th>aalahayude</th>\n",
       "      <th>aalohari</th>\n",
       "      <th>aamukham</th>\n",
       "      <th>aanslag</th>\n",
       "      <th>aansprekers</th>\n",
       "      <th>...</th>\n",
       "      <th>zwecker</th>\n",
       "      <th>zwei</th>\n",
       "      <th>zweig</th>\n",
       "      <th>zwick</th>\n",
       "      <th>zwischen</th>\n",
       "      <th>zwlf</th>\n",
       "      <th>zygmunt</th>\n",
       "      <th>zyrgon</th>\n",
       "      <th>zz</th>\n",
       "      <th>zzh</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11176</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11177</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11178</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11179</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11180</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11181 rows × 48716 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       aa  aaas  aadujeevitham  aai  aair  aalahayude  aalohari  aamukham  \\\n",
       "0       0     0              0    0     0           0         0         0   \n",
       "1       0     0              0    0     0           0         0         0   \n",
       "2       0     0              0    0     0           0         0         0   \n",
       "3       0     0              0    0     0           0         0         0   \n",
       "4       0     0              0    0     0           0         0         0   \n",
       "...    ..   ...            ...  ...   ...         ...       ...       ...   \n",
       "11176   0     0              0    0     0           0         0         0   \n",
       "11177   0     0              0    0     0           0         0         0   \n",
       "11178   0     0              0    0     0           0         0         0   \n",
       "11179   0     0              0    0     0           0         0         0   \n",
       "11180   0     0              0    0     0           0         0         0   \n",
       "\n",
       "       aanslag  aansprekers  ...  zwecker  zwei  zweig  zwick  zwischen  zwlf  \\\n",
       "0            0            0  ...        0     0      0      0         0     0   \n",
       "1            0            0  ...        0     0      0      0         0     0   \n",
       "2            0            0  ...        0     0      0      0         0     0   \n",
       "3            0            0  ...        0     0      0      0         0     0   \n",
       "4            0            0  ...        0     0      0      0         0     0   \n",
       "...        ...          ...  ...      ...   ...    ...    ...       ...   ...   \n",
       "11176        0            0  ...        0     0      0      0         0     0   \n",
       "11177        0            0  ...        0     0      0      0         0     0   \n",
       "11178        0            0  ...        0     0      0      0         0     0   \n",
       "11179        0            0  ...        0     0      0      0         0     0   \n",
       "11180        0            0  ...        0     0      0      0         0     0   \n",
       "\n",
       "       zygmunt  zyrgon  zz  zzh  \n",
       "0            0       0   0    0  \n",
       "1            0       0   0    0  \n",
       "2            0       0   0    0  \n",
       "3            0       0   0    0  \n",
       "4            0       0   0    0  \n",
       "...        ...     ...  ..  ...  \n",
       "11176        0       0   0    0  \n",
       "11177        0       0   0    0  \n",
       "11178        0       0   0    0  \n",
       "11179        0       0   0    0  \n",
       "11180        0       0   0    0  \n",
       "\n",
       "[11181 rows x 48716 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_pickle('dataset/Books_Dbpedia/DTM.pkl')\n",
    "data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
